diff -Naur linux-2.6.12.3.pristine/arch/i386/Kconfig linux-2.6.12.3-vmi/arch/i386/Kconfig
--- linux-2.6.12.3.pristine/arch/i386/Kconfig	2005-07-15 21:18:57.000000000 +0000
+++ linux-2.6.12.3-vmi/arch/i386/Kconfig	2005-11-15 16:57:30.000000000 +0000
@@ -122,8 +122,24 @@
 	  Only choose this option if you have such a system, otherwise you
 	  should say N here.
 
+config X86_VMI
+	bool "VMI architecture support"
+	help
+	   This option builds a kernel designed to run on top of a virtual
+	   machine interface layer (VMI).  Say 'N' here unless you are
+	   building a kernel to run inside a virtual machine.
+
 endchoice
 
+config MEMORY_HOLE
+	int "Create hole at top of memory (0-512 MB)"
+	range 0 512
+	default "64" if X86_VMI
+	default "0" if !X86_VMI
+	help
+	   Useful for creating a hole in the top of memory when running
+	   inside of a virtual machine monitor.
+
 config ACPI_SRAT
 	bool
 	default y
@@ -152,6 +168,7 @@
 
 config M386
 	bool "386"
+	depends on !X86_VMI
 	---help---
 	  This is the processor type of your CPU. This information is used for
 	  optimizing purposes. In order to compile a kernel that can run on
@@ -191,6 +208,7 @@
 
 config M486
 	bool "486"
+	depends on !X86_VMI
 	help
 	  Select this for a 486 series processor, either Intel or one of the
 	  compatible processors from AMD, Cyrix, IBM, or Intel.  Includes DX,
@@ -199,6 +217,7 @@
 
 config M586
 	bool "586/K5/5x86/6x86/6x86MX"
+	depends on !X86_VMI
 	help
 	  Select this for an 586 or 686 series processor such as the AMD K5,
 	  the Cyrix 5x86, 6x86 and 6x86MX.  This choice does not
@@ -206,12 +225,14 @@
 
 config M586TSC
 	bool "Pentium-Classic"
+	depends on !X86_VMI
 	help
 	  Select this for a Pentium Classic processor with the RDTSC (Read
 	  Time Stamp Counter) instruction for benchmarking.
 
 config M586MMX
 	bool "Pentium-MMX"
+	depends on !X86_VMI
 	help
 	  Select this for a Pentium with the MMX graphics/multimedia
 	  extended instructions.
@@ -574,6 +595,27 @@
 	depends on X86_VISWS
 	default y
 
+config NO_IODELAY
+	bool "Zero delay I/O operations"
+	default n
+	help
+	   Eliminate I/O hardware delays for slower machines or machine running
+	   in a virtual environment which have zero-delay device emulation.
+
+config NO_UDELAY
+	bool "Eliminate udelay based delays"
+	depends on !X86_IO_APIC && EXPERIMENTAL
+	default n
+	help
+	   Eliminate delays for machines running in a virtual machine.
+
+config FAST_TIMER
+	bool "1Khz Timer"
+	default y
+	help
+	  Some systems with lower clockrates may want to run with a lower
+	  frequency timer.  Disabling this restores the old 100HZ timer.
+
 config X86_TSC
 	bool
 	depends on (MWINCHIP3D || MWINCHIP2 || MCRUSOE || MEFFICEON || MCYRIXIII || MK7 || MK6 || MPENTIUM4 || MPENTIUMM || MPENTIUMIII || MPENTIUMII || M686 || M586MMX || M586TSC || MK8 || MVIAC3_2 || MGEODEGX1) && !X86_NUMAQ
@@ -581,7 +623,7 @@
 
 config X86_MCE
 	bool "Machine Check Exception"
-	depends on !X86_VOYAGER
+	depends on !(X86_VOYAGER || X86_VMI)
 	---help---
 	  Machine Check Exception support allows the processor to notify the
 	  kernel if it detects a problem (e.g. overheating, component failure).
@@ -618,6 +660,7 @@
 
 config TOSHIBA
 	tristate "Toshiba Laptop support"
+	depends on !X86_VMI
 	---help---
 	  This adds a driver to safely access the System Management Mode of
 	  the CPU on Toshiba portables with a genuine Toshiba BIOS. It does
@@ -633,6 +676,7 @@
 
 config I8K
 	tristate "Dell laptop support"
+	depends on !X86_VMI
 	---help---
 	  This adds a driver to safely access the System Management Mode
 	  of the CPU on the Dell Inspiron 8000. The System Management Mode
@@ -671,6 +715,7 @@
 
 config MICROCODE
 	tristate "/dev/cpu/microcode - Intel IA32 CPU microcode support"
+	depends on !X86_VMI
 	---help---
 	  If you say Y here and also to "/dev file system support" in the
 	  'File systems' section, you will be able to update the microcode on
@@ -688,6 +733,7 @@
 
 config X86_MSR
 	tristate "/dev/cpu/*/msr - Model-specific register support"
+	depends on !X86_VMI
 	help
 	  This device gives privileged processes access to the x86
 	  Model-Specific Registers (MSRs).  It is a character device with
@@ -814,6 +860,7 @@
 
 config MATH_EMULATION
 	bool "Math emulation"
+	depends on !X86_VMI
 	---help---
 	  Linux can emulate a math coprocessor (used for floating point
 	  operations) if you don't have one. 486DX and Pentium processors have
@@ -950,7 +997,7 @@
 source "drivers/acpi/Kconfig"
 
 menu "APM (Advanced Power Management) BIOS Support"
-depends on PM && !X86_VISWS
+depends on PM && !(X86_VISWS || X86_VMI)
 
 config APM
 	tristate "APM (Advanced Power Management) BIOS support"
@@ -1120,7 +1167,7 @@
 
 choice
 	prompt "PCI access mode"
-	depends on PCI && !X86_VISWS
+	depends on PCI && !(X86_VISWS || X86_VMI)
 	default PCI_GOANY
 	---help---
 	  On PCI systems, the BIOS can be used to detect the PCI devices and
@@ -1153,12 +1200,12 @@
 
 config PCI_BIOS
 	bool
-	depends on !X86_VISWS && PCI && (PCI_GOBIOS || PCI_GOANY)
+	depends on !(X86_VISWS && X86_VMI) && PCI && (PCI_GOBIOS || PCI_GOANY)
 	default y
 
 config PCI_DIRECT
 	bool
- 	depends on PCI && ((PCI_GODIRECT || PCI_GOANY) || X86_VISWS)
+ 	depends on PCI && ((PCI_GODIRECT || PCI_GOANY) || X86_VISWS || X86_VMI)
 	default y
 
 config PCI_MMCONFIG
@@ -1177,7 +1224,7 @@
 
 config ISA
 	bool "ISA support"
-	depends on !(X86_VOYAGER || X86_VISWS)
+	depends on !(X86_VOYAGER || X86_VISWS || X86_VMI)
 	help
 	  Find out whether you have ISA slots on your motherboard.  ISA is the
 	  name of a bus system, i.e. the way the CPU talks to the other stuff
@@ -1204,7 +1251,7 @@
 source "drivers/eisa/Kconfig"
 
 config MCA
-	bool "MCA support" if !(X86_VISWS || X86_VOYAGER)
+	bool "MCA support" if !(X86_VISWS || X86_VOYAGER || X86_VMI)
 	default y if X86_VOYAGER
 	help
 	  MicroChannel Architecture is found in some IBM PS/2 machines and
@@ -1275,7 +1322,7 @@
 
 config X86_BIOS_REBOOT
 	bool
-	depends on !(X86_VISWS || X86_VOYAGER)
+	depends on !(X86_VISWS || X86_VOYAGER || X86_VMI)
 	default y
 
 config X86_TRAMPOLINE
diff -Naur linux-2.6.12.3.pristine/arch/i386/Kconfig.debug linux-2.6.12.3-vmi/arch/i386/Kconfig.debug
--- linux-2.6.12.3.pristine/arch/i386/Kconfig.debug	2005-07-15 21:18:57.000000000 +0000
+++ linux-2.6.12.3-vmi/arch/i386/Kconfig.debug	2005-11-15 16:57:30.000000000 +0000
@@ -49,6 +49,13 @@
 	  This results in a large slowdown, but helps to find certain types
 	  of memory corruptions.
 
+config DEBUG_VMI
+	bool "Debug the VMI interface calls"
+	depends on X86_VMI
+	help
+	  Add extra debugging code to the VMI layer and do a basic self
+	  test on startup.
+
 config 4KSTACKS
 	bool "Use 4Kb for kernel stacks instead of 8Kb"
 	depends on DEBUG_KERNEL
diff -Naur linux-2.6.12.3.pristine/arch/i386/Makefile linux-2.6.12.3-vmi/arch/i386/Makefile
--- linux-2.6.12.3.pristine/arch/i386/Makefile	2005-07-15 21:18:57.000000000 +0000
+++ linux-2.6.12.3-vmi/arch/i386/Makefile	2005-11-15 16:57:30.000000000 +0000
@@ -101,6 +101,10 @@
 mcore-$(CONFIG_X86_ES7000)	:= mach-default
 core-$(CONFIG_X86_ES7000)	:= arch/i386/mach-es7000/
 
+# VMI subarch support
+mflags-$(CONFIG_X86_VMI)	:= -Iinclude/asm-i386/mach-vmi
+mcore-$(CONFIG_X86_VMI)		:= mach-vmi
+
 # default subarch .h files
 mflags-y += -Iinclude/asm-i386/mach-default
 
@@ -118,6 +122,7 @@
 drivers-$(CONFIG_PM)			+= arch/i386/power/
 
 CFLAGS += $(mflags-y)
+CPPFLAGS += $(mflags-y)
 AFLAGS += $(mflags-y)
 
 boot := arch/i386/boot
diff -Naur linux-2.6.12.3.pristine/arch/i386/boot/compressed/Makefile linux-2.6.12.3-vmi/arch/i386/boot/compressed/Makefile
--- linux-2.6.12.3.pristine/arch/i386/boot/compressed/Makefile	2005-07-15 21:18:57.000000000 +0000
+++ linux-2.6.12.3-vmi/arch/i386/boot/compressed/Makefile	2005-11-15 16:57:30.000000000 +0000
@@ -6,6 +6,7 @@
 
 targets		:= vmlinux vmlinux.bin vmlinux.bin.gz head.o misc.o piggy.o
 EXTRA_AFLAGS	:= -traditional
+EXTRA_CFLAGS	:= -DPRE_VMI
 
 LDFLAGS_vmlinux := -Ttext $(IMAGE_OFFSET) -e startup_32
 
diff -Naur linux-2.6.12.3.pristine/arch/i386/kernel/cpu/common.c linux-2.6.12.3-vmi/arch/i386/kernel/cpu/common.c
--- linux-2.6.12.3.pristine/arch/i386/kernel/cpu/common.c	2005-07-15 21:18:57.000000000 +0000
+++ linux-2.6.12.3-vmi/arch/i386/kernel/cpu/common.c	2005-11-15 16:57:30.000000000 +0000
@@ -388,6 +388,10 @@
 	if ( tsc_disable )
 		clear_bit(X86_FEATURE_TSC, c->x86_capability);
 
+        /* MWAIT disabled? */
+        if (mwait_disable) 
+		clear_bit(X86_FEATURE_MWAIT, c->x86_capability);
+
 	/* FXSR disabled? */
 	if (disable_x86_fxsr) {
 		clear_bit(X86_FEATURE_FXSR, c->x86_capability);
@@ -582,6 +586,11 @@
 		set_in_cr4(X86_CR4_TSD);
 	}
 
+	if (mwait_disable & cpu_has_mwait) {
+		printk(KERN_NOTICE "Disabling MWAIT...\n");
+		clear_bit(X86_FEATURE_MWAIT, boot_cpu_data.x86_capability);
+        }
+
 	/*
 	 * Initialize the per-CPU GDT with the boot GDT,
 	 * and set up the GDT descriptor:
@@ -605,8 +614,8 @@
 	memcpy(thread->tls_array, &per_cpu(cpu_gdt_table, cpu),
 		GDT_ENTRY_TLS_ENTRIES * 8);
 
-	__asm__ __volatile__("lgdt %0" : : "m" (cpu_gdt_descr[cpu]));
-	__asm__ __volatile__("lidt %0" : : "m" (idt_descr));
+	load_gdt(&cpu_gdt_descr[cpu]);
+	load_idt(&idt_descr);
 
 	/*
 	 * Delete NT
@@ -634,12 +643,12 @@
 	asm volatile ("xorl %eax, %eax; movl %eax, %fs; movl %eax, %gs");
 
 	/* Clear all 6 debug registers: */
-
-#define CD(register) __asm__("movl %0,%%db" #register ::"r"(0) );
-
-	CD(0); CD(1); CD(2); CD(3); /* no db4 and db5 */; CD(6); CD(7);
-
-#undef CD
+	clear_debug(0);
+	clear_debug(1);
+	clear_debug(2);
+	clear_debug(3);
+	clear_debug(6);
+	clear_debug(7);
 
 	/*
 	 * Force FPU initialization:
diff -Naur linux-2.6.12.3.pristine/arch/i386/kernel/cpu/cpufreq/longhaul.c linux-2.6.12.3-vmi/arch/i386/kernel/cpu/cpufreq/longhaul.c
--- linux-2.6.12.3.pristine/arch/i386/kernel/cpu/cpufreq/longhaul.c	2005-07-15 21:18:57.000000000 +0000
+++ linux-2.6.12.3-vmi/arch/i386/kernel/cpu/cpufreq/longhaul.c	2005-11-15 16:57:30.000000000 +0000
@@ -64,8 +64,6 @@
 #define dprintk(msg...) cpufreq_debug_printk(CPUFREQ_DEBUG_DRIVER, "longhaul", msg)
 
 
-#define __hlt()     __asm__ __volatile__("hlt": : :"memory")
-
 /* Clock ratios multiplied by 10 */
 static int clock_ratio[32];
 static int eblcr_table[32];
@@ -168,11 +166,9 @@
 	outb(0xFE,0x21);	/* TMR0 only */
 	outb(0xFF,0x80);	/* delay */
 
-	local_irq_enable();
-
-	__hlt();
+	safe_halt();
 	wrmsrl(MSR_VIA_LONGHAUL, longhaul->val);
-	__hlt();
+	halt();
 
 	local_irq_disable();
 
@@ -251,9 +247,7 @@
 		bcr2.bits.CLOCKMUL = clock_ratio_index;
 		local_irq_disable();
 		wrmsrl (MSR_VIA_BCR2, bcr2.val);
-		local_irq_enable();
-
-		__hlt();
+		safe_halt();
 
 		/* Disable software clock multiplier */
 		rdmsrl (MSR_VIA_BCR2, bcr2.val);
diff -Naur linux-2.6.12.3.pristine/arch/i386/kernel/cpu/cyrix.c linux-2.6.12.3-vmi/arch/i386/kernel/cpu/cyrix.c
--- linux-2.6.12.3.pristine/arch/i386/kernel/cpu/cyrix.c	2005-07-15 21:18:57.000000000 +0000
+++ linux-2.6.12.3-vmi/arch/i386/kernel/cpu/cyrix.c	2005-11-15 16:57:30.000000000 +0000
@@ -132,11 +132,7 @@
 	setCx86(CX86_CCR2, getCx86(CX86_CCR2) & ~0x04);
 	/* set 'Not Write-through' */
 	cr0 = 0x20000000;
-	__asm__("movl %%cr0,%%eax\n\t"
-		"orl %0,%%eax\n\t"
-		"movl %%eax,%%cr0\n"
-		: : "r" (cr0)
-		:"ax");
+	write_cr0(read_cr0() | cr0);
 	/* CCR2 bit 2: lock NW bit and set WT1 */
 	setCx86(CX86_CCR2, getCx86(CX86_CCR2) | 0x14 );
 }
diff -Naur linux-2.6.12.3.pristine/arch/i386/kernel/doublefault.c linux-2.6.12.3-vmi/arch/i386/kernel/doublefault.c
--- linux-2.6.12.3.pristine/arch/i386/kernel/doublefault.c	2005-07-15 21:18:57.000000000 +0000
+++ linux-2.6.12.3-vmi/arch/i386/kernel/doublefault.c	2005-11-15 16:57:30.000000000 +0000
@@ -20,7 +20,7 @@
 	struct Xgt_desc_struct gdt_desc = {0, 0};
 	unsigned long gdt, tss;
 
-	__asm__ __volatile__("sgdt %0": "=m" (gdt_desc): :"memory");
+	store_gdt(&gdt_desc);
 	gdt = gdt_desc.address;
 
 	printk("double fault, gdt at %08lx [%d bytes]\n", gdt, gdt_desc.size);
diff -Naur linux-2.6.12.3.pristine/arch/i386/kernel/efi.c linux-2.6.12.3-vmi/arch/i386/kernel/efi.c
--- linux-2.6.12.3.pristine/arch/i386/kernel/efi.c	2005-07-15 21:18:57.000000000 +0000
+++ linux-2.6.12.3-vmi/arch/i386/kernel/efi.c	2005-11-15 16:57:30.000000000 +0000
@@ -78,7 +78,7 @@
 	 * directory. If I have PSE, I just need to duplicate one entry in
 	 * page directory.
 	 */
-	__asm__ __volatile__("movl %%cr4, %0":"=r"(cr4));
+	cr4 = read_cr4();
 
 	if (cr4 & X86_CR4_PSE) {
 		efi_bak_pg_dir_pointer[0].pgd =
@@ -103,8 +103,7 @@
 	local_flush_tlb();
 
 	cpu_gdt_descr[0].address = __pa(cpu_gdt_descr[0].address);
-	__asm__ __volatile__("lgdt %0":"=m"
-			    (*(struct Xgt_desc_struct *) __pa(&cpu_gdt_descr[0])));
+	load_gdt((struct Xgt_desc_struct *) __pa(&cpu_gdt_descr[0]));
 }
 
 static void efi_call_phys_epilog(void)
@@ -113,8 +112,8 @@
 
 	cpu_gdt_descr[0].address =
 		(unsigned long) __va(cpu_gdt_descr[0].address);
-	__asm__ __volatile__("lgdt %0":"=m"(cpu_gdt_descr));
-	__asm__ __volatile__("movl %%cr4, %0":"=r"(cr4));
+	load_gdt(&cpu_gdt_descr);
+	cr4 = read_cr4();
 
 	if (cr4 & X86_CR4_PSE) {
 		swapper_pg_dir[pgd_index(0)].pgd =
diff -Naur linux-2.6.12.3.pristine/arch/i386/kernel/entry.S linux-2.6.12.3-vmi/arch/i386/kernel/entry.S
--- linux-2.6.12.3.pristine/arch/i386/kernel/entry.S	2005-07-15 21:18:57.000000000 +0000
+++ linux-2.6.12.3-vmi/arch/i386/kernel/entry.S	2005-11-15 16:57:30.000000000 +0000
@@ -48,6 +48,7 @@
 #include <asm/smp.h>
 #include <asm/page.h>
 #include <asm/desc.h>
+#include <mach_asm.h>
 #include "irq_vectors.h"
 
 #define nr_syscalls ((syscall_table_size)/4)
@@ -75,8 +76,10 @@
 NT_MASK		= 0x00004000
 VM_MASK		= 0x00020000
 
+.global iret_exc
+
 #ifdef CONFIG_PREEMPT
-#define preempt_stop		cli
+#define preempt_stop		CLI
 #else
 #define preempt_stop
 #define resume_kernel		restore_nocheck
@@ -145,10 +148,11 @@
 	GET_THREAD_INFO(%ebp)
 	movl EFLAGS(%esp), %eax		# mix EFLAGS and CS
 	movb CS(%esp), %al
-	testl $(VM_MASK | 3), %eax
-	jz resume_kernel
+	andl $(VM_MASK | 3), %eax
+	cmpl $3, %eax
+	jb resume_kernel
 ENTRY(resume_userspace)
- 	cli				# make sure we don't miss an interrupt
+ 	CLI				# make sure we don't miss an interrupt
 					# setting need_resched or sigpending
 					# between sampling and the iret
 	movl TI_flags(%ebp), %ecx
@@ -159,7 +163,7 @@
 
 #ifdef CONFIG_PREEMPT
 ENTRY(resume_kernel)
-	cli
+	CLI
 	cmpl $0,TI_preempt_count(%ebp)	# non-zero preempt_count ?
 	jnz restore_nocheck
 need_resched:
@@ -179,7 +183,7 @@
 ENTRY(sysenter_entry)
 	movl TSS_sysenter_esp0(%esp),%esp
 sysenter_past_esp:
-	sti
+	STI
 	pushl $(__USER_DS)
 	pushl %ebp
 	pushfl
@@ -209,7 +213,7 @@
 	jae syscall_badsys
 	call *sys_call_table(,%eax,4)
 	movl %eax,EAX(%esp)
-	cli
+	CLI
 	movl TI_flags(%ebp), %ecx
 	testw $_TIF_ALLWORK_MASK, %cx
 	jne syscall_exit_work
@@ -217,9 +221,7 @@
 	movl EIP(%esp), %edx
 	movl OLDESP(%esp), %ecx
 	xorl %ebp,%ebp
-	sti
-	sysexit
-
+	STI_SYSEXIT
 
 	# system call handler stub
 ENTRY(system_call)
@@ -236,7 +238,7 @@
 	call *sys_call_table(,%eax,4)
 	movl %eax,EAX(%esp)		# store the return value
 syscall_exit:
-	cli				# make sure we don't miss an interrupt
+	CLI				# make sure we don't miss an interrupt
 					# setting need_resched or sigpending
 					# between sampling and the iret
 	movl TI_flags(%ebp), %ecx
@@ -256,10 +258,10 @@
 restore_nocheck:
 	RESTORE_REGS
 	addl $4, %esp
-1:	iret
+1:	IRET
 .section .fixup,"ax"
 iret_exc:
-	sti
+	sti				# not reached in VMI mode
 	pushl $0			# no error code
 	pushl $do_iret_error
 	jmp error_code
@@ -281,14 +283,14 @@
 	 * CPUs, which we can try to work around to make
 	 * dosemu and wine happy. */
 	subl $8, %esp		# reserve space for switch16 pointer
-	cli
+	CLI
 	movl %esp, %eax
 	/* Set up the 16bit stack frame with switch32 pointer on top,
 	 * and a switch16 pointer on top of the current frame. */
 	call setup_x86_bogus_stack
 	RESTORE_REGS
 	lss 20+4(%esp), %esp	# switch to 16bit stack
-1:	iret
+1:	IRET16
 .section __ex_table,"a"
 	.align 4
 	.long 1b,iret_exc
@@ -301,7 +303,7 @@
 	jz work_notifysig
 work_resched:
 	call schedule
-	cli				# make sure we don't miss an interrupt
+	CLI				# make sure we don't miss an interrupt
 					# setting need_resched or sigpending
 					# between sampling and the iret
 	movl TI_flags(%ebp), %ecx
@@ -348,7 +350,7 @@
 syscall_exit_work:
 	testb $(_TIF_SYSCALL_TRACE|_TIF_SYSCALL_AUDIT|_TIF_SINGLESTEP), %cl
 	jz work_pending
-	sti				# could let do_syscall_trace() call
+	STI				# could let do_syscall_trace() call
 					# schedule() instead
 	movl %esp, %eax
 	movl $1, %edx
@@ -379,10 +381,11 @@
 #define UNWIND_ESPFIX_STACK \
 	pushl %eax; \
 	movl %ss, %eax; \
+	MASK_RPL(%eax); \
 	/* see if on 16bit stack */ \
 	cmpw $__ESPFIX_SS, %ax; \
 	jne 28f; \
-	movl $__KERNEL_DS, %edx; \
+	movl $__USER_DS, %edx; \
 	movl %edx, %ds; \
 	movl %edx, %es; \
 	/* switch to 32bit stack */ \
@@ -470,7 +473,7 @@
 ENTRY(device_not_available)
 	pushl $-1			# mark this as an int
 	SAVE_ALL
-	movl %cr0, %eax
+	GET_CR0
 	testl $0x4, %eax		# EM (math emulation bit)
 	jne device_not_available_emulate
 	preempt_stop
@@ -494,6 +497,10 @@
  * We just load the right stack, and push the three (known) values
  * by hand onto the new stack - while updating the return eip past
  * the instruction that would have done it for sysenter.
+ *
+ * N.B. - VMI kernels need these behaviors, but only when running on
+ * real hardware.  Virtual machine implementations should supress
+ * kernel debug traps triggered from user mode.
  */
 #define FIX_STACK(offset, ok, label)		\
 	cmpw $__KERNEL_CS,4(%esp);		\
@@ -527,6 +534,7 @@
 ENTRY(nmi)
 	pushl %eax
 	movl %ss, %eax
+	MASK_RPL(%eax)
 	cmpw $__ESPFIX_SS, %ax
 	popl %eax
 	je nmi_16bit_stack
diff -Naur linux-2.6.12.3.pristine/arch/i386/kernel/head.S linux-2.6.12.3-vmi/arch/i386/kernel/head.S
--- linux-2.6.12.3.pristine/arch/i386/kernel/head.S	2005-07-15 21:18:57.000000000 +0000
+++ linux-2.6.12.3-vmi/arch/i386/kernel/head.S	2005-11-15 16:57:30.000000000 +0000
@@ -402,6 +402,7 @@
 	popl %ecx
 	popl %eax
 #endif
+1:	jmp 1b
 	iret
 
 /*
diff -Naur linux-2.6.12.3.pristine/arch/i386/kernel/ioport.c linux-2.6.12.3-vmi/arch/i386/kernel/ioport.c
--- linux-2.6.12.3.pristine/arch/i386/kernel/ioport.c	2005-07-15 21:18:57.000000000 +0000
+++ linux-2.6.12.3-vmi/arch/i386/kernel/ioport.c	2005-11-15 16:57:30.000000000 +0000
@@ -132,6 +132,7 @@
 	volatile struct pt_regs * regs = (struct pt_regs *) &unused;
 	unsigned int level = regs->ebx;
 	unsigned int old = (regs->eflags >> 12) & 3;
+	struct thread_struct * t = &current->thread;
 
 	if (level > 3)
 		return -EINVAL;
@@ -140,8 +141,8 @@
 		if (!capable(CAP_SYS_RAWIO))
 			return -EPERM;
 	}
-	regs->eflags = (regs->eflags &~ 0x3000UL) | (level << 12);
-	/* Make sure we return the long way (not sysenter) */
-	set_thread_flag(TIF_IRET);
+	t->iopl = level << 12;
+	regs->eflags = (regs->eflags & ~X86_EFLAGS_IOPL) | t->iopl;
+	set_iopl_mask(t->iopl);
 	return 0;
 }
diff -Naur linux-2.6.12.3.pristine/arch/i386/kernel/microcode.c linux-2.6.12.3-vmi/arch/i386/kernel/microcode.c
--- linux-2.6.12.3.pristine/arch/i386/kernel/microcode.c	2005-07-15 21:18:57.000000000 +0000
+++ linux-2.6.12.3-vmi/arch/i386/kernel/microcode.c	2005-11-15 16:57:30.000000000 +0000
@@ -164,7 +164,8 @@
 	}
 
 	wrmsr(MSR_IA32_UCODE_REV, 0, 0);
-	__asm__ __volatile__ ("cpuid" : : : "ax", "bx", "cx", "dx");
+	/* XXX needed? wrmsr should serialize unless a chip bug */
+	serialize(); 
 	/* get the current revision from MSR 0x8B */
 	rdmsr(MSR_IA32_UCODE_REV, val[0], uci->rev);
 	pr_debug("microcode: collect_cpu_info : sig=0x%x, pf=0x%x, rev=0x%x\n",
@@ -377,7 +378,9 @@
 		(unsigned long) uci->mc->bits >> 16 >> 16);
 	wrmsr(MSR_IA32_UCODE_REV, 0, 0);
 
-	__asm__ __volatile__ ("cpuid" : : : "ax", "bx", "cx", "dx");
+	/* XXX needed? wrmsr should serialize unless a chip bug */
+	serialize(); 
+
 	/* get the current revision from MSR 0x8B */
 	rdmsr(MSR_IA32_UCODE_REV, val[0], val[1]);
 
diff -Naur linux-2.6.12.3.pristine/arch/i386/kernel/pci-dma.c linux-2.6.12.3-vmi/arch/i386/kernel/pci-dma.c
--- linux-2.6.12.3.pristine/arch/i386/kernel/pci-dma.c	2005-07-15 21:18:57.000000000 +0000
+++ linux-2.6.12.3-vmi/arch/i386/kernel/pci-dma.c	2005-11-15 16:57:30.000000000 +0000
@@ -50,7 +50,7 @@
 
 	if (ret != NULL) {
 		memset(ret, 0, size);
-		*dma_handle = virt_to_phys(ret);
+		*dma_handle = virt_to_bus(ret); // VU: virt_to_phys->virt_to_bus
 	}
 	return ret;
 }
diff -Naur linux-2.6.12.3.pristine/arch/i386/kernel/process.c linux-2.6.12.3-vmi/arch/i386/kernel/process.c
--- linux-2.6.12.3.pristine/arch/i386/kernel/process.c	2005-07-15 21:18:57.000000000 +0000
+++ linux-2.6.12.3-vmi/arch/i386/kernel/process.c	2005-11-15 16:57:30.000000000 +0000
@@ -220,7 +220,7 @@
 
 void __init select_idle_routine(const struct cpuinfo_x86 *c)
 {
-	if (cpu_has(c, X86_FEATURE_MWAIT)) {
+	if (cpu_has(c, X86_FEATURE_MWAIT) && !mwait_disable) {
 		printk("monitor/mwait feature present.\n");
 		/*
 		 * Skip, if setup has overridden idle.
@@ -262,7 +262,7 @@
 	printk("EIP: %04x:[<%08lx>] CPU: %d\n",0xffff & regs->xcs,regs->eip, smp_processor_id());
 	print_symbol("EIP is at %s\n", regs->eip);
 
-	if (regs->xcs & 3)
+	if (user_mode(regs))
 		printk(" ESP: %04x:%08lx",0xffff & regs->xss,regs->esp);
 	printk(" EFLAGS: %08lx    %s  (%s)\n",
 	       regs->eflags, print_tainted(), system_utsname.release);
@@ -273,16 +273,12 @@
 	printk(" DS: %04x ES: %04x\n",
 		0xffff & regs->xds,0xffff & regs->xes);
 
-	__asm__("movl %%cr0, %0": "=r" (cr0));
-	__asm__("movl %%cr2, %0": "=r" (cr2));
-	__asm__("movl %%cr3, %0": "=r" (cr3));
-	/* This could fault if %cr4 does not exist */
-	__asm__("1: movl %%cr4, %0		\n"
-		"2:				\n"
-		".section __ex_table,\"a\"	\n"
-		".long 1b,2b			\n"
-		".previous			\n"
-		: "=r" (cr4): "0" (0));
+	cr0 = read_cr0();
+	cr2 = read_cr2();
+	cr3 = read_cr3();
+	if (current_cpu_data.x86 > 4) {
+		cr4 = read_cr4();
+	}
 	printk("CR0: %08lx CR2: %08lx CR3: %08lx CR4: %08lx\n", cr0, cr2, cr3, cr4);
 	show_trace(NULL, &regs->esp);
 }
@@ -319,7 +315,7 @@
 	regs.xes = __USER_DS;
 	regs.orig_eax = -1;
 	regs.eip = (unsigned long) kernel_thread_helper;
-	regs.xcs = __KERNEL_CS;
+	regs.xcs = make_kernel_segment(__KERNEL_CS);
 	regs.eflags = X86_EFLAGS_IF | X86_EFLAGS_SF | X86_EFLAGS_PF | 0x2;
 
 	/* Ok, create the new process.. */
@@ -599,21 +595,26 @@
 	__unlazy_fpu(prev_p);
 
 	/*
-	 * Reload esp0, LDT and the page table pointer:
+	 * Reload esp0.
 	 */
 	load_esp0(tss, next);
 
 	/*
-	 * Load the per-thread Thread-Local Storage descriptor.
+	 * Save away %fs and %gs. No need to save %es and %ds, as
+	 * those are always kernel segments while inside the kernel.
+	 * Doing this before setting the new TLS descriptors avoids
+	 * the situation where we temporarily have non-reloadable
+	 * segments in %fs and %gs.  This could be an issue if the
+	 * NMI handler ever used %fs or %gs (it does not today), or
+	 * if the kernel is running inside of a hypervisor layer.
 	 */
-	load_TLS(next, cpu);
+	savesegment(fs, prev->fs);
+	savesegment(gs, prev->gs);
 
 	/*
-	 * Save away %fs and %gs. No need to save %es and %ds, as
-	 * those are always kernel segments while inside the kernel.
+	 * Load the per-thread Thread-Local Storage descriptor.
 	 */
-	asm volatile("mov %%fs,%0":"=m" (prev->fs));
-	asm volatile("mov %%gs,%0":"=m" (prev->gs));
+	load_TLS(next, cpu);
 
 	/*
 	 * Restore %fs and %gs if needed.
@@ -624,6 +625,13 @@
 	}
 
 	/*
+	 * Restore IOPL if needed.
+	 */
+	if (unlikely(prev->iopl != next->iopl)) {
+		set_iopl_mask(next->iopl);
+	}
+
+	/*
 	 * Now maybe reload the debug registers
 	 */
 	if (unlikely(next->debugreg[7])) {
@@ -636,8 +644,10 @@
 		loaddebug(next, 7);
 	}
 
-	if (unlikely(prev->io_bitmap_ptr || next->io_bitmap_ptr))
+	if (unlikely(prev->io_bitmap_ptr || next->io_bitmap_ptr)) {
 		handle_io_bitmap(next, tss);
+		mach_update_io_bitmap(tss);
+	}
 
 	return prev_p;
 }
diff -Naur linux-2.6.12.3.pristine/arch/i386/kernel/reboot.c linux-2.6.12.3-vmi/arch/i386/kernel/reboot.c
--- linux-2.6.12.3.pristine/arch/i386/kernel/reboot.c	2005-07-15 21:18:57.000000000 +0000
+++ linux-2.6.12.3-vmi/arch/i386/kernel/reboot.c	2005-11-15 16:57:30.000000000 +0000
@@ -12,6 +12,7 @@
 #include <linux/dmi.h>
 #include <asm/uaccess.h>
 #include <asm/apic.h>
+#include <asm/desc.h>
 #include "mach_reboot.h"
 #include <linux/reboot_fixups.h>
 
@@ -266,13 +267,13 @@
 
 	/* Set up the IDT for real mode. */
 
-	__asm__ __volatile__ ("lidt %0" : : "m" (real_mode_idt));
+	load_idt(&real_mode_idt);
 
 	/* Set up a GDT from which we can load segment descriptors for real
 	   mode.  The GDT is not used in real mode; it is just needed here to
 	   prepare the descriptors. */
 
-	__asm__ __volatile__ ("lgdt %0" : : "m" (real_mode_gdt));
+	load_gdt(&real_mode_gdt);
 
 	/* Load the data segment registers, and thus the descriptors ready for
 	   real mode.  The base address of each segment is 0x100, 16 times the
@@ -325,7 +326,7 @@
 	   and if we are not running on the reboot_cpu,, halt */
 	if ((reboot_cpu != -1) && (cpuid != reboot_cpu)) {
 		for (;;)
-		__asm__ __volatile__ ("hlt");
+			halt();
 	}
 	/*
 	 * Stop all CPUs and turn off local APICs and the IO-APIC, so
@@ -343,7 +344,7 @@
 	if (!reboot_thru_bios) {
 		if (efi_enabled) {
 			efi.reset_system(EFI_RESET_COLD, EFI_SUCCESS, 0, NULL);
-			__asm__ __volatile__("lidt %0": :"m" (no_idt));
+			load_idt(&no_idt);
 			__asm__ __volatile__("int3");
 		}
 		/* rebooting needs to touch the page at absolute addr 0 */
@@ -352,7 +353,7 @@
 			mach_reboot_fixups(); /* for board specific fixups */
 			mach_reboot();
 			/* That didn't work - force a triple fault.. */
-			__asm__ __volatile__("lidt %0": :"m" (no_idt));
+			load_idt(&no_idt);
 			__asm__ __volatile__("int3");
 		}
 	}
diff -Naur linux-2.6.12.3.pristine/arch/i386/kernel/setup.c linux-2.6.12.3-vmi/arch/i386/kernel/setup.c
--- linux-2.6.12.3.pristine/arch/i386/kernel/setup.c	2005-07-15 21:18:57.000000000 +0000
+++ linux-2.6.12.3-vmi/arch/i386/kernel/setup.c	2005-11-16 12:25:35.000000000 +0000
@@ -59,6 +59,7 @@
 unsigned long init_pg_tables_end __initdata = ~0UL;
 
 int disable_pse __initdata = 0;
+int mwait_disable __initdata = 0;
 
 /*
  * Machine setup..
@@ -75,6 +76,7 @@
 struct cpuinfo_x86 boot_cpu_data = { 0, 0, 0, 0, -1, 1, 0, 0, -1 };
 
 unsigned long mmu_cr4_features;
+EXPORT_SYMBOL(mmu_cr4_features);
 
 #ifdef	CONFIG_ACPI_INTERPRETER
 	int acpi_disabled = 0;
@@ -391,7 +393,6 @@
 static void __init print_memory_map(char *who)
 {
 	int i;
-
 	for (i = 0; i < e820.nr_map; i++) {
 		printk(" %s: %016Lx - %016Lx ", who,
 			e820.map[i].addr,
@@ -1474,6 +1475,9 @@
 	smp_alloc_memory(); /* AP processor realmode stacks in low memory*/
 #endif
 	paging_init();
+#ifdef CONFIG_X86_VMI
+	//vmi_init();
+#endif
 	remapped_pgdat_init();
 	zone_sizes_init();
 
@@ -1493,7 +1497,6 @@
 	}
 #endif
 
-
 	dmi_scan_machine();
 
 #ifdef CONFIG_X86_GENERICARCH
diff -Naur linux-2.6.12.3.pristine/arch/i386/kernel/signal.c linux-2.6.12.3-vmi/arch/i386/kernel/signal.c
--- linux-2.6.12.3.pristine/arch/i386/kernel/signal.c	2005-07-15 21:18:57.000000000 +0000
+++ linux-2.6.12.3-vmi/arch/i386/kernel/signal.c	2005-11-15 16:57:30.000000000 +0000
@@ -278,9 +278,9 @@
 	int tmp, err = 0;
 
 	tmp = 0;
-	__asm__("movl %%gs,%0" : "=r"(tmp): "0"(tmp));
+	savesegment(gs, tmp);
 	err |= __put_user(tmp, (unsigned int __user *)&sc->gs);
-	__asm__("movl %%fs,%0" : "=r"(tmp): "0"(tmp));
+	savesegment(fs, tmp);
 	err |= __put_user(tmp, (unsigned int __user *)&sc->fs);
 
 	err |= __put_user(regs->xes, (unsigned int __user *)&sc->es);
@@ -597,9 +597,11 @@
 	 * We want the common case to go fast, which
 	 * is why we may in certain cases get here from
 	 * kernel mode. Just return without doing anything
-	 * if so.
+	 * if so.  vm86 regs switched out by assembly code
+	 * before reaching here, so testing against kernel
+	 * CS suffices.
 	 */
-	if ((regs->xcs & 3) != 3)
+	if (is_kernel_cs(regs->xcs))
 		return 1;
 
 	if (current->flags & PF_FREEZE) {
diff -Naur linux-2.6.12.3.pristine/arch/i386/kernel/smp.c linux-2.6.12.3-vmi/arch/i386/kernel/smp.c
--- linux-2.6.12.3.pristine/arch/i386/kernel/smp.c	2005-07-15 21:18:57.000000000 +0000
+++ linux-2.6.12.3-vmi/arch/i386/kernel/smp.c	2005-11-15 16:57:30.000000000 +0000
@@ -557,7 +557,7 @@
 	local_irq_disable();
 	disable_local_APIC();
 	if (cpu_data[smp_processor_id()].hlt_works_ok)
-		for(;;) __asm__("hlt");
+		for(;;) halt();
 	for (;;);
 }
 
diff -Naur linux-2.6.12.3.pristine/arch/i386/kernel/timers/timer_tsc.c linux-2.6.12.3-vmi/arch/i386/kernel/timers/timer_tsc.c
--- linux-2.6.12.3.pristine/arch/i386/kernel/timers/timer_tsc.c	2005-07-15 21:18:57.000000000 +0000
+++ linux-2.6.12.3-vmi/arch/i386/kernel/timers/timer_tsc.c	2005-11-15 16:57:30.000000000 +0000
@@ -157,6 +157,7 @@
 
 static void delay_tsc(unsigned long loops)
 {
+#ifndef CONFIG_NO_UDELAY
 	unsigned long bclock, now;
 	
 	rdtscl(bclock);
@@ -165,6 +166,7 @@
 		rep_nop();
 		rdtscl(now);
 	} while ((now-bclock) < loops);
+#endif
 }
 
 #ifdef CONFIG_HPET_TIMER
diff -Naur linux-2.6.12.3.pristine/arch/i386/kernel/traps.c linux-2.6.12.3-vmi/arch/i386/kernel/traps.c
--- linux-2.6.12.3.pristine/arch/i386/kernel/traps.c	2005-07-15 21:18:57.000000000 +0000
+++ linux-2.6.12.3-vmi/arch/i386/kernel/traps.c	2005-11-15 16:57:30.000000000 +0000
@@ -208,8 +208,8 @@
 	unsigned short ss;
 
 	esp = (unsigned long) (&regs->esp);
-	ss = __KERNEL_DS;
-	if (regs->xcs & 3) {
+	ss = get_current_ss();
+	if (user_mode(regs)) {
 		in_kernel = 0;
 		esp = regs->esp;
 		ss = regs->xss & 0xffff;
@@ -265,9 +265,6 @@
 	char c;
 	unsigned long eip;
 
-	if (regs->xcs & 3)
-		goto no_bug;		/* Not in kernel */
-
 	eip = regs->eip;
 
 	if (eip < PAGE_OFFSET)
@@ -353,7 +350,7 @@
 
 static inline void die_if_kernel(const char * str, struct pt_regs * regs, long err)
 {
-	if (!(regs->eflags & VM_MASK) && !(3 & regs->xcs))
+	if (!user_mode(regs))
 		die(str, regs, err);
 }
 
@@ -366,7 +363,7 @@
 		goto trap_signal;
 	}
 
-	if (!(regs->xcs & 3))
+	if (is_kernel_cs((regs->xcs)))
 		goto kernel_trap;
 
 	trap_signal: {
@@ -488,7 +485,7 @@
 	if (regs->eflags & VM_MASK)
 		goto gp_in_vm86;
 
-	if (!(regs->xcs & 3))
+	if (is_kernel_cs(regs->xcs))
 		goto gp_in_kernel;
 
 	current->thread.error_code = error_code;
@@ -682,7 +679,7 @@
 	unsigned int condition;
 	struct task_struct *tsk = current;
 
-	__asm__ __volatile__("movl %%db6,%0" : "=r" (condition));
+	condition = read_debug(6);
 
 	if (notify_die(DIE_DEBUG, "debug", regs, condition, error_code,
 					SIGTRAP) == NOTIFY_STOP)
@@ -713,7 +710,7 @@
 		 * check for kernel mode by just checking the CPL
 		 * of CS.
 		 */
-		if ((regs->xcs & 3) == 0)
+		if (is_kernel_cs(regs->xcs))
 			goto clear_TF_reenable;
 	}
 
@@ -724,9 +721,7 @@
 	 * the signal is delivered.
 	 */
 clear_dr7:
-	__asm__("movl %0,%%db7"
-		: /* no output */
-		: "r" (0));
+	clear_debug(7);
 	return;
 
 debug_vm86:
@@ -907,10 +902,10 @@
 	memcpy((void *)(stack_bot + iret_frame16_off), &regs->eip, 20);
 	/* fill in the switch pointers */
 	switch16_ptr[0] = (regs->esp & 0xffff0000) | iret_frame16_off;
-	switch16_ptr[1] = __ESPFIX_SS;
+	switch16_ptr[1] = make_kernel_segment(__ESPFIX_SS);
 	switch32_ptr[0] = (unsigned long)stk + sizeof(struct pt_regs) +
 		8 - CPU_16BIT_STACK_SIZE;
-	switch32_ptr[1] = __KERNEL_DS;
+	switch32_ptr[1] = make_kernel_segment(__KERNEL_DS);
 }
 
 fastcall unsigned char * fixup_x86_bogus_stack(unsigned short sp)
@@ -976,7 +971,7 @@
 	 * it uses the read-only mapped virtual address.
 	 */
 	idt_descr.address = fix_to_virt(FIX_F00F_IDT);
-	__asm__ __volatile__("lidt %0" : : "m" (idt_descr));
+	load_idt(&idt_descr);
 }
 #endif
 
diff -Naur linux-2.6.12.3.pristine/arch/i386/kernel/vm86.c linux-2.6.12.3-vmi/arch/i386/kernel/vm86.c
--- linux-2.6.12.3.pristine/arch/i386/kernel/vm86.c	2005-07-15 21:18:57.000000000 +0000
+++ linux-2.6.12.3-vmi/arch/i386/kernel/vm86.c	2005-11-15 16:57:30.000000000 +0000
@@ -294,8 +294,8 @@
  */
 	info->regs32->eax = 0;
 	tsk->thread.saved_esp0 = tsk->thread.esp0;
-	asm volatile("mov %%fs,%0":"=m" (tsk->thread.saved_fs));
-	asm volatile("mov %%gs,%0":"=m" (tsk->thread.saved_gs));
+	savesegment(fs, tsk->thread.saved_fs);
+	savesegment(gs, tsk->thread.saved_gs);
 
 	tss = &per_cpu(init_tss, get_cpu());
 	tsk->thread.esp0 = (unsigned long) &info->VM86_TSS_ESP0;
diff -Naur linux-2.6.12.3.pristine/arch/i386/kernel/vmlinux.lds.S linux-2.6.12.3-vmi/arch/i386/kernel/vmlinux.lds.S
--- linux-2.6.12.3.pristine/arch/i386/kernel/vmlinux.lds.S	2005-07-15 21:18:57.000000000 +0000
+++ linux-2.6.12.3-vmi/arch/i386/kernel/vmlinux.lds.S	2005-11-15 16:57:30.000000000 +0000
@@ -2,7 +2,7 @@
  * Written by Martin Mares <mj@atrey.karlin.mff.cuni.cz>;
  */
 
-#include <asm-generic/vmlinux.lds.h>
+#include <asm/vmlinux.lds.h>
 #include <asm/thread_info.h>
 #include <asm/page.h>
 
@@ -22,7 +22,7 @@
 	*(.fixup)
 	*(.gnu.warning)
 	} = 0x9090
-
+  MACH_TEXT
   _etext = .;			/* End of text section */
 
   . = ALIGN(16);		/* Exception table */
diff -Naur linux-2.6.12.3.pristine/arch/i386/mach-vmi/Makefile linux-2.6.12.3-vmi/arch/i386/mach-vmi/Makefile
--- linux-2.6.12.3.pristine/arch/i386/mach-vmi/Makefile	1970-01-01 00:00:00.000000000 +0000
+++ linux-2.6.12.3-vmi/arch/i386/mach-vmi/Makefile	2005-11-15 16:57:30.000000000 +0000
@@ -0,0 +1,11 @@
+#
+# Makefile for the linux kernel.
+#
+
+EXTRA_CFLAGS	+= -I../kernel
+
+export CFLAGS_stubs.o += -ffunction-sections
+
+obj-y				:= reboot.o setup.o stubs.o stubs-asm.o \
+				   exports.o
+obj-$(CONFIG_DEBUG_VMI)		+= debug.o
diff -Naur linux-2.6.12.3.pristine/arch/i386/mach-vmi/debug.c linux-2.6.12.3-vmi/arch/i386/mach-vmi/debug.c
--- linux-2.6.12.3.pristine/arch/i386/mach-vmi/debug.c	1970-01-01 00:00:00.000000000 +0000
+++ linux-2.6.12.3-vmi/arch/i386/mach-vmi/debug.c	2005-11-15 16:57:30.000000000 +0000
@@ -0,0 +1,99 @@
+/*
+ * vmi/debug.c
+ *
+ * Copyright (c) 2005, VMware, Inc.
+ * All rights reserved.
+ *
+ */
+
+#include <linux/config.h>
+#include <linux/smp.h>
+#include <linux/init.h>
+#include <linux/irq.h>
+#include <linux/interrupt.h>
+#include <linux/bootmem.h>
+#include <linux/mm.h>
+#include <asm/acpi.h>
+#include <asm/arch_hooks.h>
+#include <asm/processor.h>
+#include <asm/desc.h>
+#include <asm/io.h>
+#include <asm/highmem.h>
+#include <vmi.h>
+
+void vmi_debug(void)
+{
+	void *data_area = (void *)alloc_bootmem_low_pages(PAGE_SIZE);
+	void *page_area = (void *)alloc_bootmem_low_pages(PAGE_SIZE);
+	VMI_UINT32 ppn;
+	VMI_PTE *ptep = (VMI_PTE *)page_area;
+	VMI_PTE pteval, ptenew, pteold;
+	VMI_PAE_PTE *paep = (VMI_PAE_PTE *)page_area;
+	VMI_PAE_PTE paeval, paenew, paeold, paenp;
+	int bit;
+	
+	printk("Testing VMI...");
+	vmi_SetDeferredMode(VMI_DEFER_NONE);
+
+	ppn = __pa(page_area) >> PAGE_SHIFT;
+	vmi_RegisterPageUsage(ppn, VMI_PAGE_PT);
+	vmi_ReleasePage(ppn, VMI_PAGE_PT);
+
+	vmi_RegisterPageUsage(ppn, VMI_PAGE_PT);
+	ppn = __pa(data_area) >> PAGE_SHIFT;
+	pteval = (ppn << PAGE_SHIFT) | _PAGE_PRESENT | _PAGE_USER;
+	vmi_SetPte(pteval, ptep);
+	BUG_ON(*ptep != pteval);
+	
+	bit = vmi_TestAndClearPteBit(0, ptep);
+	BUG_ON(!bit);
+	BUG_ON(*ptep != (pteval & ~1));
+
+	bit = vmi_TestAndSetPteBit(0, ptep);
+	BUG_ON(bit);
+	BUG_ON(*ptep != pteval);
+
+	ppn = __pa(page_area) >> PAGE_SHIFT;
+	ptenew = (ppn << PAGE_SHIFT) | _PAGE_PRESENT;
+	pteold = vmi_SwapPte(ptenew, ptep);
+	BUG_ON(pteold != pteval);
+	BUG_ON(*ptep != ptenew);
+
+	vmi_ReleasePage(ppn, VMI_PAGE_PT);
+
+	/* Now PAE */
+	ppn = __pa(page_area) >> PAGE_SHIFT;
+	vmi_RegisterPageUsage(ppn, VMI_PAGE_PAE_PT);
+	vmi_ReleasePage(ppn, VMI_PAGE_PAE_PT);
+
+	vmi_RegisterPageUsage(ppn, VMI_PAGE_PAE_PT);
+	ppn = __pa(data_area) >> PAGE_SHIFT;
+	paeval = ((unsigned long long)ppn << PAGE_SHIFT) | _PAGE_PRESENT | _PAGE_USER;
+	vmi_SetPteLong(paeval, paep);
+	BUG_ON(*paep != paeval);
+	
+	bit = vmi_TestAndClearPteBitLong(0, paep);
+	BUG_ON(!bit);
+	BUG_ON(*paep != (paeval & ~1));
+
+	bit = vmi_TestAndSetPteBitLong(0, paep);
+	BUG_ON(bit);
+	BUG_ON(*paep != paeval);
+
+	ppn = __pa(page_area) >> PAGE_SHIFT;
+	paenew = (ppn << PAGE_SHIFT) | _PAGE_PRESENT;
+	paeold = vmi_SwapPteLong(paenew, paep);
+	BUG_ON(paeold != paeval);
+	BUG_ON(*paep != paenew);
+
+	paenp = 0xb0b0b0b0b0b0b0b0ULL;
+	paeold = vmi_SwapPteLong(paenp, paep);
+	BUG_ON(paeold != paenew);
+	BUG_ON(*paep != paenp);
+
+	vmi_SetPteLong(0, paep);
+	BUG_ON(*paep != 0);
+
+	vmi_ReleasePage(ppn, VMI_PAGE_PT);
+	printk(" passed.\n");
+}
diff -Naur linux-2.6.12.3.pristine/arch/i386/mach-vmi/exports.c linux-2.6.12.3-vmi/arch/i386/mach-vmi/exports.c
--- linux-2.6.12.3.pristine/arch/i386/mach-vmi/exports.c	1970-01-01 00:00:00.000000000 +0000
+++ linux-2.6.12.3-vmi/arch/i386/mach-vmi/exports.c	2005-11-15 16:57:30.000000000 +0000
@@ -0,0 +1,55 @@
+/*
+ * Copyright (C) 2005, VMware, Inc.
+ *
+ * All rights reserved.
+ *
+ * This program is free software; you can redistribute it and/or modify
+ * it under the terms of the GNU General Public License as published by
+ * the Free Software Foundation; either version 2 of the License, or
+ * (at your option) any later version.
+ *
+ * This program is distributed in the hope that it will be useful, but
+ * WITHOUT ANY WARRANTY; without even the implied warranty of
+ * MERCHANTABILITY OR FITNESS FOR A PARTICULAR PURPOSE, GOOD TITLE or
+ * NON INFRINGEMENT.  See the GNU General Public License for more
+ * details.
+ *
+ * You should have received a copy of the GNU General Public License
+ * along with this program; if not, write to the Free Software
+ * Foundation, Inc., 675 Mass Ave, Cambridge, MA 02139, USA.
+ *
+ * Send feedback to zach@vmware.com
+ *
+ */
+
+#include <linux/config.h>
+#include <asm/processor.h>
+#include <asm/bitops.h>
+#include <vmi.h>
+#include <linux/module.h>
+
+#define VMI_SPACE(kind)
+#define VMI_FUNC(call, ...) \
+	extern int VMI_##call(void); \
+	EXPORT_SYMBOL(VMI_##call); 
+#define VMI_PROC(call, ...) \
+	extern void VMI_##call(void); \
+	EXPORT_SYMBOL(VMI_##call); 
+#define VMI_JUMP(call, ...) \
+	extern void __attribute__((noreturn)) VMI_##call(void); \
+	EXPORT_SYMBOL(VMI_##call); 
+
+/* Export all VMI symbols to modules */
+VMI_CALLS
+VMI_PROC(Inb)
+VMI_PROC(Inw)
+VMI_PROC(Inl)
+VMI_PROC(Insb)
+VMI_PROC(Insw)
+VMI_PROC(Insl)
+VMI_PROC(Outb)
+VMI_PROC(Outw)
+VMI_PROC(Outl)
+VMI_PROC(Outsb)
+VMI_PROC(Outsw)
+VMI_PROC(Outsl)
diff -Naur linux-2.6.12.3.pristine/arch/i386/mach-vmi/reboot.c linux-2.6.12.3-vmi/arch/i386/mach-vmi/reboot.c
--- linux-2.6.12.3.pristine/arch/i386/mach-vmi/reboot.c	1970-01-01 00:00:00.000000000 +0000
+++ linux-2.6.12.3-vmi/arch/i386/mach-vmi/reboot.c	2005-11-15 16:57:30.000000000 +0000
@@ -0,0 +1,51 @@
+/*
+ * Copyright (C) 2005, VMware, Inc.
+ *
+ * All rights reserved.
+ *
+ * This program is free software; you can redistribute it and/or modify
+ * it under the terms of the GNU General Public License as published by
+ * the Free Software Foundation; either version 2 of the License, or
+ * (at your option) any later version.
+ *
+ * This program is distributed in the hope that it will be useful, but
+ * WITHOUT ANY WARRANTY; without even the implied warranty of
+ * MERCHANTABILITY OR FITNESS FOR A PARTICULAR PURPOSE, GOOD TITLE or
+ * NON INFRINGEMENT.  See the GNU General Public License for more
+ * details.
+ *
+ * You should have received a copy of the GNU General Public License
+ * along with this program; if not, write to the Free Software
+ * Foundation, Inc., 675 Mass Ave, Cambridge, MA 02139, USA.
+ *
+ * Send feedback to zach@vmware.com
+ *
+ */
+
+
+#include <linux/module.h>
+#include <linux/init.h>
+
+void machine_restart(char * __unused)
+{
+	vmi_Reboot(VMI_REBOOT_HARD);
+}
+
+EXPORT_SYMBOL(machine_restart);
+
+void machine_halt(void)
+{
+	vmi_Shutdown();
+}
+
+EXPORT_SYMBOL(machine_halt);
+
+void machine_power_off(void)
+{
+	vmi_Shutdown();
+}
+
+void (*pm_power_off)(void) = machine_power_off;
+
+EXPORT_SYMBOL(machine_power_off);
+
diff -Naur linux-2.6.12.3.pristine/arch/i386/mach-vmi/setup.c linux-2.6.12.3-vmi/arch/i386/mach-vmi/setup.c
--- linux-2.6.12.3.pristine/arch/i386/mach-vmi/setup.c	1970-01-01 00:00:00.000000000 +0000
+++ linux-2.6.12.3-vmi/arch/i386/mach-vmi/setup.c	2005-11-15 16:57:30.000000000 +0000
@@ -0,0 +1,198 @@
+/*
+ * Machine specific setup for generic
+ *
+ * Copyright (C) 2005, VMware, Inc.
+ *
+ * All rights reserved.
+ *
+ * This program is free software; you can redistribute it and/or modify
+ * it under the terms of the GNU General Public License as published by
+ * the Free Software Foundation; either version 2 of the License, or
+ * (at your option) any later version.
+ *
+ * This program is distributed in the hope that it will be useful, but
+ * WITHOUT ANY WARRANTY; without even the implied warranty of
+ * MERCHANTABILITY OR FITNESS FOR A PARTICULAR PURPOSE, GOOD TITLE or
+ * NON INFRINGEMENT.  See the GNU General Public License for more
+ * details.
+ *
+ * You should have received a copy of the GNU General Public License
+ * along with this program; if not, write to the Free Software
+ * Foundation, Inc., 675 Mass Ave, Cambridge, MA 02139, USA.
+ *
+ * Send feedback to zach@vmware.com
+ *
+ */
+
+#include <linux/config.h>
+#include <linux/smp.h>
+#include <linux/init.h>
+#include <linux/irq.h>
+#include <linux/interrupt.h>
+#include <linux/bootmem.h>
+#include <linux/mm.h>
+#include <asm/acpi.h>
+#include <asm/arch_hooks.h>
+#include <asm/processor.h>
+#include <asm/desc.h>
+#include <asm/io.h>
+#include <asm/highmem.h>
+#include <paravirtualInterface.h>
+
+extern char __VMI_END;
+extern char __VMI_START;
+extern char __VMI_SHARED;
+static VROMHeader *vmi_rom = NULL;
+
+extern unsigned long max_low_pfn;
+
+extern void vmi_debug(void);
+
+/**
+ * pre_intr_init_hook - initialisation prior to setting up interrupt vectors
+ *
+ * Description:
+ *	Perform any necessary interrupt initialisation prior to setting up
+ *	the "ordinary" interrupt call gates.  For legacy reasons, the ISA
+ *	interrupts should be initialised here if the machine emulates a PC
+ *	in any way.
+ **/
+void __init pre_intr_init_hook(void)
+{
+	init_ISA_irqs();
+}
+
+/*
+ * IRQ2 is cascade interrupt to second interrupt controller
+ */
+static struct irqaction irq2 = { no_action, 0, CPU_MASK_NONE, "cascade", NULL, NULL};
+
+/**
+ * intr_init_hook - post gate setup interrupt initialisation
+ *
+ * Description:
+ *	Fill in any interrupts that may have been left out by the general
+ *	init_IRQ() routine.  interrupts having to do with the machine rather
+ *	than the devices on the I/O bus (like APIC interrupts in intel MP
+ *	systems) are started here.
+ **/
+void __init intr_init_hook(void)
+{
+#ifdef CONFIG_X86_LOCAL_APIC
+	apic_intr_init();
+#endif
+
+	setup_irq(2, &irq2);
+}
+
+/*
+ * Probe for the VMI option ROM
+ */
+void __init probe_vmi_rom(void)
+{
+	unsigned long base;
+
+	/* VMI ROM is in option ROM area, check signature */
+	for (base = 0xC0000; base < 0xE0000; base += 2048) {
+		VROMHeader *romstart;
+		romstart = (VROMHeader *)isa_bus_to_virt(base);
+		if (romstart->romSignature != 0xaa55)
+			continue;
+		if (romstart->vRomSignature == VMI_SIGNATURE && !vmi_rom) {
+			printk("Detected VMI ROM API version %d.%d\n",
+				romstart->APIVersionMajor,
+				romstart->APIVersionMinor);
+			if (romstart->APIVersionMajor != VMI_API_REV_MAJOR ||
+			    romstart->APIVersionMinor < VMI_MIN_API_REV_MINOR) {
+				continue;
+			}
+			if (romstart->romLength * 512 > 
+					&__VMI_END - &__VMI_START) {
+				panic("VMI OPROM size exceeds mappable space\n");
+			}
+			vmi_rom = romstart;
+			continue;
+		}
+	}
+}
+
+
+/*
+ * Activate the VMI interfaces
+ */
+void __init vmi_init(void)
+{
+	int romsize;
+
+	/*
+	 * Setup optional callback functions if we found the VMI ROM
+	 */
+	if (vmi_rom) {
+		unsigned long dsize = vmi_rom->dataPages * PAGE_SIZE;
+		__u32 data_area = dsize ? (__u32)alloc_bootmem_low_pages(dsize) : 0;
+		romsize = vmi_rom->romLength * 512;
+		unsigned retval;
+		__asm__("call *%2" :
+			"=a" (retval) :
+			"0" (__pa(data_area)),
+			"r" (&vmi_rom->vromCall[VMI_CALL_Init]));
+		if (retval) {
+			printk(KERN_WARNING "VMI ROM failed to initialize\n");
+			vmi_rom = NULL;
+		} else {
+			memcpy(&__VMI_START, (char *)vmi_rom, romsize);
+			vmi_SetDeferredMode(VMI_DEFER_MMU);
+			vmi_RegisterPageMapping(PAGE_OFFSET, 0, max_low_pfn);
+		}
+	}
+	if (!vmi_rom) {
+		printk(KERN_WARNING "VMI ROM version mismatch "
+			" - falling back to stub mode\n");
+	}
+#ifdef CONFIG_DEBUG_VMI
+	vmi_debug();
+#endif
+}
+
+
+/**
+ * pre_setup_arch_hook - hook called prior to any setup_arch() execution
+ *
+ * Description:
+ *	generally used to activate any machine specific identification
+ *	routines that may be needed before setup_arch() runs. 
+ *      We probe for various component option ROMs here.
+ **/
+void __init pre_setup_arch_hook(void)
+{
+	probe_vmi_rom();
+	if (vmi_rom) {
+                mwait_disable = 1;
+		vmi_init();
+	}
+}
+
+/**
+ * trap_init_hook - initialise system specific traps
+ *
+ * Description:
+ *	Called as the final act of trap_init().
+ **/
+void __init trap_init_hook(void)
+{
+}
+
+static struct irqaction irq0  = { timer_interrupt, SA_INTERRUPT, CPU_MASK_NONE, "timer", NULL, NULL};
+
+/**
+ * time_init_hook - do any specific initialisations for the system timer.
+ *
+ * Description:
+ *	Must plug the system timer interrupt source at HZ into the IRQ listed
+ *	in irq_vectors.h:TIMER_IRQ
+ **/
+void __init time_init_hook(void)
+{
+	setup_irq(0, &irq0);
+	load_idt(&idt_descr);
+}
diff -Naur linux-2.6.12.3.pristine/arch/i386/mach-vmi/stubs-asm.S linux-2.6.12.3-vmi/arch/i386/mach-vmi/stubs-asm.S
--- linux-2.6.12.3.pristine/arch/i386/mach-vmi/stubs-asm.S	1970-01-01 00:00:00.000000000 +0000
+++ linux-2.6.12.3-vmi/arch/i386/mach-vmi/stubs-asm.S	2006-01-03 13:47:37.000000000 +0000
@@ -0,0 +1,465 @@
+/*
+ * Copyright (c) 2005, VMware, Inc.
+ * All rights reserved.
+ */
+
+#include <linux/linkage.h>
+
+.extern iret_exc
+
+#define VMI_STUB_BEGIN(name)		 \
+	.section .text.VMI_##name, "ax"	;\
+	ENTRY(VMI_##name)
+
+#define VMI_STUB_END \
+	.previous
+
+#define VMI_STUB_DUMMY(name)		 \
+	.section .text.VMI_##name, "ax"	;\
+	ENTRY(VMI_##name)		;\
+	ret				;\
+	.previous
+
+#define VMI_STUB_IDENT(name, inst)	 \
+	.section .text.VMI_##name, "ax"	;\
+	ENTRY(VMI_##name)		;\
+	inst				;\
+	ret				;\
+	.previous
+
+#define VMI_STUB_WRAPPER(name)		 \
+	.section .text.VMI_##name, "ax"	;\
+	ENTRY(VMI_##name)		;\
+	push %ecx			;\
+	push %edx			;\
+	push %eax			;\
+	call VMI_##name##_Helper	;\
+	pop %eax			;\
+	pop %edx			;\
+	pop %ecx			;\
+	ret				;\
+	.previous
+
+#define VMI_STUB_WRAPPER_EAX(name)	 \
+	.section .text.VMI_##name, "ax"	;\
+	ENTRY(VMI_##name)		;\
+	push %ecx			;\
+	push %edx			;\
+	push %eax			;\
+	call VMI_##name##_Helper	;\
+	addl $4, %esp			;\
+	pop %edx			;\
+	pop %ecx			;\
+	ret				;\
+	.previous
+
+#ifdef CONFIG_SMP
+#define LOCK lock; 
+#else
+#define LOCK
+#endif
+
+#ifdef CONFIG_X86_OOSTORE
+#define SFENCE sfence 
+#else
+#define SFENCE
+#endif
+
+VMI_STUB_DUMMY(Init)
+VMI_STUB_IDENT(CPUID, cpuid)
+VMI_STUB_IDENT(WRMSR, wrmsr)
+VMI_STUB_IDENT(RDMSR, rdmsr)
+
+VMI_STUB_BEGIN(SetGDT)
+	lgdtl	(%eax)
+	ret
+VMI_STUB_END
+
+VMI_STUB_BEGIN(SetIDT)
+	lidtl	(%eax)
+	ret
+VMI_STUB_END
+
+VMI_STUB_BEGIN(SetLDT)
+	lldt	%ax
+	ret
+VMI_STUB_END
+
+VMI_STUB_BEGIN(SetTR)
+	ltr	%ax
+	ret
+VMI_STUB_END
+
+VMI_STUB_BEGIN(GetGDT)
+	sgdtl	(%eax)
+	ret
+VMI_STUB_END
+
+VMI_STUB_BEGIN(GetIDT)
+	sidtl	(%eax)
+	ret
+VMI_STUB_END
+
+VMI_STUB_BEGIN(GetLDT)
+	sldt	%eax
+	ret
+VMI_STUB_END
+
+VMI_STUB_BEGIN(GetTR)
+	str	%eax
+	ret
+VMI_STUB_END
+
+VMI_STUB_DUMMY(UpdateGDT)
+VMI_STUB_DUMMY(UpdateIDT)
+VMI_STUB_DUMMY(UpdateLDT)
+VMI_STUB_DUMMY(UpdateKernelStack)
+
+VMI_STUB_BEGIN(SetCR0)
+	mov %eax, %cr0
+	ret
+VMI_STUB_END
+
+VMI_STUB_BEGIN(SetCR2)
+	mov %eax, %cr2
+	ret
+VMI_STUB_END
+
+VMI_STUB_BEGIN(SetCR3)
+	mov %eax, %cr3
+	ret
+VMI_STUB_END
+
+VMI_STUB_BEGIN(SetCR4)
+	mov %eax, %cr4
+	ret
+VMI_STUB_END
+
+VMI_STUB_BEGIN(GetCR0)
+	mov %cr0, %eax
+	ret
+VMI_STUB_END
+
+VMI_STUB_BEGIN(GetCR2)
+	mov %cr2, %eax
+	ret
+VMI_STUB_END
+
+VMI_STUB_BEGIN(GetCR3)
+	mov %cr3, %eax
+	ret
+VMI_STUB_END
+
+VMI_STUB_BEGIN(GetCR4)
+	mov %cr4, %eax
+	ret
+VMI_STUB_END
+
+VMI_STUB_BEGIN(LMSW)
+	lmsw %ax
+	ret
+VMI_STUB_END
+
+VMI_STUB_BEGIN(SMSW)
+	xor %eax, %eax
+	smsw %ax
+	ret
+VMI_STUB_END
+
+VMI_STUB_IDENT(CLTS, clts)
+
+VMI_STUB_BEGIN(STTS)
+	push %eax
+	mov %cr0, %eax
+	or  $0x8, %eax
+	mov %eax, %cr0
+	pop %eax
+	ret
+VMI_STUB_END
+
+VMI_STUB_WRAPPER(SetDR)
+VMI_STUB_WRAPPER_EAX(GetDR)
+
+VMI_STUB_IDENT(RDPMC, rdpmc)
+VMI_STUB_IDENT(RDTSC, rdtsc)
+VMI_STUB_IDENT(INVD, invd)
+VMI_STUB_IDENT(WBINVD, wbinvd)
+
+/*
+ * These functions have two symbols to avoid convoluting the already
+ * quite complex macro-izing of I/O instructions in include/asm-i386/io.h
+ * We only have the lower case letter name available to the VMI macro in
+ * include/asm-i386/mach-vmi/mach_io.h, thus the transformed names.
+ */
+VMI_STUB_BEGIN(INB)
+ENTRY(VMI_Inb)
+	inb %dx, %al
+	ret
+VMI_STUB_END
+
+VMI_STUB_BEGIN(INW)
+ENTRY(VMI_Inw)
+	inw %dx, %ax
+	ret
+VMI_STUB_END
+
+VMI_STUB_BEGIN(INL)
+ENTRY(VMI_Inl)
+	in %dx, %eax
+	ret
+VMI_STUB_END
+
+VMI_STUB_BEGIN(OUTB)
+ENTRY(VMI_Outb)
+	outb %al, %dx
+	ret
+VMI_STUB_END
+
+VMI_STUB_BEGIN(OUTW)
+ENTRY(VMI_Outw)
+	outw %ax, %dx
+	ret
+VMI_STUB_END
+
+VMI_STUB_BEGIN(OUTL)
+ENTRY(VMI_Outl)
+	out %eax, %dx
+	ret
+VMI_STUB_END
+
+VMI_STUB_BEGIN(INSB)
+ENTRY(VMI_Insb)
+	rep; insb
+	ret
+VMI_STUB_END
+
+VMI_STUB_BEGIN(INSW)
+ENTRY(VMI_Insw)
+	rep; insw
+	ret
+VMI_STUB_END
+
+VMI_STUB_BEGIN(INSL)
+ENTRY(VMI_Insl)
+	rep; insl
+	ret
+VMI_STUB_END
+
+VMI_STUB_BEGIN(OUTSB)
+ENTRY(VMI_Outsb)
+	rep; outsb
+	ret
+VMI_STUB_END
+
+VMI_STUB_BEGIN(OUTSW)
+ENTRY(VMI_Outsw)
+	rep; outsw
+	ret
+VMI_STUB_END
+
+VMI_STUB_BEGIN(OUTSL)
+ENTRY(VMI_Outsl)
+	rep; outsl
+	ret
+VMI_STUB_END
+
+VMI_STUB_BEGIN(SetIOPLMask)
+	pushf
+	andb $0xcf, 1(%esp)
+	orb  %ah, 1(%esp)	/* User error could turn on NT - not really an issue */
+	popf
+	ret
+VMI_STUB_END
+
+VMI_STUB_BEGIN(GetIOPLMask)
+	pushf
+	pop %eax
+	andl $0x3000, %eax
+	ret
+VMI_STUB_END
+
+VMI_STUB_DUMMY(UpdateIOBitmap)
+VMI_STUB_DUMMY(UpdateInterruptBitmap)
+
+VMI_STUB_BEGIN(SetEFLAGS)
+	push %eax
+	popf
+	ret
+VMI_STUB_END
+
+VMI_STUB_BEGIN(GetEFLAGS)
+	pushf 
+	pop %eax
+	ret
+VMI_STUB_END
+
+VMI_STUB_BEGIN(SaveAndDisableIRQs)
+	pushf 
+	pop %eax
+	cli
+	ret
+VMI_STUB_END
+
+/* Not verified safe to use yet because of IOPL issues */
+VMI_STUB_DUMMY(RestoreIRQs)
+
+VMI_STUB_IDENT(CLI, cli)
+VMI_STUB_IDENT(STI, sti)
+
+VMI_STUB_BEGIN(IRET)
+1:	iret
+VMI_STUB_END
+.section __ex_table,"a"
+	.align 4
+	.long 1b,iret_exc
+.previous
+
+VMI_STUB_BEGIN(IRET16)
+1:	iret
+VMI_STUB_END
+.section __ex_table,"a"
+	.align 4
+	.long 1b,iret_exc
+.previous
+
+VMI_STUB_BEGIN(SysExit)
+	sysexit
+	ud2a
+VMI_STUB_END
+
+VMI_STUB_BEGIN(StiSysexit)
+	sti
+	sysexit
+	ud2a
+VMI_STUB_END
+
+VMI_STUB_BEGIN(SysRet)
+	sysret
+	ud2a
+VMI_STUB_END
+
+VMI_STUB_BEGIN(SafeHalt)
+	sti
+	hlt
+	ret
+VMI_STUB_END
+
+VMI_STUB_IDENT(Halt, hlt)
+VMI_STUB_IDENT(Pause, pause)
+
+VMI_STUB_BEGIN(Shutdown)
+	cli
+	hlt
+	ud2a
+VMI_STUB_END
+
+VMI_STUB_BEGIN(Reboot)
+	outb %al, $0x80
+	outb %al, $0x80
+	movb $0xfe, %al
+	outb %al, $0x64
+	outb %al, $0x80
+	outb %al, $0x80
+	lidt empty_zero_page
+	int3
+	ud2a
+VMI_STUB_END
+
+VMI_STUB_DUMMY(GetPteVal)
+VMI_STUB_DUMMY(GetPdeVal)
+VMI_STUB_DUMMY(PhysToMachine)
+VMI_STUB_DUMMY(MachineToPhys)
+VMI_STUB_BEGIN(SetPte)
+	mov %eax, (%edx)
+	ret
+VMI_STUB_END
+
+VMI_STUB_BEGIN(SwapPte)
+	xchg %eax, (%edx)
+	ret
+VMI_STUB_END
+
+VMI_STUB_BEGIN(TestAndSetPteBit)
+	LOCK bts %eax, (%edx)
+	sbb %eax, %eax
+	ret
+VMI_STUB_END
+
+VMI_STUB_BEGIN(TestAndClearPteBit)
+	LOCK btr %eax, (%edx)
+	sbb %eax, %eax
+	ret
+VMI_STUB_END
+
+/*
+ * This function can not be used on an active root PDP.
+ * use SwapPdpeLong instead.  The problem is SMIs can
+ * arrive which cause suspend to activate, and a half
+ * written value may get cached in hardware when CR3 is
+ * reloaded.
+ */
+VMI_STUB_BEGIN(SetPteLong)
+	mov %edx, 4(%ecx)
+	SFENCE
+	mov %eax, (%ecx)
+	ret
+VMI_STUB_END
+
+VMI_STUB_BEGIN(SwapPteLong)
+	mov  (%edi), %eax
+	mov  4(%edi), %edx
+1:	LOCK cmpxchg8b (%edi)
+	jne  1b
+	ret
+VMI_STUB_END
+
+/*
+ * The following are actually completly identical for PDE and PTE cases
+ * in both PAE and non-PAE mode, but having separate functions allows the
+ * functions to avoid using a double wide convention for non-PAE updates.
+ */
+VMI_STUB_BEGIN(TestAndSetPteBitLong)
+	LOCK bts %eax, (%edx)
+	sbb %eax, %eax
+	ret
+VMI_STUB_END
+
+VMI_STUB_BEGIN(TestAndClearPteBitLong)
+	LOCK btr %eax, (%edx)
+	sbb %eax, %eax
+	ret
+VMI_STUB_END
+
+VMI_STUB_DUMMY(ClonePageTable)
+VMI_STUB_DUMMY(ClonePageDirectory)
+VMI_STUB_DUMMY(RegisterPageMapping)
+VMI_STUB_DUMMY(RegisterPageUsage)
+VMI_STUB_DUMMY(ReleasePage)
+
+VMI_STUB_BEGIN(InvalPage)
+	invlpg (%eax)
+	ret
+VMI_STUB_END
+
+VMI_STUB_BEGIN(FlushTLB)
+	push %eax
+	mov %cr3, %eax
+	mov %eax, %cr3
+	pop %eax
+	ret
+VMI_STUB_END
+
+VMI_STUB_BEGIN(FlushTLBAll)
+	push %eax
+	mov %cr4, %eax
+	xor $0x80, %eax
+	mov %eax, %cr4
+	xor $0x80, %eax
+	mov %eax, %cr4
+	pop %eax
+	ret
+VMI_STUB_END
+
+VMI_STUB_DUMMY(SetDeferredMode)
+VMI_STUB_DUMMY(FlushDeferredCalls)
+
diff -Naur linux-2.6.12.3.pristine/arch/i386/mach-vmi/stubs.c linux-2.6.12.3-vmi/arch/i386/mach-vmi/stubs.c
--- linux-2.6.12.3.pristine/arch/i386/mach-vmi/stubs.c	1970-01-01 00:00:00.000000000 +0000
+++ linux-2.6.12.3-vmi/arch/i386/mach-vmi/stubs.c	2005-11-15 16:57:30.000000000 +0000
@@ -0,0 +1,67 @@
+/*
+ * Stub implementation of hardware features for transparent
+ * virtualization.
+ *
+ * Copyright (C) 2005, VMware, Inc.
+ *
+ * All rights reserved.
+ *
+ * This program is free software; you can redistribute it and/or modify
+ * it under the terms of the GNU General Public License as published by
+ * the Free Software Foundation; either version 2 of the License, or
+ * (at your option) any later version.
+ *
+ * This program is distributed in the hope that it will be useful, but
+ * WITHOUT ANY WARRANTY; without even the implied warranty of
+ * MERCHANTABILITY OR FITNESS FOR A PARTICULAR PURPOSE, GOOD TITLE or
+ * NON INFRINGEMENT.  See the GNU General Public License for more
+ * details.
+ *
+ * You should have received a copy of the GNU General Public License
+ * along with this program; if not, write to the Free Software
+ * Foundation, Inc., 675 Mass Ave, Cambridge, MA 02139, USA.
+ *
+ * Send feedback to zach@vmware.com
+ *
+ */
+
+#include <linux/config.h>
+#include <asm/processor.h>
+#include <asm/desc.h>
+#include <asm/bitops.h>
+#include <vmi.h>
+
+#define set_debug(register, val) \
+               __asm__("movl %0,%%db" #register  \
+                       : /* no output */ \
+                       :"r" (val))
+
+void VMI_SetDR_Helper(unsigned num, VMI_UINT32 val)
+{
+	switch(num) {
+		case 0:	set_debug(0, val); break;
+		case 1:	set_debug(1, val); break;
+		case 2:	set_debug(2, val); break;
+		case 3:	set_debug(3, val); break;
+		case 6:	set_debug(6, val); break;
+		case 7:	set_debug(7, val); break;
+	}
+}
+
+#define get_debug(register, val) \
+               __asm__("movl %%db" #register ", %0"  \
+                       : "=r" (val))
+
+VMI_UINT32 VMI_GetDR_Helper(unsigned num)
+{
+	VMI_UINT32 val = 0;
+	switch(num) {
+		case 0:	get_debug(0, val); break;
+		case 1:	get_debug(1, val); break;
+		case 2:	get_debug(2, val); break;
+		case 3:	get_debug(3, val); break;
+		case 6:	get_debug(6, val); break;
+		case 7:	get_debug(7, val); break;
+	}
+	return val;
+}
diff -Naur linux-2.6.12.3.pristine/arch/i386/math-emu/get_address.c linux-2.6.12.3-vmi/arch/i386/math-emu/get_address.c
--- linux-2.6.12.3.pristine/arch/i386/math-emu/get_address.c	2005-07-15 21:18:57.000000000 +0000
+++ linux-2.6.12.3-vmi/arch/i386/math-emu/get_address.c	2005-11-15 16:57:30.000000000 +0000
@@ -155,7 +155,6 @@
 { 
   struct desc_struct descriptor;
   unsigned long base_address, limit, address, seg_top;
-  unsigned short selector;
 
   segment--;
 
@@ -173,17 +172,11 @@
       /* fs and gs aren't used by the kernel, so they still have their
 	 user-space values. */
     case PREFIX_FS_-1:
-      /* The cast is needed here to get gcc 2.8.0 to use a 16 bit register
-	 in the assembler statement. */
-
-      __asm__("mov %%fs,%0":"=r" (selector));
-      addr->selector = selector;
+      /* N.B. - movl %seg, mem is a 2 bytes write regardless of prefix */
+      savesegment(fs, addr->selector);
       break;
     case PREFIX_GS_-1:
-      /* The cast is needed here to get gcc 2.8.0 to use a 16 bit register
-	 in the assembler statement. */
-      __asm__("mov %%gs,%0":"=r" (selector));
-      addr->selector = selector;
+      savesegment(gs, addr->selector);
       break;
     default:
       addr->selector = PM_REG_(segment);
diff -Naur linux-2.6.12.3.pristine/arch/i386/mm/fault.c linux-2.6.12.3-vmi/arch/i386/mm/fault.c
--- linux-2.6.12.3.pristine/arch/i386/mm/fault.c	2005-07-15 21:18:57.000000000 +0000
+++ linux-2.6.12.3-vmi/arch/i386/mm/fault.c	2005-11-15 16:57:30.000000000 +0000
@@ -222,7 +222,7 @@
 	siginfo_t info;
 
 	/* get the address */
-	__asm__("movl %%cr2,%0":"=r" (address));
+        address = read_cr2();
 
 	if (notify_die(DIE_PAGE_FAULT, "page fault", regs, error_code, 14,
 					SIGSEGV) == NOTIFY_STOP)
@@ -446,7 +446,7 @@
 	printk(" at virtual address %08lx\n",address);
 	printk(KERN_ALERT " printing eip:\n");
 	printk("%08lx\n", regs->eip);
-	asm("movl %%cr3,%0":"=r" (page));
+	page = read_cr3();
 	page = ((unsigned long *) __va(page))[address >> 22];
 	printk(KERN_ALERT "*pde = %08lx\n", page);
 	/*
@@ -520,7 +520,7 @@
 		pmd_t *pmd, *pmd_k;
 		pte_t *pte_k;
 
-		asm("movl %%cr3,%0":"=r" (pgd_paddr));
+		pgd_paddr = read_cr3();
 		pgd = index + (pgd_t *)__va(pgd_paddr);
 		pgd_k = init_mm.pgd + index;
 
@@ -547,6 +547,14 @@
 		pte_k = pte_offset_kernel(pmd_k, address);
 		if (!pte_present(*pte_k))
 			goto no_context;
+
+		/*
+		 * Needed for the VMI.  We have just updated this root
+		 * with a copy of the kernel pmd.  To return without
+		 * flushing would introduce a fault loop.
+		 */
+		update_mmu_cache(vma, address, pte_k);
+
 		return;
 	}
 }
diff -Naur linux-2.6.12.3.pristine/arch/i386/mm/init.c linux-2.6.12.3-vmi/arch/i386/mm/init.c
--- linux-2.6.12.3.pristine/arch/i386/mm/init.c	2005-07-15 21:18:57.000000000 +0000
+++ linux-2.6.12.3-vmi/arch/i386/mm/init.c	2005-11-15 16:57:30.000000000 +0000
@@ -79,6 +79,7 @@
 {
 	if (pmd_none(*pmd)) {
 		pte_t *page_table = (pte_t *) alloc_bootmem_low_pages(PAGE_SIZE);
+		mach_use_pte(__pa(page_table) >> PAGE_SHIFT);
 		set_pmd(pmd, __pmd(__pa(page_table) | _PAGE_TABLE));
 		if (page_table != pte_offset_kernel(pmd, 0))
 			BUG();	
@@ -336,7 +337,8 @@
 	 * created - mappings will be set by set_fixmap():
 	 */
 	vaddr = __fix_to_virt(__end_of_fixed_addresses - 1) & PMD_MASK;
-	page_table_range_init(vaddr, 0, pgd_base);
+/* VU: limit end */
+	page_table_range_init(vaddr, vaddr + PMD_SIZE, pgd_base);
 
 	permanent_kmaps_init(pgd_base);
 
diff -Naur linux-2.6.12.3.pristine/arch/i386/mm/pageattr.c linux-2.6.12.3-vmi/arch/i386/mm/pageattr.c
--- linux-2.6.12.3.pristine/arch/i386/mm/pageattr.c	2005-07-15 21:18:57.000000000 +0000
+++ linux-2.6.12.3-vmi/arch/i386/mm/pageattr.c	2005-11-15 16:57:30.000000000 +0000
@@ -12,6 +12,7 @@
 #include <asm/uaccess.h>
 #include <asm/processor.h>
 #include <asm/tlbflush.h>
+#include <asm/pgalloc.h>
 
 static DEFINE_SPINLOCK(cpa_lock);
 static struct list_head df_list = LIST_HEAD_INIT(df_list);
@@ -52,8 +53,9 @@
 	addr = address & LARGE_PAGE_MASK; 
 	pbase = (pte_t *)page_address(base);
 	for (i = 0; i < PTRS_PER_PTE; i++, addr += PAGE_SIZE) {
-		pbase[i] = pfn_pte(addr >> PAGE_SHIFT, 
-				   addr == address ? prot : PAGE_KERNEL);
+               set_pte(&pbase[i], pfn_pte(addr >> PAGE_SHIFT, 
+                                          addr == address ? prot : PAGE_KERNEL));
+		mach_use_pte(__pa(pbase) >> PAGE_SHIFT);
 	}
 	return base;
 } 
@@ -62,19 +64,19 @@
 { 
 	/* Could use CLFLUSH here if the CPU supports it (Hammer,P4) */
 	if (boot_cpu_data.x86_model >= 4) 
-		asm volatile("wbinvd":::"memory"); 
+		wbinvd();
 	/* Flush all to work around Errata in early athlons regarding 
 	 * large page flushing. 
 	 */
 	__flush_tlb_all(); 	
 }
 
-static void set_pmd_pte(pte_t *kpte, unsigned long address, pte_t pte) 
+static void set_pmd_pde(pmd_t *kpmd, unsigned long address, pmd_t pde) 
 { 
 	struct page *page;
 	unsigned long flags;
 
-	set_pte_atomic(kpte, pte); 	/* change init_mm */
+	set_pmd(kpmd, pde); 	/* change init_mm */
 	if (PTRS_PER_PMD > 1)
 		return;
 
@@ -86,7 +88,7 @@
 		pgd = (pgd_t *)page_address(page) + pgd_index(address);
 		pud = pud_offset(pgd, address);
 		pmd = pmd_offset(pud, address);
-		set_pte_atomic((pte_t *)pmd, pte);
+		set_pmd(pmd, pde);
 	}
 	spin_unlock_irqrestore(&pgd_lock, flags);
 }
@@ -95,12 +97,12 @@
  * No more special protections in this 2/4MB area - revert to a
  * large page again. 
  */
-static inline void revert_page(struct page *kpte_page, unsigned long address)
+static inline void revert_page(unsigned long address)
 {
-	pte_t *linear = (pte_t *) 
-		pmd_offset(pud_offset(pgd_offset_k(address), address), address);
-	set_pmd_pte(linear,  address,
-		    pfn_pte((__pa(address) & LARGE_PAGE_MASK) >> PAGE_SHIFT,
+	pmd_t *linear = pmd_offset(pud_offset(pgd_offset_k(address), address),
+			 	   address);
+	set_pmd_pde(linear,  address,
+		    pfn_pmd((__pa(address) & LARGE_PAGE_MASK) >> PAGE_SHIFT,
 			    PAGE_KERNEL_LARGE));
 }
 
@@ -125,30 +127,33 @@
 			struct page *split = split_large_page(address, prot); 
 			if (!split)
 				return -ENOMEM;
-			set_pmd_pte(kpte,address,mk_pte(split, PAGE_KERNEL));
+			set_pmd_pde((pmd_t *)kpte, address,
+				    pfn_pmd(page_to_pfn(split), PAGE_KERNEL));
 			kpte_page = split;
 		}	
 		get_page(kpte_page);
 	} else if ((pte_val(*kpte) & _PAGE_PSE) == 0) { 
 		set_pte_atomic(kpte, mk_pte(page, PAGE_KERNEL));
 		__put_page(kpte_page);
+
+		/*
+		 * If the pte was reserved, it means it was created at boot
+		 * time (not via split_large_page) and in turn we must not
+		 * replace it with a largepage.
+		 */
+		if (!PageReserved(kpte_page)) {
+			/* memleak and potential failed 2M page regeneration */
+			BUG_ON(!page_count(kpte_page));
+
+			if (cpu_has_pse && (page_count(kpte_page) == 1)) {
+				mach_unuse_pte(__pa(kpte) >> PAGE_SHIFT);
+				list_add(&kpte_page->lru, &df_list);
+				revert_page(address);
+			}
+		}
 	} else
 		BUG();
 
-	/*
-	 * If the pte was reserved, it means it was created at boot
-	 * time (not via split_large_page) and in turn we must not
-	 * replace it with a largepage.
-	 */
-	if (!PageReserved(kpte_page)) {
-		/* memleak and potential failed 2M page regeneration */
-		BUG_ON(!page_count(kpte_page));
-
-		if (cpu_has_pse && (page_count(kpte_page) == 1)) {
-			list_add(&kpte_page->lru, &df_list);
-			revert_page(kpte_page, address);
-		}
-	}
 	return 0;
 } 
 
diff -Naur linux-2.6.12.3.pristine/arch/i386/mm/pgtable.c linux-2.6.12.3-vmi/arch/i386/mm/pgtable.c
--- linux-2.6.12.3.pristine/arch/i386/mm/pgtable.c	2005-07-15 21:18:57.000000000 +0000
+++ linux-2.6.12.3-vmi/arch/i386/mm/pgtable.c	2005-11-15 16:57:30.000000000 +0000
@@ -199,19 +199,17 @@
 {
 	unsigned long flags;
 
+	memset(pgd, 0, USER_PTRS_PER_PGD*sizeof(pgd_t));
 	if (PTRS_PER_PMD == 1)
 		spin_lock_irqsave(&pgd_lock, flags);
 
-	memcpy((pgd_t *)pgd + USER_PTRS_PER_PGD,
-			swapper_pg_dir + USER_PTRS_PER_PGD,
-			(PTRS_PER_PGD - USER_PTRS_PER_PGD) * sizeof(pgd_t));
-
+	clone_pgd_range(pgd, swapper_pg_dir, USER_PTRS_PER_PGD,
+			PTRS_PER_PGD - USER_PTRS_PER_PGD);
 	if (PTRS_PER_PMD > 1)
 		return;
 
 	pgd_list_add(pgd);
 	spin_unlock_irqrestore(&pgd_lock, flags);
-	memset(pgd, 0, USER_PTRS_PER_PGD*sizeof(pgd_t));
 }
 
 /* never called when PTRS_PER_PMD > 1 */
@@ -236,13 +234,17 @@
 		pmd_t *pmd = kmem_cache_alloc(pmd_cache, GFP_KERNEL);
 		if (!pmd)
 			goto out_oom;
+		mach_use_pmd(__pa(pmd) >> PAGE_SHIFT);
 		set_pgd(&pgd[i], __pgd(1 + __pa(pmd)));
 	}
 	return pgd;
 
 out_oom:
-	for (i--; i >= 0; i--)
+	for (i--; i >= 0; i--) {
+		mach_unuse_pmd(pgd_val(pgd[i]) >> PAGE_SHIFT);
 		kmem_cache_free(pmd_cache, (void *)__va(pgd_val(pgd[i])-1));
+	}
+	mach_unuse_pgd(__pa(pgd) >> PAGE_SHIFT);
 	kmem_cache_free(pgd_cache, pgd);
 	return NULL;
 }
@@ -253,8 +255,11 @@
 
 	/* in the PAE case user pgd entries are overwritten before usage */
 	if (PTRS_PER_PMD > 1)
-		for (i = 0; i < USER_PTRS_PER_PGD; ++i)
-			kmem_cache_free(pmd_cache, (void *)__va(pgd_val(pgd[i])-1));
+		for (i = 0; i < USER_PTRS_PER_PGD; ++i) {
+			mach_unuse_pmd(pgd_val(pgd[i]) >> PAGE_SHIFT);
+			kmem_cache_free(pmd_cache, (void *)__va(pgd_val(pgd[i]) & PAGE_MASK));
+		}
 	/* in the non-PAE case, free_pgtables() clears user pgd entries */
+	mach_unuse_pgd(__pa(pgd) >> PAGE_SHIFT);
 	kmem_cache_free(pgd_cache, pgd);
 }
diff -Naur linux-2.6.12.3.pristine/arch/i386/power/cpu.c linux-2.6.12.3-vmi/arch/i386/power/cpu.c
--- linux-2.6.12.3.pristine/arch/i386/power/cpu.c	2005-07-15 21:18:57.000000000 +0000
+++ linux-2.6.12.3-vmi/arch/i386/power/cpu.c	2005-11-15 16:57:30.000000000 +0000
@@ -42,26 +42,26 @@
 	/*
 	 * descriptor tables
 	 */
-	asm volatile ("sgdt %0" : "=m" (ctxt->gdt_limit));
-	asm volatile ("sidt %0" : "=m" (ctxt->idt_limit));
-	asm volatile ("sldt %0" : "=m" (ctxt->ldt));
-	asm volatile ("str %0"  : "=m" (ctxt->tr));
+	store_gdt(&ctxt->gdt_limit);
+	store_idt(&ctxt->idt_limit);
+	store_ldt(ctxt->ldt);
+	store_tr(ctxt->tr);
 
 	/*
 	 * segment registers
 	 */
-	asm volatile ("movw %%es, %0" : "=m" (ctxt->es));
-	asm volatile ("movw %%fs, %0" : "=m" (ctxt->fs));
-	asm volatile ("movw %%gs, %0" : "=m" (ctxt->gs));
-	asm volatile ("movw %%ss, %0" : "=m" (ctxt->ss));
+	savesegment(es, ctxt->es);
+	savesegment(fs, ctxt->fs);
+	savesegment(gs, ctxt->gs);
+	savesegment(ss, ctxt->ss);
 
 	/*
 	 * control registers 
 	 */
-	asm volatile ("movl %%cr0, %0" : "=r" (ctxt->cr0));
-	asm volatile ("movl %%cr2, %0" : "=r" (ctxt->cr2));
-	asm volatile ("movl %%cr3, %0" : "=r" (ctxt->cr3));
-	asm volatile ("movl %%cr4, %0" : "=r" (ctxt->cr4));
+	ctxt->cr0 = read_cr0();
+	ctxt->cr2 = read_cr2();
+	ctxt->cr3 = read_cr3();
+	ctxt->cr4 = read_cr4();
 }
 
 void save_processor_state(void)
@@ -111,26 +111,26 @@
 	/*
 	 * control registers
 	 */
-	asm volatile ("movl %0, %%cr4" :: "r" (ctxt->cr4));
-	asm volatile ("movl %0, %%cr3" :: "r" (ctxt->cr3));
-	asm volatile ("movl %0, %%cr2" :: "r" (ctxt->cr2));
-	asm volatile ("movl %0, %%cr0" :: "r" (ctxt->cr0));
+	write_cr4(ctxt->cr4);
+	write_cr3(ctxt->cr3);
+	write_cr2(ctxt->cr2);
+	write_cr2(ctxt->cr0);
 
 	/*
 	 * segment registers
 	 */
-	asm volatile ("movw %0, %%es" :: "r" (ctxt->es));
-	asm volatile ("movw %0, %%fs" :: "r" (ctxt->fs));
-	asm volatile ("movw %0, %%gs" :: "r" (ctxt->gs));
-	asm volatile ("movw %0, %%ss" :: "r" (ctxt->ss));
+	loadsegment(es, ctxt->es);
+	loadsegment(fs, ctxt->fs);
+	loadsegment(gs, ctxt->gs);
+	loadsegment(ss, ctxt->ss);
 
 	/*
 	 * now restore the descriptor tables to their proper values
 	 * ltr is done i fix_processor_context().
 	 */
-	asm volatile ("lgdt %0" :: "m" (ctxt->gdt_limit));
-	asm volatile ("lidt %0" :: "m" (ctxt->idt_limit));
-	asm volatile ("lldt %0" :: "m" (ctxt->ldt));
+	load_gdt(&ctxt->gdt_limit);
+	load_idt(&ctxt->idt_limit);
+	load_ldt(ctxt->ldt);
 
 	/*
 	 * sysenter MSRs
diff -Naur linux-2.6.12.3.pristine/include/asm-generic/pgtable-nopud.h linux-2.6.12.3-vmi/include/asm-generic/pgtable-nopud.h
--- linux-2.6.12.3.pristine/include/asm-generic/pgtable-nopud.h	2005-07-15 21:18:57.000000000 +0000
+++ linux-2.6.12.3-vmi/include/asm-generic/pgtable-nopud.h	2005-11-15 16:57:30.000000000 +0000
@@ -3,6 +3,8 @@
 
 #ifndef __ASSEMBLY__
 
+#include <pgtable-ops.h>
+
 #define __PAGETABLE_PUD_FOLDED
 
 /*
diff -Naur linux-2.6.12.3.pristine/include/asm-i386/agp.h linux-2.6.12.3-vmi/include/asm-i386/agp.h
--- linux-2.6.12.3.pristine/include/asm-i386/agp.h	2005-07-15 21:18:57.000000000 +0000
+++ linux-2.6.12.3-vmi/include/asm-i386/agp.h	2005-11-15 16:57:30.000000000 +0000
@@ -19,7 +19,7 @@
 /* Could use CLFLUSH here if the cpu supports it. But then it would
    need to be called for each cacheline of the whole page so it may not be 
    worth it. Would need a page for it. */
-#define flush_agp_cache() asm volatile("wbinvd":::"memory")
+#define flush_agp_cache() wbinvd()
 
 /* Convert a physical address to an address suitable for the GART. */
 #define phys_to_gart(x) (x)
diff -Naur linux-2.6.12.3.pristine/include/asm-i386/bugs.h linux-2.6.12.3-vmi/include/asm-i386/bugs.h
--- linux-2.6.12.3.pristine/include/asm-i386/bugs.h	2005-07-15 21:18:57.000000000 +0000
+++ linux-2.6.12.3-vmi/include/asm-i386/bugs.h	2005-11-15 16:57:30.000000000 +0000
@@ -118,7 +118,10 @@
 		printk("disabled\n");
 		return;
 	}
-	__asm__ __volatile__("hlt ; hlt ; hlt ; hlt");
+	halt();
+	halt();
+	halt();
+	halt();
 	printk("OK.\n");
 }
 
diff -Naur linux-2.6.12.3.pristine/include/asm-i386/cpufeature.h linux-2.6.12.3-vmi/include/asm-i386/cpufeature.h
--- linux-2.6.12.3.pristine/include/asm-i386/cpufeature.h	2005-07-15 21:18:57.000000000 +0000
+++ linux-2.6.12.3-vmi/include/asm-i386/cpufeature.h	2005-11-15 16:57:30.000000000 +0000
@@ -102,6 +102,7 @@
 #define cpu_has_pge		boot_cpu_has(X86_FEATURE_PGE)
 #define cpu_has_apic		boot_cpu_has(X86_FEATURE_APIC)
 #define cpu_has_sep		boot_cpu_has(X86_FEATURE_SEP)
+#define cpu_has_mwait		boot_cpu_has(X86_FEATURE_MWAIT)
 #define cpu_has_mtrr		boot_cpu_has(X86_FEATURE_MTRR)
 #define cpu_has_mmx		boot_cpu_has(X86_FEATURE_MMX)
 #define cpu_has_fxsr		boot_cpu_has(X86_FEATURE_FXSR)
diff -Naur linux-2.6.12.3.pristine/include/asm-i386/desc.h linux-2.6.12.3-vmi/include/asm-i386/desc.h
--- linux-2.6.12.3.pristine/include/asm-i386/desc.h	2005-07-15 21:18:57.000000000 +0000
+++ linux-2.6.12.3-vmi/include/asm-i386/desc.h	2005-11-15 16:57:30.000000000 +0000
@@ -27,9 +27,6 @@
 
 extern struct Xgt_desc_struct idt_descr, cpu_gdt_descr[NR_CPUS];
 
-#define load_TR_desc() __asm__ __volatile__("ltr %%ax"::"a" (GDT_ENTRY_TSS*8))
-#define load_LDT_desc() __asm__ __volatile__("lldt %%ax"::"a" (GDT_ENTRY_LDT*8))
-
 /*
  * This is the ldt that every process will get unless we need
  * something other than this.
@@ -48,19 +45,10 @@
 	"rorl $16,%%eax" \
 	: "=m"(*(n)) : "a" (addr), "r"(n), "ir"(limit), "i"(type))
 
-static inline void __set_tss_desc(unsigned int cpu, unsigned int entry, void *addr)
-{
-	_set_tssldt_desc(&per_cpu(cpu_gdt_table, cpu)[entry], (int)addr,
-		offsetof(struct tss_struct, __cacheline_filler) - 1, 0x89);
-}
+#include <mach_desc.h>
 
 #define set_tss_desc(cpu,addr) __set_tss_desc(cpu, GDT_ENTRY_TSS, addr)
 
-static inline void set_ldt_desc(unsigned int cpu, void *addr, unsigned int size)
-{
-	_set_tssldt_desc(&per_cpu(cpu_gdt_table, cpu)[GDT_ENTRY_LDT], (int)addr, ((size << 3)-1), 0x82);
-}
-
 #define LDT_entry_a(info) \
 	((((info)->base_addr & 0x0000ffff) << 16) | ((info)->limit & 0x0ffff))
 
@@ -86,17 +74,6 @@
 	(info)->seg_not_present	== 1	&& \
 	(info)->useable		== 0	)
 
-#if TLS_SIZE != 24
-# error update this code.
-#endif
-
-static inline void load_TLS(struct thread_struct *t, unsigned int cpu)
-{
-#define C(i) per_cpu(cpu_gdt_table, cpu)[GDT_ENTRY_TLS_MIN + i] = t->tls_array[i]
-	C(0); C(1); C(2);
-#undef C
-}
-
 static inline void clear_LDT(void)
 {
 	int cpu = get_cpu();
diff -Naur linux-2.6.12.3.pristine/include/asm-i386/dma-mapping.h linux-2.6.12.3-vmi/include/asm-i386/dma-mapping.h
--- linux-2.6.12.3.pristine/include/asm-i386/dma-mapping.h	2005-07-15 21:18:57.000000000 +0000
+++ linux-2.6.12.3-vmi/include/asm-i386/dma-mapping.h	2005-11-15 16:57:30.000000000 +0000
@@ -22,7 +22,8 @@
 {
 	BUG_ON(direction == DMA_NONE);
 	flush_write_buffers();
-	return virt_to_phys(ptr);
+// VU
+	return virt_to_bus(ptr);
 }
 
 static inline void
@@ -42,8 +43,8 @@
 
 	for (i = 0; i < nents; i++ ) {
 		BUG_ON(!sg[i].page);
-
-		sg[i].dma_address = page_to_phys(sg[i].page) + sg[i].offset;
+// VU
+		sg[i].dma_address = page_to_bus(sg[i].page) + sg[i].offset;
 	}
 
 	flush_write_buffers();
@@ -55,7 +56,8 @@
 	     size_t size, enum dma_data_direction direction)
 {
 	BUG_ON(direction == DMA_NONE);
-	return page_to_phys(page) + offset;
+// VU
+	return page_to_bus(page) + offset;
 }
 
 static inline void
diff -Naur linux-2.6.12.3.pristine/include/asm-i386/fixmap.h linux-2.6.12.3-vmi/include/asm-i386/fixmap.h
--- linux-2.6.12.3.pristine/include/asm-i386/fixmap.h	2005-07-15 21:18:57.000000000 +0000
+++ linux-2.6.12.3-vmi/include/asm-i386/fixmap.h	2005-11-15 16:57:30.000000000 +0000
@@ -20,7 +20,7 @@
  * Leave one empty page between vmalloc'ed areas and
  * the start of the fixmap.
  */
-#define __FIXADDR_TOP	0xfffff000
+#define __FIXADDR_TOP	(0xfffff000-(CONFIG_MEMORY_HOLE << 20))
 
 #ifndef __ASSEMBLY__
 #include <linux/kernel.h>
diff -Naur linux-2.6.12.3.pristine/include/asm-i386/io.h linux-2.6.12.3-vmi/include/asm-i386/io.h
--- linux-2.6.12.3.pristine/include/asm-i386/io.h	2005-07-15 21:18:57.000000000 +0000
+++ linux-2.6.12.3-vmi/include/asm-i386/io.h	2005-11-15 16:57:30.000000000 +0000
@@ -4,6 +4,7 @@
 #include <linux/config.h>
 #include <linux/string.h>
 #include <linux/compiler.h>
+#include <mach_io.h>
 
 /*
  * This file contains the definitions for the x86 IO instructions
@@ -132,22 +133,6 @@
 extern void bt_iounmap(void *addr, unsigned long size);
 
 /*
- * ISA I/O bus memory addresses are 1:1 with the physical address.
- */
-#define isa_virt_to_bus virt_to_phys
-#define isa_page_to_bus page_to_phys
-#define isa_bus_to_virt phys_to_virt
-
-/*
- * However PCI ones are not necessarily 1:1 and therefore these interfaces
- * are forbidden in portable PCI drivers.
- *
- * Allow them on x86 for legacy drivers, though.
- */
-#define virt_to_bus virt_to_phys
-#define bus_to_virt phys_to_virt
-
-/*
  * readX/writeX() are used to access memory mapped devices. On some
  * architectures the memory mapped IO stuff needs to be accessed
  * differently. On the x86 architecture, we just read/write the
@@ -298,12 +283,14 @@
 #endif
 
 static inline void slow_down_io(void) {
+#ifndef CONFIG_NO_IODELAY
 	__asm__ __volatile__(
 		__SLOW_DOWN_IO
 #ifdef REALLY_SLOW_IO
 		__SLOW_DOWN_IO __SLOW_DOWN_IO __SLOW_DOWN_IO
 #endif
 		: : );
+#endif
 }
 
 #ifdef CONFIG_X86_NUMAQ
@@ -341,11 +328,11 @@
 
 #define BUILDIO(bwl,bw,type) \
 static inline void out##bwl##_local(unsigned type value, int port) { \
-	__asm__ __volatile__("out" #bwl " %" #bw "0, %w1" : : "a"(value), "Nd"(port)); \
+	__BUILDOUTINST(bwl,bw,value,port); \
 } \
 static inline unsigned type in##bwl##_local(int port) { \
 	unsigned type value; \
-	__asm__ __volatile__("in" #bwl " %w1, %" #bw "0" : "=a"(value) : "Nd"(port)); \
+	__BUILDININST(bwl,bw,value,port); \
 	return value; \
 } \
 static inline void out##bwl##_local_p(unsigned type value, int port) { \
@@ -368,10 +355,10 @@
 	return value; \
 } \
 static inline void outs##bwl(int port, const void *addr, unsigned long count) { \
-	__asm__ __volatile__("rep; outs" #bwl : "+S"(addr), "+c"(count) : "d"(port)); \
+	__BUILDOUTSINST(bwl,addr,count,port); \
 } \
 static inline void ins##bwl(int port, void *addr, unsigned long count) { \
-	__asm__ __volatile__("rep; ins" #bwl : "+D"(addr), "+c"(count) : "d"(port)); \
+	__BUILDINSINST(bwl,addr,count,port); \
 }
 
 BUILDIO(b,b,char)
diff -Naur linux-2.6.12.3.pristine/include/asm-i386/mach-default/mach-vmlinux.lds.h linux-2.6.12.3-vmi/include/asm-i386/mach-default/mach-vmlinux.lds.h
--- linux-2.6.12.3.pristine/include/asm-i386/mach-default/mach-vmlinux.lds.h	1970-01-01 00:00:00.000000000 +0000
+++ linux-2.6.12.3-vmi/include/asm-i386/mach-default/mach-vmlinux.lds.h	2005-11-15 16:57:30.000000000 +0000
@@ -0,0 +1 @@
+#define MACH_TEXT /* nothing */
diff -Naur linux-2.6.12.3.pristine/include/asm-i386/mach-default/mach_asm.h linux-2.6.12.3-vmi/include/asm-i386/mach-default/mach_asm.h
--- linux-2.6.12.3.pristine/include/asm-i386/mach-default/mach_asm.h	1970-01-01 00:00:00.000000000 +0000
+++ linux-2.6.12.3-vmi/include/asm-i386/mach-default/mach_asm.h	2005-11-15 16:57:30.000000000 +0000
@@ -0,0 +1,15 @@
+#ifndef __MACH_ASM_H
+#define __MACH_ASM_H
+
+#define IRET		iret
+#define IRET16		iret
+#define CLI		cli
+#define STI		sti
+#define STI_SYSEXIT	sti; sysexit
+#define MASK_RPL(reg)	/* unused */
+#define GET_CR0		mov %cr0, %eax
+#define WRMSR		wrmsr
+#define RDMSR		rdmsr
+#define CPUID		cpuid
+
+#endif /* __MACH_ASM_H */
diff -Naur linux-2.6.12.3.pristine/include/asm-i386/mach-default/mach_desc.h linux-2.6.12.3-vmi/include/asm-i386/mach-default/mach_desc.h
--- linux-2.6.12.3.pristine/include/asm-i386/mach-default/mach_desc.h	1970-01-01 00:00:00.000000000 +0000
+++ linux-2.6.12.3-vmi/include/asm-i386/mach-default/mach_desc.h	2005-11-15 16:57:30.000000000 +0000
@@ -0,0 +1,71 @@
+/*
+ * Copyright (C) 2005, VMware, Inc.
+ *
+ * All rights reserved.
+ *
+ * This program is free software; you can redistribute it and/or modify
+ * it under the terms of the GNU General Public License as published by
+ * the Free Software Foundation; either version 2 of the License, or
+ * (at your option) any later version.
+ *
+ * This program is distributed in the hope that it will be useful, but
+ * WITHOUT ANY WARRANTY; without even the implied warranty of
+ * MERCHANTABILITY OR FITNESS FOR A PARTICULAR PURPOSE, GOOD TITLE or
+ * NON INFRINGEMENT.  See the GNU General Public License for more
+ * details.
+ *
+ * You should have received a copy of the GNU General Public License
+ * along with this program; if not, write to the Free Software
+ * Foundation, Inc., 675 Mass Ave, Cambridge, MA 02139, USA.
+ *
+ */
+
+#ifndef __MACH_DESC_H
+#define __MACH_DESC_H
+
+#define load_TR_desc() __asm__ __volatile__("ltr %w0"::"q" (GDT_ENTRY_TSS*8))
+#define load_LDT_desc() __asm__ __volatile__("lldt %w0"::"q" (GDT_ENTRY_LDT*8))
+
+#define load_gdt(dtr) __asm__ __volatile("lgdt %0"::"m" (*dtr))
+#define load_idt(dtr) __asm__ __volatile("lidt %0"::"m" (*dtr))
+#define load_tr(tr) __asm__ __volatile("ltr %0"::"m" (tr))
+#define load_ldt(ldt) __asm__ __volatile("lldt %0"::"m" (ldt))
+
+#define store_gdt(dtr) __asm__ ("sgdt %0":"=m" (*dtr))
+#define store_idt(dtr) __asm__ ("sidt %0":"=m" (*dtr))
+#define store_tr(tr) __asm__ ("str %0":"=m" (tr))
+#define store_ldt(ldt) __asm__ ("sldt %0":"=m" (ldt))
+
+static inline unsigned int get_TR_desc(void)
+{
+	unsigned int tr;
+	__asm__ ("str %w0":"=q" (tr));
+	return tr;
+}
+
+static inline unsigned int get_LDT_desc(void)
+{
+	unsigned int ldt;
+	__asm__ ("sldt %w0":"=q" (ldt));
+	return ldt;
+}
+
+static inline void __set_tss_desc(unsigned int cpu, unsigned int entry, void *addr)
+{
+	_set_tssldt_desc(&per_cpu(cpu_gdt_table, cpu)[entry], (int)addr,
+		offsetof(struct tss_struct, __cacheline_filler) - 1, 0x89);
+}
+
+static inline void set_ldt_desc(unsigned int cpu, void *addr, unsigned int size)
+{
+	_set_tssldt_desc(&per_cpu(cpu_gdt_table, cpu)[GDT_ENTRY_LDT], (int)addr, ((size << 3)-1), 0x82);
+}
+
+static inline void load_TLS(struct thread_struct *t, unsigned int cpu)
+{
+#define C(i) per_cpu(cpu_gdt_table, cpu)[GDT_ENTRY_TLS_MIN + i] = t->tls_array[i]
+	C(0); C(1); C(2);
+#undef C
+}
+
+#endif
diff -Naur linux-2.6.12.3.pristine/include/asm-i386/mach-default/mach_io.h linux-2.6.12.3-vmi/include/asm-i386/mach-default/mach_io.h
--- linux-2.6.12.3.pristine/include/asm-i386/mach-default/mach_io.h	1970-01-01 00:00:00.000000000 +0000
+++ linux-2.6.12.3-vmi/include/asm-i386/mach-default/mach_io.h	2005-11-15 16:57:30.000000000 +0000
@@ -0,0 +1,33 @@
+#ifndef _MACH_ASM_IO_H
+#define _MACH_ASM_IO_H
+
+#define __BUILDOUTINST(bwl,bw,value,port) \
+	__asm__ __volatile__("out" #bwl " %" #bw "0, %w1" : : "a"(value), "Nd"(port))
+#define	__BUILDININST(bwl,bw,value,port) \
+	__asm__ __volatile__("in" #bwl " %w1, %" #bw "0" : "=a"(value) : "Nd"(port))
+#define	__BUILDOUTSINST(bwl,addr,count,port) \
+	__asm__ __volatile__("rep; outs" #bwl : "+S"(addr), "+c"(count) : "d"(port))
+#define	__BUILDINSINST(bwl,addr,count,port) \
+	__asm__ __volatile__("rep; ins" #bwl \
+			     : "+D"(addr), "+c"(count) \
+			     : "d"(port) \
+			     : "memory")
+
+/*
+ * ISA I/O bus memory addresses are 1:1 with the physical address.
+ */
+#define isa_virt_to_bus virt_to_phys
+#define isa_page_to_bus page_to_phys
+#define isa_bus_to_virt phys_to_virt
+
+/*
+ * However PCI ones are not necessarily 1:1 and therefore these interfaces
+ * are forbidden in portable PCI drivers.
+ *
+ * Allow them on x86 for legacy drivers, though.
+ */
+#define virt_to_bus virt_to_phys
+#define bus_to_virt phys_to_virt
+#define page_to_bus page_to_phys
+
+#endif
diff -Naur linux-2.6.12.3.pristine/include/asm-i386/mach-default/mach_irqcontrol.h linux-2.6.12.3-vmi/include/asm-i386/mach-default/mach_irqcontrol.h
--- linux-2.6.12.3.pristine/include/asm-i386/mach-default/mach_irqcontrol.h	1970-01-01 00:00:00.000000000 +0000
+++ linux-2.6.12.3-vmi/include/asm-i386/mach-default/mach_irqcontrol.h	2005-11-15 16:57:30.000000000 +0000
@@ -0,0 +1,38 @@
+/*
+ * Copyright (C) 2005, VMware, Inc.
+ *
+ * All rights reserved.
+ *
+ * This program is free software; you can redistribute it and/or modify
+ * it under the terms of the GNU General Public License as published by
+ * the Free Software Foundation; either version 2 of the License, or
+ * (at your option) any later version.
+ *
+ * This program is distributed in the hope that it will be useful, but
+ * WITHOUT ANY WARRANTY; without even the implied warranty of
+ * MERCHANTABILITY OR FITNESS FOR A PARTICULAR PURPOSE, GOOD TITLE or
+ * NON INFRINGEMENT.  See the GNU General Public License for more
+ * details.
+ *
+ * You should have received a copy of the GNU General Public License
+ * along with this program; if not, write to the Free Software
+ * Foundation, Inc., 675 Mass Ave, Cambridge, MA 02139, USA.
+ *
+ * Send feedback to zach@vmware.com
+ *
+ */
+
+#ifndef _MACH_IRQCONTROL_H
+#define _MACH_IRQCONTROL_H
+
+#define local_save_flags(x)     do { typecheck(unsigned long,x); __asm__ __volatile__("pushfl ; popl %0":"=g" (x): /* no input */); } while (0)
+
+/* For spinlocks etc */
+#define local_irq_save(x)       __asm__ __volatile__("pushfl ; popl %0 ; cli":"=g" (x): /* no input */ :"memory")
+#define local_irq_restore(x)    do { typecheck(unsigned long,x); __asm__ __volatile__("pushl %0 ; popfl": /* no output */ :"g" (x):"memory", "cc"); } while (0)
+
+#define local_irq_disable()     __asm__ __volatile__("cli": : :"memory")
+#define local_irq_enable()      __asm__ __volatile__("sti": : :"memory")
+
+#endif /* _MACH_IRQCONTROL_H */
+
diff -Naur linux-2.6.12.3.pristine/include/asm-i386/mach-default/mach_msr.h linux-2.6.12.3-vmi/include/asm-i386/mach-default/mach_msr.h
--- linux-2.6.12.3.pristine/include/asm-i386/mach-default/mach_msr.h	1970-01-01 00:00:00.000000000 +0000
+++ linux-2.6.12.3-vmi/include/asm-i386/mach-default/mach_msr.h	2005-11-15 16:57:30.000000000 +0000
@@ -0,0 +1,45 @@
+#ifndef MACH_MSR_H
+#define MACH_MSR_H
+
+#define rdmsr(msr,val1,val2) \
+	__asm__ __volatile__("rdmsr" \
+			  : "=a" (val1), "=d" (val2) \
+			  : "c" (msr))
+
+#define wrmsr(msr,val1,val2) \
+	__asm__ __volatile__("wrmsr" \
+			  : /* no outputs */ \
+			  : "c" (msr), "a" (val1), "d" (val2))
+
+/* wrmsr with exception handling */
+#define wrmsr_safe(msr,a,b) ({ int ret__;						\
+	asm volatile("2: wrmsr ; xorl %0,%0\n"						\
+		     "1:\n\t"								\
+		     ".section .fixup,\"ax\"\n\t"					\
+		     "3:  movl %4,%0 ; jmp 1b\n\t"					\
+		     ".previous\n\t"							\
+ 		     ".section __ex_table,\"a\"\n"					\
+		     "   .align 4\n\t"							\
+		     "   .long 	2b,3b\n\t"						\
+		     ".previous"							\
+		     : "=a" (ret__)							\
+		     : "c" (msr), "0" (a), "d" (b), "i" (-EFAULT));\
+	ret__; })
+
+#define rdtsc(low,high) \
+     __asm__ __volatile__("rdtsc" : "=a" (low), "=d" (high))
+
+#define rdtscl(low) \
+     __asm__ __volatile__("rdtsc" : "=a" (low) : : "edx")
+
+#define rdtscll(val) \
+     __asm__ __volatile__("rdtsc" : "=A" (val))
+
+#define write_tsc(val1,val2) wrmsr(0x10, val1, val2)
+
+#define rdpmc(counter,low,high) \
+     __asm__ __volatile__("rdpmc" \
+			  : "=a" (low), "=d" (high) \
+			  : "c" (counter))
+
+#endif
diff -Naur linux-2.6.12.3.pristine/include/asm-i386/mach-default/mach_pgalloc.h linux-2.6.12.3-vmi/include/asm-i386/mach-default/mach_pgalloc.h
--- linux-2.6.12.3.pristine/include/asm-i386/mach-default/mach_pgalloc.h	1970-01-01 00:00:00.000000000 +0000
+++ linux-2.6.12.3-vmi/include/asm-i386/mach-default/mach_pgalloc.h	2005-11-15 16:57:30.000000000 +0000
@@ -0,0 +1,46 @@
+/*
+ * Copyright (C) 2005, VMware, Inc.
+ *
+ * All rights reserved.
+ *
+ * This program is free software; you can redistribute it and/or modify
+ * it under the terms of the GNU General Public License as published by
+ * the Free Software Foundation; either version 2 of the License, or
+ * (at your option) any later version.
+ *
+ * This program is distributed in the hope that it will be useful, but
+ * WITHOUT ANY WARRANTY; without even the implied warranty of
+ * MERCHANTABILITY OR FITNESS FOR A PARTICULAR PURPOSE, GOOD TITLE or
+ * NON INFRINGEMENT.  See the GNU General Public License for more
+ * details.
+ *
+ * You should have received a copy of the GNU General Public License
+ * along with this program; if not, write to the Free Software
+ * Foundation, Inc., 675 Mass Ave, Cambridge, MA 02139, USA.
+ *
+ * Send feedback to zach@vmware.com
+ *
+ */
+
+#ifndef _MACH_PGALLOC_H
+#define _MACH_PGALLOC_H
+
+#define mach_use_pte(pfn)
+#define mach_unuse_pte(pfn)
+
+#define mach_use_pmd(pfn)
+#define mach_unuse_pmd(pfn)
+
+#define mach_use_pgd(pfn)
+#define mach_unuse_pgd(pfn)
+
+#define mach_map_pagetables(va, ppn, count)
+
+#define clone_pgd_range(dst, src, start, count) 	\
+do {							\
+       memcpy((pgd_t *)(dst) + (start),			\
+	      (pgd_t *)(src) + (start),			\
+	      (count) * sizeof(pgd_t));			\
+} while (0)
+
+#endif /* _MACH_PGALLOC_H */
diff -Naur linux-2.6.12.3.pristine/include/asm-i386/mach-default/mach_processor.h linux-2.6.12.3-vmi/include/asm-i386/mach-default/mach_processor.h
--- linux-2.6.12.3.pristine/include/asm-i386/mach-default/mach_processor.h	1970-01-01 00:00:00.000000000 +0000
+++ linux-2.6.12.3-vmi/include/asm-i386/mach-default/mach_processor.h	2005-11-15 16:57:30.000000000 +0000
@@ -0,0 +1,199 @@
+/*
+ * Copyright (C) 2005, VMware, Inc.
+ * Copyright (C) 1994 Linus Torvalds
+ *
+ * All rights reserved.
+ *
+ * This program is free software; you can redistribute it and/or modify
+ * it under the terms of the GNU General Public License as published by
+ * the Free Software Foundation; either version 2 of the License, or
+ * (at your option) any later version.
+ *
+ * This program is distributed in the hope that it will be useful, but
+ * WITHOUT ANY WARRANTY; without even the implied warranty of
+ * MERCHANTABILITY OR FITNESS FOR A PARTICULAR PURPOSE, GOOD TITLE or
+ * NON INFRINGEMENT.  See the GNU General Public License for more
+ * details.
+ *
+ * You should have received a copy of the GNU General Public License
+ * along with this program; if not, write to the Free Software
+ * Foundation, Inc., 675 Mass Ave, Cambridge, MA 02139, USA.
+ *
+ */
+
+#ifndef _MACH_PROCESSOR_H
+#define _MACH_PROCESSOR_H
+
+/*
+ * Generic CPUID function
+ * clear %ecx since some cpus (Cyrix MII) do not set or clear %ecx
+ * resulting in stale register contents being returned.
+ */
+static inline void cpuid(unsigned int op, unsigned int *eax, unsigned int *ebx, unsigned int *ecx, unsigned int *edx)
+{
+	__asm__("cpuid"
+		: "=a" (*eax),
+		  "=b" (*ebx),
+		  "=c" (*ecx),
+		  "=d" (*edx)
+		: "0" (op), "c"(0));
+}
+
+/* Some CPUID calls want 'count' to be placed in ecx */
+static inline void cpuid_count(int op, int count, int *eax, int *ebx, int *ecx,
+	       	int *edx)
+{
+	__asm__("cpuid"
+		: "=a" (*eax),
+		  "=b" (*ebx),
+		  "=c" (*ecx),
+		  "=d" (*edx)
+		: "0" (op), "c" (count));
+}
+
+/*
+ * CPUID functions returning a single datum
+ */
+static inline unsigned int cpuid_eax(unsigned int op)
+{
+	unsigned int eax;
+
+	__asm__("cpuid"
+		: "=a" (eax)
+		: "0" (op)
+		: "bx", "cx", "dx");
+	return eax;
+}
+static inline unsigned int cpuid_ebx(unsigned int op)
+{
+	unsigned int eax, ebx;
+
+	__asm__("cpuid"
+		: "=a" (eax), "=b" (ebx)
+		: "0" (op)
+		: "cx", "dx" );
+	return ebx;
+}
+static inline unsigned int cpuid_ecx(unsigned int op)
+{
+	unsigned int eax, ecx;
+
+	__asm__("cpuid"
+		: "=a" (eax), "=c" (ecx)
+		: "0" (op)
+		: "bx", "dx" );
+	return ecx;
+}
+static inline unsigned int cpuid_edx(unsigned int op)
+{
+	unsigned int eax, edx;
+
+	__asm__("cpuid"
+		: "=a" (eax), "=d" (edx)
+		: "0" (op)
+		: "bx", "cx");
+	return edx;
+}
+
+#define read_cr0() ({ \
+	unsigned int __dummy; \
+	__asm__ __volatile__( \
+		"movl %%cr0,%0\n\t" \
+		:"=r" (__dummy)); \
+	__dummy; \
+})
+#define write_cr0(x) \
+	__asm__ __volatile__("movl %0,%%cr0": :"r" (x));
+
+#define read_cr2() ({ \
+        unsigned int __dummy; \
+        __asm__ __volatile__( \
+                "movl %%cr2,%0\n\t" \
+                :"=r" (__dummy)); \
+        __dummy; \
+})
+#define write_cr2(x) \
+	__asm__("movl %0,%%cr2": :"r" (x));
+
+#define read_cr3() ({ \
+        unsigned int __dummy; \
+        __asm__( \
+                "movl %%cr3,%0\n\t" \
+                :"=r" (__dummy)); \
+        __dummy; \
+})
+#define write_cr3(x) \
+	__asm__ __volatile__("movl %0,%%cr3": :"r" (x));
+
+#define read_cr4() ({ \
+	unsigned int __dummy; \
+	__asm__( \
+		"movl %%cr4,%0\n\t" \
+		:"=r" (__dummy)); \
+	__dummy; \
+})
+#define write_cr4(x) \
+	__asm__ __volatile__("movl %0,%%cr4": :"r" (x));
+
+
+/*
+ * Clear and set 'TS' bit respectively
+ */
+#define clts() __asm__ __volatile__ ("clts")
+#define stts() write_cr0(8 | read_cr0())
+
+#define load_cr3(pgdir) write_cr3(__pa(pgdir))
+
+#define load_kernel_stack(tss, ss, esp) \
+do { \
+	((tss)->esp0) = (esp); \
+} while (0)
+
+#define mach_update_io_bitmap(tss)
+
+#define wbinvd() \
+	__asm__ __volatile__ ("wbinvd": : :"memory");
+
+/*
+ * This special macro can be used to load a debugging register
+ */
+#define loaddebug(thread,register) \
+       __asm__ __volatile__( \
+		"movl %0,%%db" #register  \
+	       : /* no output */ \
+	       :"r" ((thread)->debugreg[register]))
+
+#define clear_debug(register) \
+       __asm__ __volatile__( \
+		"movl %0,%%db" #register  \
+	       : /* no output */ \
+	       :"r" (0))
+
+#define read_debug(register) ({ \
+	unsigned int __dummy; \
+	__asm__ __volatile__ ( \
+		"movl %%db" #register ",%0\n\t" \
+		:"=r" (__dummy)); \
+	__dummy; \
+})
+
+/* used in the idle loop; sti holds off interrupts for 1 instruction */
+#define safe_halt()             __asm__ __volatile__("sti; hlt": : :"memory")
+
+/* halt until interrupted */
+#define halt()			__asm__ __volatile__("hlt")
+
+static inline void set_iopl_mask(unsigned mask)
+{
+	unsigned int reg;
+	__asm__ __volatile__ ("pushfl;"
+			      "popl %0;"
+			      "andl %1, %0;"
+			      "orl %2, %0;"
+			      "pushl %0;"
+			      "popfl"
+				: "=&r" (reg)
+				: "i" (~X86_EFLAGS_IOPL), "r" (mask));
+}
+
+#endif
diff -Naur linux-2.6.12.3.pristine/include/asm-i386/mach-default/mach_segment.h linux-2.6.12.3-vmi/include/asm-i386/mach-default/mach_segment.h
--- linux-2.6.12.3.pristine/include/asm-i386/mach-default/mach_segment.h	1970-01-01 00:00:00.000000000 +0000
+++ linux-2.6.12.3-vmi/include/asm-i386/mach-default/mach_segment.h	2005-11-15 16:57:30.000000000 +0000
@@ -0,0 +1,32 @@
+/*
+ * Copyright (C) 2005, VMware, Inc.
+ *
+ * All rights reserved.
+ *
+ * This program is free software; you can redistribute it and/or modify
+ * it under the terms of the GNU General Public License as published by
+ * the Free Software Foundation; either version 2 of the License, or
+ * (at your option) any later version.
+ *
+ * This program is distributed in the hope that it will be useful, but
+ * WITHOUT ANY WARRANTY; without even the implied warranty of
+ * MERCHANTABILITY OR FITNESS FOR A PARTICULAR PURPOSE, GOOD TITLE or
+ * NON INFRINGEMENT.  See the GNU General Public License for more
+ * details.
+ *
+ * You should have received a copy of the GNU General Public License
+ * along with this program; if not, write to the Free Software
+ * Foundation, Inc., 675 Mass Ave, Cambridge, MA 02139, USA.
+ *
+ * Send feedback to zach@vmware.com
+ *
+ */
+
+
+#ifndef __MACH_SEGMENT_H
+#define __MACH_SEGMENT_H
+
+#define is_kernel_cs(cs)		(((cs) & 3) != 3)
+#define make_kernel_segment(seg)	(seg)
+
+#endif
diff -Naur linux-2.6.12.3.pristine/include/asm-i386/mach-default/mach_tlbflush.h linux-2.6.12.3-vmi/include/asm-i386/mach-default/mach_tlbflush.h
--- linux-2.6.12.3.pristine/include/asm-i386/mach-default/mach_tlbflush.h	1970-01-01 00:00:00.000000000 +0000
+++ linux-2.6.12.3-vmi/include/asm-i386/mach-default/mach_tlbflush.h	2005-11-15 16:57:30.000000000 +0000
@@ -0,0 +1,61 @@
+/*
+ * Copyright (C) 2005, VMware, Inc.
+ *
+ * All rights reserved.
+ *
+ * This program is free software; you can redistribute it and/or modify
+ * it under the terms of the GNU General Public License as published by
+ * the Free Software Foundation; either version 2 of the License, or
+ * (at your option) any later version.
+ *
+ * This program is distributed in the hope that it will be useful, but
+ * WITHOUT ANY WARRANTY; without even the implied warranty of
+ * MERCHANTABILITY OR FITNESS FOR A PARTICULAR PURPOSE, GOOD TITLE or
+ * NON INFRINGEMENT.  See the GNU General Public License for more
+ * details.
+ *
+ * You should have received a copy of the GNU General Public License
+ * along with this program; if not, write to the Free Software
+ * Foundation, Inc., 675 Mass Ave, Cambridge, MA 02139, USA.
+ *
+ * Send feedback to zach@vmware.com
+ *
+ */
+ 
+#ifndef _MACH_TLBFLUSH_H
+#define _MACH_TLBFLUSH_H
+
+#define __flush_tlb()							\
+	do {								\
+		unsigned int tmpreg;					\
+									\
+		__asm__ __volatile__(					\
+			"movl %%cr3, %0;              \n"		\
+			"movl %0, %%cr3;  # flush TLB \n"		\
+			: "=r" (tmpreg)					\
+			:: "memory");					\
+	} while (0)
+
+/*
+ * Global pages have to be flushed a bit differently. Not a real
+ * performance problem because this does not happen often.
+ */
+#define __flush_tlb_global()						\
+	do {								\
+		unsigned int tmpreg;					\
+									\
+		__asm__ __volatile__(					\
+			"movl %1, %%cr4;  # turn off PGE     \n"	\
+			"movl %%cr3, %0;                     \n"	\
+			"movl %0, %%cr3;  # flush TLB        \n"	\
+			"movl %2, %%cr4;  # turn PGE back on \n"	\
+			: "=&r" (tmpreg)				\
+			: "r" (mmu_cr4_features & ~X86_CR4_PGE),	\
+			  "r" (mmu_cr4_features)			\
+			: "memory");					\
+	} while (0)
+
+#define __flush_tlb_single(addr) \
+	__asm__ __volatile__("invlpg %0": :"m" (*(char *) addr))
+
+#endif /* _MACH_TLBFLUSH_H */
diff -Naur linux-2.6.12.3.pristine/include/asm-i386/mach-default/pgtable-2level-ops.h linux-2.6.12.3-vmi/include/asm-i386/mach-default/pgtable-2level-ops.h
--- linux-2.6.12.3.pristine/include/asm-i386/mach-default/pgtable-2level-ops.h	1970-01-01 00:00:00.000000000 +0000
+++ linux-2.6.12.3-vmi/include/asm-i386/mach-default/pgtable-2level-ops.h	2005-12-14 20:47:00.000000000 +0000
@@ -0,0 +1,18 @@
+#ifndef _MACH_PGTABLE_LEVEL_OPS_H
+#define _MACH_PGTABLE_LEVEL_OPS_H
+
+/*
+ * Certain architectures need to do special things when PTEs
+ * within a page table are directly modified.  Thus, the following
+ * hook is made available.
+ */
+#define set_pte(pteptr, pteval) (*(pteptr) = pteval)
+#define set_pte_atomic(pteptr, pteval) set_pte(pteptr,pteval)
+#define set_pmd(pmdptr, pmdval) (*(pmdptr) = (pmdval))
+
+#define pgd_val(x)	((x).pgd)
+#define pte_pfn(x)	((unsigned long)(((x).pte_low >> PAGE_SHIFT)))
+
+#define ptep_get_and_clear(mm,addr,xp)	__pte(xchg(&(xp)->pte_low, 0))
+
+#endif /* _PGTABLE_OPS_H */
diff -Naur linux-2.6.12.3.pristine/include/asm-i386/mach-default/pgtable-3level-ops.h linux-2.6.12.3-vmi/include/asm-i386/mach-default/pgtable-3level-ops.h
--- linux-2.6.12.3.pristine/include/asm-i386/mach-default/pgtable-3level-ops.h	1970-01-01 00:00:00.000000000 +0000
+++ linux-2.6.12.3-vmi/include/asm-i386/mach-default/pgtable-3level-ops.h	2005-11-15 16:57:30.000000000 +0000
@@ -0,0 +1,36 @@
+#ifndef _MACH_PGTABLE_LEVEL_OPS_H
+#define _MACH_PGTABLE_LEVEL_OPS_H
+
+/* Rules for using set_pte: the pte being assigned *must* be
+ * either not present or in a state where the hardware will
+ * not attempt to update the pte.  In places where this is
+ * not possible, use pte_get_and_clear to obtain the old pte
+ * value and then use set_pte to update it.  -ben
+ */
+static inline void set_pte(pte_t *ptep, pte_t pte)
+{
+	ptep->pte_high = pte.pte_high;
+	smp_wmb();
+	ptep->pte_low = pte.pte_low;
+}
+#define __HAVE_ARCH_SET_PTE_ATOMIC
+#define set_pte_atomic(pteptr,pteval) \
+		set_64bit((unsigned long long *)(pteptr),pte_val(pteval))
+#define set_pmd(pmdptr,pmdval) \
+		set_64bit((unsigned long long *)(pmdptr),pmd_val(pmdval))
+#define set_pud(pudptr,pudval) \
+		set_64bit((unsigned long long *)(pudptr),pud_val(pudval))
+
+static inline pte_t ptep_get_and_clear(struct mm_struct *mm, unsigned long addr, pte_t *ptep)
+{
+	pte_t res;
+
+	/* xchg acts as a barrier before the setting of the high bits */
+	res.pte_low = xchg(&ptep->pte_low, 0);
+	res.pte_high = ptep->pte_high;
+	ptep->pte_high = 0;
+
+	return res;
+}
+
+#endif
diff -Naur linux-2.6.12.3.pristine/include/asm-i386/mach-default/pgtable-ops.h linux-2.6.12.3-vmi/include/asm-i386/mach-default/pgtable-ops.h
--- linux-2.6.12.3.pristine/include/asm-i386/mach-default/pgtable-ops.h	1970-01-01 00:00:00.000000000 +0000
+++ linux-2.6.12.3-vmi/include/asm-i386/mach-default/pgtable-ops.h	2005-11-15 16:57:30.000000000 +0000
@@ -0,0 +1,74 @@
+/*
+ * Copyright (C) 2005, VMware, Inc.
+ *
+ * All rights reserved.
+ *
+ * This program is free software; you can redistribute it and/or modify
+ * it under the terms of the GNU General Public License as published by
+ * the Free Software Foundation; either version 2 of the License, or
+ * (at your option) any later version.
+ *
+ * This program is distributed in the hope that it will be useful, but
+ * WITHOUT ANY WARRANTY; without even the implied warranty of
+ * MERCHANTABILITY OR FITNESS FOR A PARTICULAR PURPOSE, GOOD TITLE or
+ * NON INFRINGEMENT.  See the GNU General Public License for more
+ * details.
+ *
+ * You should have received a copy of the GNU General Public License
+ * along with this program; if not, write to the Free Software
+ * Foundation, Inc., 675 Mass Ave, Cambridge, MA 02139, USA.
+ *
+ * Send feedback to zach@vmware.com
+ *
+ */
+
+#ifndef _PGTABLE_OPS_H
+#define _PGTABLE_OPS_H
+
+#ifdef CONFIG_X86_PAE
+# include <pgtable-3level-ops.h>
+#else
+# include <pgtable-2level-ops.h>
+#endif
+
+static inline int ptep_test_and_clear_dirty(struct vm_area_struct *vma, unsigned long addr, pte_t *ptep)
+{
+	if (!pte_dirty(*ptep))
+		return 0;
+	return test_and_clear_bit(_PAGE_BIT_DIRTY, &ptep->pte_low);
+}
+
+static inline int ptep_test_and_clear_young(struct vm_area_struct *vma, unsigned long addr, pte_t *ptep)
+{
+	if (!pte_young(*ptep))
+		return 0;
+	return test_and_clear_bit(_PAGE_BIT_ACCESSED, &ptep->pte_low);
+}
+
+static inline void ptep_set_wrprotect(struct mm_struct *mm, unsigned long addr, pte_t *ptep)
+{
+	clear_bit(_PAGE_BIT_RW, &ptep->pte_low);
+}
+
+/*
+ * The i386 doesn't have any external MMU info: the kernel page
+ * tables contain all the necessary information.
+ *
+ * Also, we only update the dirty/accessed state if we set
+ * the dirty bit by hand in the kernel, since the hardware
+ * will do the accessed bit for us, and we don't want to
+ * race with other CPU's that might be updating the dirty
+ * bit at the same time.
+ */
+#define update_mmu_cache(vma,address,pte) do { } while (0)
+
+#define  __HAVE_ARCH_PTEP_SET_ACCESS_FLAGS
+#define ptep_set_access_flags(__vma, __address, __ptep, __entry, __dirty) \
+	do {								  \
+		if (__dirty) {						  \
+			(__ptep)->pte_low = (__entry).pte_low;	  	  \
+			flush_tlb_page(__vma, __address);		  \
+		}							  \
+	} while (0)
+
+#endif /* _PGTABLE_OPS_H */
diff -Naur linux-2.6.12.3.pristine/include/asm-i386/mach-default/setup_arch_post.h linux-2.6.12.3-vmi/include/asm-i386/mach-default/setup_arch_post.h
--- linux-2.6.12.3.pristine/include/asm-i386/mach-default/setup_arch_post.h	2005-07-15 21:18:57.000000000 +0000
+++ linux-2.6.12.3-vmi/include/asm-i386/mach-default/setup_arch_post.h	2005-11-15 16:57:30.000000000 +0000
@@ -10,7 +10,6 @@
 {
 	char *who;
 
-
 	who = "BIOS-e820";
 
 	/*
diff -Naur linux-2.6.12.3.pristine/include/asm-i386/mach-vmi/mach-vmlinux.lds.h linux-2.6.12.3-vmi/include/asm-i386/mach-vmi/mach-vmlinux.lds.h
--- linux-2.6.12.3.pristine/include/asm-i386/mach-vmi/mach-vmlinux.lds.h	1970-01-01 00:00:00.000000000 +0000
+++ linux-2.6.12.3-vmi/include/asm-i386/mach-vmi/mach-vmlinux.lds.h	2005-11-15 16:57:30.000000000 +0000
@@ -0,0 +1,54 @@
+/*
+ * Copyright (C) 2005, VMware, Inc.
+ *
+ * All rights reserved.
+ *
+ * This program is free software; you can redistribute it and/or modify
+ * it under the terms of the GNU General Public License as published by
+ * the Free Software Foundation; either version 2 of the License, or
+ * (at your option) any later version.
+ *
+ * This program is distributed in the hope that it will be useful, but
+ * WITHOUT ANY WARRANTY; without even the implied warranty of
+ * MERCHANTABILITY OR FITNESS FOR A PARTICULAR PURPOSE, GOOD TITLE or
+ * NON INFRINGEMENT.  See the GNU General Public License for more
+ * details.
+ *
+ * You should have received a copy of the GNU General Public License
+ * along with this program; if not, write to the Free Software
+ * Foundation, Inc., 675 Mass Ave, Cambridge, MA 02139, USA.
+ *
+ * Send feedback to zach@vmware.com
+ *
+ */
+
+#include <vmiCalls.h>
+
+#define VMI_SPACE(name, ...) \
+	. = __VMI_NEXT; \
+	__VMI_NEXT = . + 32; \
+	.text.VMI_##name : { *(.text.VMI_##name) }
+			 
+#define VMI_FUNC(name, ...) \
+	. = __VMI_NEXT; \
+	__VMI_NEXT = . + 32; \
+	.text.VMI_##name : { *(.text.VMI_##name) }
+			 
+#define VMI_PROC(name, ...) \
+	. = __VMI_NEXT; \
+	__VMI_NEXT = . + 32; \
+	.text.VMI_##name : { *(.text.VMI_##name) }
+			 
+#define VMI_JUMP(name, ...) \
+	. = __VMI_NEXT; \
+	__VMI_NEXT = . + 32; \
+	.text.VMI_##name : { *(.text.VMI_##name) }
+			 
+#define MACH_TEXT \
+. = ALIGN(4096); \
+__VMI_START = .; \
+__VMI_NEXT = .;  \
+__VMI_END = . + 16384; \
+VMI_CALLS \
+. = __VMI_END; \
+. = ALIGN(4096);
diff -Naur linux-2.6.12.3.pristine/include/asm-i386/mach-vmi/mach_asm.h linux-2.6.12.3-vmi/include/asm-i386/mach-vmi/mach_asm.h
--- linux-2.6.12.3.pristine/include/asm-i386/mach-vmi/mach_asm.h	1970-01-01 00:00:00.000000000 +0000
+++ linux-2.6.12.3-vmi/include/asm-i386/mach-vmi/mach_asm.h	2005-11-15 16:57:30.000000000 +0000
@@ -0,0 +1,15 @@
+#ifndef __MACH_ASM_H
+#define __MACH_ASM_H
+
+#define IRET		jmp  VMI_IRET
+#define IRET16		jmp  VMI_IRET16
+#define CLI		call VMI_CLI
+#define STI		call VMI_STI
+#define STI_SYSEXIT	jmp  VMI_StiSysexit
+#define MASK_RPL(reg)	and  $~3, reg
+#define GET_CR0		call VMI_GetCR0
+#define WRMSR		call VMI_WRMSR
+#define RDMSR		call VMI_RDMSR
+#define CPUID		call VMI_CPUID
+
+#endif /* __MACH_ASM_H */
diff -Naur linux-2.6.12.3.pristine/include/asm-i386/mach-vmi/mach_desc.h linux-2.6.12.3-vmi/include/asm-i386/mach-vmi/mach_desc.h
--- linux-2.6.12.3.pristine/include/asm-i386/mach-vmi/mach_desc.h	1970-01-01 00:00:00.000000000 +0000
+++ linux-2.6.12.3-vmi/include/asm-i386/mach-vmi/mach_desc.h	2005-11-15 16:57:30.000000000 +0000
@@ -0,0 +1,87 @@
+/*
+ * Copyright (C) 2005, VMware, Inc.
+ *
+ * All rights reserved.
+ *
+ * This program is free software; you can redistribute it and/or modify
+ * it under the terms of the GNU General Public License as published by
+ * the Free Software Foundation; either version 2 of the License, or
+ * (at your option) any later version.
+ *
+ * This program is distributed in the hope that it will be useful, but
+ * WITHOUT ANY WARRANTY; without even the implied warranty of
+ * MERCHANTABILITY OR FITNESS FOR A PARTICULAR PURPOSE, GOOD TITLE or
+ * NON INFRINGEMENT.  See the GNU General Public License for more
+ * details.
+ *
+ * You should have received a copy of the GNU General Public License
+ * along with this program; if not, write to the Free Software
+ * Foundation, Inc., 675 Mass Ave, Cambridge, MA 02139, USA.
+ *
+ * Send feedback to zach@vmware.com
+ *
+ */
+	
+#ifndef __MACH_DESC_H
+#define __MACH_DESC_H
+
+#include <vmi.h>
+
+#if !defined(CONFIG_X86_VMI)
+# error invalid sub-arch include
+#endif
+
+#define load_TR_desc() vmi_SetTR(GDT_ENTRY_TSS << 3)
+#define load_LDT_desc() vmi_SetLDT(GDT_ENTRY_LDT << 3)
+
+#define load_gdt(dtr) vmi_SetGDT(dtr)
+#define load_idt(dtr) vmi_SetIDT(dtr)
+#define load_tr(desc) vmi_SetTR(desc)
+#define load_ldt(desc) vmi_SetLDT(desc)
+
+#define store_gdt(dtr) vmi_GetGDT(dtr)
+#define store_idt(dtr) vmi_GetIDT(dtr)
+#define store_tr(tr) do { (tr) = vmi_GetTR(); } while (0)
+#define store_ldt(ldt) do { (ldt) = vmi_GetLDT(); } while (0)
+
+#define get_TR_desc() vmi_GetTR()
+#define get_LDT_desc() vmi_GetLDT()
+
+static inline void __set_tss_desc(unsigned int cpu, unsigned int entry, void *addr)
+{
+	_set_tssldt_desc(&per_cpu(cpu_gdt_table, cpu)[entry], (int)addr,
+		offsetof(struct tss_struct, __cacheline_filler) - 1, 0x89);
+        vmi_UpdateGDT(entry, entry);
+}
+
+static inline void set_ldt_desc(unsigned int cpu, void *addr, unsigned int size)
+{
+	_set_tssldt_desc(&per_cpu(cpu_gdt_table, cpu)[GDT_ENTRY_LDT], (int)addr, ((size << 3)-1), 0x82);
+        vmi_UpdateGDT(GDT_ENTRY_LDT, GDT_ENTRY_LDT);
+}
+
+#if TLS_SIZE != 24
+# error update this code.
+#endif
+
+static inline void load_TLS(struct thread_struct *t, unsigned int cpu)
+{
+	unsigned first = 0;
+	unsigned last = 0;
+	unsigned i;
+	for (i = 0; i < 3; i++) {
+		unsigned cur = i + GDT_ENTRY_TLS_MIN;
+		if (per_cpu(cpu_gdt_table, cpu)[cur].a != t->tls_array[i].a ||
+		    per_cpu(cpu_gdt_table, cpu)[cur].b != t->tls_array[i].b) {
+			per_cpu(cpu_gdt_table, cpu)[cur] = t->tls_array[i]; 
+			last = cur;
+			if (!first)
+				first = cur;
+		}
+        }
+	if (first != 0) {
+		vmi_UpdateGDT(first, last);
+	}
+}
+
+#endif
diff -Naur linux-2.6.12.3.pristine/include/asm-i386/mach-vmi/mach_io.h linux-2.6.12.3-vmi/include/asm-i386/mach-vmi/mach_io.h
--- linux-2.6.12.3.pristine/include/asm-i386/mach-vmi/mach_io.h	1970-01-01 00:00:00.000000000 +0000
+++ linux-2.6.12.3-vmi/include/asm-i386/mach-vmi/mach_io.h	2005-11-15 16:57:30.000000000 +0000
@@ -0,0 +1,36 @@
+#ifdef PRE_VMI
+#include <../mach-default/mach_io.h>
+#else
+#ifndef _MACH_ASM_IO_H
+#define _MACH_ASM_IO_H
+
+#include <vmi.h>
+
+#define __BUILDOUTINST(bwl,bw,value,port) \
+	__asm__ __volatile__("call VMI_Out"#bwl : : "a"(value), "d"(port) : "cc")
+#define	__BUILDININST(bwl,bw,value,port) \
+	__asm__ __volatile__("call VMI_In"#bwl : "=a"(value) : "d"(port) : "cc")
+#define	__BUILDOUTSINST(bwl,addr,count,port) \
+	__asm__ __volatile__("call VMI_Outs"#bwl \
+			     : "+S"(addr), "+c"(count) \
+			     : "d"(port) \
+			     : "cc")
+#define	__BUILDINSINST(bwl,addr,count,port) \
+	__asm__ __volatile__("call VMI_Ins"#bwl \
+			     : "+D"(addr), "+c"(count) \
+			     : "d"(port) \
+			     : "cc", "memory")
+
+#define virt_to_bus(virt) vmi_PhysToMachine(virt_to_phys(virt))
+#define bus_to_virt(bus)  phys_to_virt(vmi_MachineToPhys(bus))
+#define page_to_bus(page) vmi_PhysToMachine(page_to_phys(page))
+
+/*
+ * ISA I/O bus memory addresses are 1:1 with the physical address.
+ */
+#define isa_virt_to_bus virt_to_bus
+#define isa_page_to_bus page_to_bus
+#define isa_bus_to_virt bus_to_virt
+
+#endif
+#endif
diff -Naur linux-2.6.12.3.pristine/include/asm-i386/mach-vmi/mach_irqcontrol.h linux-2.6.12.3-vmi/include/asm-i386/mach-vmi/mach_irqcontrol.h
--- linux-2.6.12.3.pristine/include/asm-i386/mach-vmi/mach_irqcontrol.h	1970-01-01 00:00:00.000000000 +0000
+++ linux-2.6.12.3-vmi/include/asm-i386/mach-vmi/mach_irqcontrol.h	2005-11-15 16:57:30.000000000 +0000
@@ -0,0 +1,35 @@
+/*
+ * Copyright (C) 2005, VMware, Inc.
+ *
+ * All rights reserved.
+ *
+ * This program is free software; you can redistribute it and/or modify
+ * it under the terms of the GNU General Public License as published by
+ * the Free Software Foundation; either version 2 of the License, or
+ * (at your option) any later version.
+ *
+ * This program is distributed in the hope that it will be useful, but
+ * WITHOUT ANY WARRANTY; without even the implied warranty of
+ * MERCHANTABILITY OR FITNESS FOR A PARTICULAR PURPOSE, GOOD TITLE or
+ * NON INFRINGEMENT.  See the GNU General Public License for more
+ * details.
+ *
+ * You should have received a copy of the GNU General Public License
+ * along with this program; if not, write to the Free Software
+ * Foundation, Inc., 675 Mass Ave, Cambridge, MA 02139, USA.
+ *
+ * Send feedback to zach@vmware.com
+ *
+ */
+
+#ifndef _MACH_IRQCONTROL_H
+#define _MACH_IRQCONTROL_H
+
+#define local_save_flags(x)     do { typecheck(unsigned long,x); (x) = vmi_GetEFLAGS(); } while (0)
+#define local_irq_restore(x)    do { typecheck(unsigned long,x); vmi_SetEFLAGS(x); } while (0)
+#define local_irq_disable()     vmi_CLI()
+#define local_irq_enable()      vmi_STI()
+#define local_irq_save(x) 	do { typecheck(unsigned long,x); (x) = vmi_SaveAndDisableIRQs(); } while (0)
+
+#endif /* _MACH_IRQCONTROL_H */
+
diff -Naur linux-2.6.12.3.pristine/include/asm-i386/mach-vmi/mach_msr.h linux-2.6.12.3-vmi/include/asm-i386/mach-vmi/mach_msr.h
--- linux-2.6.12.3.pristine/include/asm-i386/mach-vmi/mach_msr.h	1970-01-01 00:00:00.000000000 +0000
+++ linux-2.6.12.3-vmi/include/asm-i386/mach-vmi/mach_msr.h	2005-11-15 16:57:30.000000000 +0000
@@ -0,0 +1,69 @@
+#ifndef MACH_MSR_H
+#define MACH_MSR_H
+
+#define rdmsr(msr,val1,val2) \
+do { \
+	__asm__ __volatile__("call VMI_RDMSR" \
+			: "=a" (val1), "=d" (val2) \
+			: "c" (msr) \
+			: "cc"); \
+} while (0)
+
+#define wrmsr(msr,val1,val2) \
+do { \
+	__asm__ __volatile__("call VMI_WRMSR" \
+			: \
+			: "c" (msr), "a" (val1), "d" (val2) \
+			: "cc"); \
+} while (0)
+
+/* wrmsr with exception handling - use trap and emulate for now */
+#define wrmsr_safe(msr,a,b) ({ int ret__;						\
+	asm volatile("2: wrmsr ; xorl %0,%0\n"						\
+		     "1:\n\t"								\
+		     ".section .fixup,\"ax\"\n\t"					\
+		     "3:  movl %4,%0 ; jmp 1b\n\t"					\
+		     ".previous\n\t"							\
+ 		     ".section __ex_table,\"a\"\n"					\
+		     "   .align 4\n\t"							\
+		     "   .long 	2b,3b\n\t"						\
+		     ".previous"							\
+		     : "=a" (ret__)							\
+		     : "c" (msr), "0" (a), "d" (b), "i" (-EFAULT));\
+	ret__; })
+
+#define rdtsc(low,high) \
+do { \
+	__asm__ __volatile__("call VMI_RDTSC" \
+			: "=a" (low), "=d" (high) \
+			: \
+			: "cc"); \
+} while (0)
+
+#define rdtscl(low) \
+do { \
+	__asm__ __volatile__("call VMI_RDTSC" \
+			: "=a" (low) \
+			: \
+			: "edx", "cc"); \
+} while (0)
+
+#define rdtscll(val) \
+do { \
+	__asm__ __volatile__("call VMI_RDTSC" \
+			: "=A" (val) \
+			: \
+			: "cc"); \
+} while (0)
+
+#define write_tsc(val1,val2) wrmsr(0x10, val1, val2)
+
+#define rdpmc(counter,low,high) \
+do { \
+     	__asm__ __volatile__("call VMI_RDPMC" \
+			: "=a" (low), "=d" (high) \
+			: "c" (counter) \
+			: "cc"); \
+} while (0)
+
+#endif
diff -Naur linux-2.6.12.3.pristine/include/asm-i386/mach-vmi/mach_pgalloc.h linux-2.6.12.3-vmi/include/asm-i386/mach-vmi/mach_pgalloc.h
--- linux-2.6.12.3.pristine/include/asm-i386/mach-vmi/mach_pgalloc.h	1970-01-01 00:00:00.000000000 +0000
+++ linux-2.6.12.3-vmi/include/asm-i386/mach-vmi/mach_pgalloc.h	2005-11-15 16:57:30.000000000 +0000
@@ -0,0 +1,67 @@
+/*
+ * Copyright (C) 2005, VMware, Inc.
+ *
+ * All rights reserved.
+ *
+ * This program is free software; you can redistribute it and/or modify
+ * it under the terms of the GNU General Public License as published by
+ * the Free Software Foundation; either version 2 of the License, or
+ * (at your option) any later version.
+ *
+ * This program is distributed in the hope that it will be useful, but
+ * WITHOUT ANY WARRANTY; without even the implied warranty of
+ * MERCHANTABILITY OR FITNESS FOR A PARTICULAR PURPOSE, GOOD TITLE or
+ * NON INFRINGEMENT.  See the GNU General Public License for more
+ * details.
+ *
+ * You should have received a copy of the GNU General Public License
+ * along with this program; if not, write to the Free Software
+ * Foundation, Inc., 675 Mass Ave, Cambridge, MA 02139, USA.
+ *
+ * Send feedback to zach@vmware.com
+ *
+ */
+
+#ifndef _MACH_PGALLOC_H
+#define _MACH_PGALLOC_H
+
+#include <vmi.h>
+
+#ifndef CONFIG_X86_PAE
+#define mach_use_pte(pfn) vmi_RegisterPageUsage(pfn, VMI_PAGE_PT)
+#define mach_unuse_pte(pfn) vmi_ReleasePage(pfn, VMI_PAGE_PT)
+
+#define mach_use_pmd(pfn)
+#define mach_unuse_pmd(pfn) 
+
+#define mach_use_pgd(pfn, root, base, count) \
+        vmi_ClonePageDirectory(pfn, root, VMI_MKCLONE(base, count))
+#define mach_unuse_pgd(pfn) vmi_ReleasePage(pfn, VMI_PAGE_PD)
+
+#else /* CONFIG_X86_PAE */
+
+#define mach_use_pte(pfn) vmi_RegisterPageUsage(pfn, VMI_PAGE_PAE_PT)
+#define mach_unuse_pte(pfn) vmi_ReleasePage(pfn, VMI_PAGE_PAE_PT)
+
+#define mach_use_pmd(pfn) vmi_RegisterPageUsage(pfn, VMI_PAGE_PAE_PD)
+#define mach_unuse_pmd(pfn) vmi_ReleasePage(pfn, VMI_PAGE_PAE_PD)
+
+#define mach_use_pgd(pfn, root, base, count) \
+        vmi_RegisterPageUsage(pfn, VMI_PAGE_PDP)
+#define mach_unuse_pgd(pfn) vmi_ReleasePage(pfn, VMI_PAGE_PDP)
+
+#endif
+
+#define mach_map_pagetables(va, ppn, count) \
+	vmi_RegisterPageMapping(va, ppn, count)
+
+#define clone_pgd_range(dst, src, start, count) 			\
+do {									\
+	memcpy((pgd_t *)(dst) + (start),				\
+	      (pgd_t *)(src) + (start),					\
+	      (count) * sizeof(pgd_t));					\
+	mach_use_pgd(__pa(dst) >> PAGE_SHIFT, __pa(src) >> PAGE_SHIFT,	\
+		     start, count); 					\
+} while (0)
+
+#endif /* _MACH_PGALLOC_H */
diff -Naur linux-2.6.12.3.pristine/include/asm-i386/mach-vmi/mach_processor.h linux-2.6.12.3-vmi/include/asm-i386/mach-vmi/mach_processor.h
--- linux-2.6.12.3.pristine/include/asm-i386/mach-vmi/mach_processor.h	1970-01-01 00:00:00.000000000 +0000
+++ linux-2.6.12.3-vmi/include/asm-i386/mach-vmi/mach_processor.h	2005-11-15 16:57:30.000000000 +0000
@@ -0,0 +1,143 @@
+/*
+ * Copyright (C) 2005, VMware, Inc.
+ *
+ * All rights reserved.
+ *
+ * This program is free software; you can redistribute it and/or modify
+ * it under the terms of the GNU General Public License as published by
+ * the Free Software Foundation; either version 2 of the License, or
+ * (at your option) any later version.
+ *
+ * This program is distributed in the hope that it will be useful, but
+ * WITHOUT ANY WARRANTY; without even the implied warranty of
+ * MERCHANTABILITY OR FITNESS FOR A PARTICULAR PURPOSE, GOOD TITLE or
+ * NON INFRINGEMENT.  See the GNU General Public License for more
+ * details.
+ *
+ * You should have received a copy of the GNU General Public License
+ * along with this program; if not, write to the Free Software
+ * Foundation, Inc., 675 Mass Ave, Cambridge, MA 02139, USA.
+ *
+ * Send feedback to zach@vmware.com
+ *
+ */
+
+
+#ifndef _MACH_PROCESSOR_H
+#define _MACH_PROCESSOR_H
+
+#include <vmi.h>
+
+/*
+ * Generic CPUID function
+ * clear %ecx since some cpus (Cyrix MII) do not set or clear %ecx
+ * resulting in stale register contents being returned.
+ */
+static inline void cpuid(unsigned int op, unsigned int *eax, unsigned int *ebx, unsigned int *ecx, unsigned int *edx)
+{
+	__asm__("call VMI_CPUID"
+		: "=a" (*eax),
+		  "=b" (*ebx),
+		  "=c" (*ecx),
+		  "=d" (*edx)
+		: "0" (op), "c"(0)
+		: "cc" );
+}
+
+/* Some CPUID calls want 'count' to be placed in ecx */
+static inline void cpuid_count(int op, int count, int *eax, int *ebx, int *ecx,
+	       	int *edx)
+{
+	__asm__("call VMI_CPUID"
+		: "=a" (*eax),
+		  "=b" (*ebx),
+		  "=c" (*ecx),
+		  "=d" (*edx)
+		: "0" (op), "c" (count)
+		: "cc" );
+}
+
+/*
+ * CPUID functions returning a single datum
+ */
+static inline unsigned int cpuid_eax(unsigned int op)
+{
+	unsigned int eax;
+
+	__asm__("call VMI_CPUID"
+		: "=a" (eax)
+		: "0" (op)
+		: "bx", "cx", "dx", "cc" );
+	return eax;
+}
+static inline unsigned int cpuid_ebx(unsigned int op)
+{
+	unsigned int eax, ebx;
+
+	__asm__("call VMI_CPUID"
+		: "=a" (eax), "=b" (ebx)
+		: "0" (op)
+		: "cx", "dx", "cc" );
+	return ebx;
+}
+static inline unsigned int cpuid_ecx(unsigned int op)
+{
+	unsigned int eax, ecx;
+
+	__asm__("call VMI_CPUID"
+		: "=a" (eax), "=c" (ecx)
+		: "0" (op)
+		: "bx", "dx", "cc" );
+	return ecx;
+}
+static inline unsigned int cpuid_edx(unsigned int op)
+{
+	unsigned int eax, edx;
+
+	__asm__("call VMI_CPUID"
+		: "=a" (eax), "=d" (edx)
+		: "0" (op)
+		: "bx", "cx", "cc" );
+	return edx;
+}
+
+#define read_cr0() vmi_GetCR0() 
+#define read_cr2() vmi_GetCR2() 
+#define read_cr3() vmi_GetCR3()
+#define read_cr4() vmi_GetCR4()
+
+#define write_cr0(val) vmi_SetCR0(val)
+#define write_cr2(val) vmi_SetCR2(val)
+#define write_cr3(val) vmi_SetCR3(val)
+#define write_cr4(val) vmi_SetCR4(val)
+
+#define stts() vmi_STTS()
+#define clts() vmi_CLTS()
+
+#define load_cr3(pgdir) vmi_SetCR3(__pa(pgdir))
+
+#define load_kernel_stack(tss, ss, esp) \
+do { \
+	((tss)->esp0) = (esp); \
+	vmi_UpdateKernelStack(ss, (void *)esp); \
+} while (0)
+
+#define mach_update_io_bitmap(tss) vmi_UpdateIOBitmap()
+
+#define wbinvd() vmi_WBINVD()
+
+#define loaddebug(thread,register) \
+	vmi_SetDR((register),(thread)->debugreg[register]) 
+
+#define clear_debug(register) \
+	vmi_SetDR((register), 0) 
+
+#define read_debug(register) \
+	vmi_GetDR(register) 
+
+#define safe_halt()             vmi_SafeHalt()
+#define halt()			vmi_Halt()
+
+#define set_iopl_mask(m)	vmi_SetIOPLMask(m)
+
+#endif
diff -Naur linux-2.6.12.3.pristine/include/asm-i386/mach-vmi/mach_segment.h linux-2.6.12.3-vmi/include/asm-i386/mach-vmi/mach_segment.h
--- linux-2.6.12.3.pristine/include/asm-i386/mach-vmi/mach_segment.h	1970-01-01 00:00:00.000000000 +0000
+++ linux-2.6.12.3-vmi/include/asm-i386/mach-vmi/mach_segment.h	2005-11-15 16:57:30.000000000 +0000
@@ -0,0 +1,52 @@
+/*
+ * Copyright (C) 2005, VMware, Inc.
+ *
+ * All rights reserved.
+ *
+ * This program is free software; you can redistribute it and/or modify
+ * it under the terms of the GNU General Public License as published by
+ * the Free Software Foundation; either version 2 of the License, or
+ * (at your option) any later version.
+ *
+ * This program is distributed in the hope that it will be useful, but
+ * WITHOUT ANY WARRANTY; without even the implied warranty of
+ * MERCHANTABILITY OR FITNESS FOR A PARTICULAR PURPOSE, GOOD TITLE or
+ * NON INFRINGEMENT.  See the GNU General Public License for more
+ * details.
+ *
+ * You should have received a copy of the GNU General Public License
+ * along with this program; if not, write to the Free Software
+ * Foundation, Inc., 675 Mass Ave, Cambridge, MA 02139, USA.
+ *
+ * Send feedback to zach@vmware.com
+ *
+ */
+
+
+#ifndef __MACH_SEGMENT_H
+#define __MACH_SEGMENT_H
+
+#if !defined(CONFIG_X86_VMI)
+# error invalid sub-arch include
+#endif
+
+static inline unsigned make_kernel_segment(unsigned seg)
+{
+	unsigned cs;
+	__asm__ ("movl %%cs,%0" : "=r" (cs));
+	return ((cs & 3) | seg);
+}
+
+/*
+ * Treat any supervisor level CS as kernel.  This is ok
+ * because the PNP and APM BIOS code is disabled in VMI
+ * mode.  This test can only be used if V8086 mode has
+ * already been ruled out (since v8086 mode cs selector
+ * has no RPL).
+ */
+static inline int is_kernel_cs(unsigned cs)
+{
+	return ((cs & 3) != 3);
+}
+
+#endif
diff -Naur linux-2.6.12.3.pristine/include/asm-i386/mach-vmi/mach_tlbflush.h linux-2.6.12.3-vmi/include/asm-i386/mach-vmi/mach_tlbflush.h
--- linux-2.6.12.3.pristine/include/asm-i386/mach-vmi/mach_tlbflush.h	1970-01-01 00:00:00.000000000 +0000
+++ linux-2.6.12.3-vmi/include/asm-i386/mach-vmi/mach_tlbflush.h	2005-11-15 16:57:30.000000000 +0000
@@ -0,0 +1,40 @@
+/*
+ * Copyright (C) 2005, VMware, Inc.
+ *
+ * All rights reserved.
+ *
+ * This program is free software; you can redistribute it and/or modify
+ * it under the terms of the GNU General Public License as published by
+ * the Free Software Foundation; either version 2 of the License, or
+ * (at your option) any later version.
+ *
+ * This program is distributed in the hope that it will be useful, but
+ * WITHOUT ANY WARRANTY; without even the implied warranty of
+ * MERCHANTABILITY OR FITNESS FOR A PARTICULAR PURPOSE, GOOD TITLE or
+ * NON INFRINGEMENT.  See the GNU General Public License for more
+ * details.
+ *
+ * You should have received a copy of the GNU General Public License
+ * along with this program; if not, write to the Free Software
+ * Foundation, Inc., 675 Mass Ave, Cambridge, MA 02139, USA.
+ *
+ * Send feedback to zach@vmware.com
+ *
+ */
+
+
+#ifndef _MACH_TLBFLUSH_H
+#define _MACH_TLBFLUSH_H
+
+#include <vmi.h>
+
+#define __flush_tlb()		\
+	vmi_FlushTLB()
+
+#define __flush_tlb_global()	\
+	vmi_FlushTLBAll()
+
+#define __flush_tlb_single(addr) \
+	vmi_InvalPage(addr)
+
+#endif /* _MACH_TLBFLUSH_H */
diff -Naur linux-2.6.12.3.pristine/include/asm-i386/mach-vmi/paravirtualInterface.h linux-2.6.12.3-vmi/include/asm-i386/mach-vmi/paravirtualInterface.h
--- linux-2.6.12.3.pristine/include/asm-i386/mach-vmi/paravirtualInterface.h	1970-01-01 00:00:00.000000000 +0000
+++ linux-2.6.12.3-vmi/include/asm-i386/mach-vmi/paravirtualInterface.h	2005-11-15 16:57:30.000000000 +0000
@@ -0,0 +1,99 @@
+/*
+ * paravirtualInterface.h --
+ *
+ *      Header file for paravirtualization interface and definitions
+ *      for the hypervisor option ROM tables.
+ *
+ *      Copyright (C) 2005, VMWare, Inc.
+ *
+ */
+
+#ifndef _PARAVIRTUAL_INTERFACE_H_
+#define _PARAVIRTUAL_INTERFACE_H_
+
+#include <vmiCalls.h>
+
+/*
+ *---------------------------------------------------------------------
+ *
+ *  VMI Option ROM API
+ *
+ *---------------------------------------------------------------------
+ */
+
+#define VMI_SPACE(call, ...)
+#define VMI_FUNC(call, ...) VMI_CALL_##call,
+#define VMI_PROC(call, ...) VMI_CALL_##call,
+#define VMI_JUMP(call, ...) VMI_CALL_##call,
+
+typedef enum VMICall {
+	VMI_CALLS
+} VMICall;
+
+#undef VMI_SPACE
+#undef VMI_FUNC
+#undef VMI_PROC
+#undef VMI_JUMP
+
+#define VMI_SIGNATURE 0x696d5663   /* "cVmi" */
+
+#define VMI_API_REV_MAJOR          6
+#define VMI_API_REV_MINOR          1
+
+/* Flags used by VMI_Reboot call */
+#define VMI_REBOOT_SOFT          0x0
+#define VMI_REBOOT_HARD          0x1
+
+/* Flags used by VMI_RegisterPageMapping call */
+#define VMI_PAGE_PT              0x00
+#define VMI_PAGE_PD              0x01
+#define VMI_PAGE_PAE_PT          0x04
+#define VMI_PAGE_PAE_PD          0x05
+#define VMI_PAGE_PDP             0x06
+#define VMI_PAGE_PML4            0x07
+
+/* Flags for VMI_ClonePage{Table|Directory} call */
+#define VMI_MKCLONE(start, count) (((start) << 16) | (count))
+
+/* Flags used by VMI_SetDeferredMode call */
+#define VMI_DEFER_NONE		0x00
+#define VMI_DEFER_MMU		0x01
+#define VMI_DEFER_CPU		0x02
+#define VMI_DEFER_DT		0x04
+
+/*
+ *---------------------------------------------------------------------
+ *
+ *  Generic VROM structures and definitions
+ *
+ *---------------------------------------------------------------------
+ */
+
+/* VROM call table definitions */
+#define VROM_CALL_LEN             32
+
+typedef struct VROMCallEntry {
+   char f[VROM_CALL_LEN];
+} VROMCallEntry;
+
+typedef struct VROMHeader {
+   VMI_UINT16          romSignature;             // option ROM signature
+   VMI_INT8            romLength;                // ROM length in 512 byte chunks
+   unsigned char       romEntry[4];              // 16-bit code entry point
+   VMI_UINT8           romPad0;                  // 4-byte align pad
+   VMI_UINT32          vRomSignature;            // VROM identification signature
+   VMI_UINT8           APIVersionMinor;          // Minor version of API
+   VMI_UINT8           APIVersionMajor;          // Major version of API
+   VMI_UINT8           dataPages;                // Number of pages for data area
+   VMI_UINT8           reserved0;                // Reserved for expansion
+   VMI_UINT32          reserved1;                // Reserved for expansion
+   VMI_UINT32          reserved2;                // Reserved for private use
+   VMI_UINT16          pciHeaderOffset;          // Offset to PCI OPROM header
+   VMI_UINT16          pnpHeaderOffset;          // Offset to PnP OPROM header
+   VMI_UINT32          romPad3;                  // PnP reserverd / VMI reserved
+   char                reserved[32];             // Reserved for future expansion
+   char                elfHeader[64];            // Reserved for ELF header
+   VROMCallEntry       vromCall[124];            // @ 0x80: ROM calls 4-127
+} VROMHeader;
+
+#endif
diff -Naur linux-2.6.12.3.pristine/include/asm-i386/mach-vmi/pgtable-2level-ops.h linux-2.6.12.3-vmi/include/asm-i386/mach-vmi/pgtable-2level-ops.h
--- linux-2.6.12.3.pristine/include/asm-i386/mach-vmi/pgtable-2level-ops.h	1970-01-01 00:00:00.000000000 +0000
+++ linux-2.6.12.3-vmi/include/asm-i386/mach-vmi/pgtable-2level-ops.h	2006-01-03 13:48:43.000000000 +0000
@@ -0,0 +1,76 @@
+/*
+ * Copyright (C) 2005, VMware, Inc.
+ *
+ * All rights reserved.
+ *
+ * This program is free software; you can redistribute it and/or modify
+ * it under the terms of the GNU General Public License as published by
+ * the Free Software Foundation; either version 2 of the License, or
+ * (at your option) any later version.
+ *
+ * This program is distributed in the hope that it will be useful, but
+ * WITHOUT ANY WARRANTY; without even the implied warranty of
+ * MERCHANTABILITY OR FITNESS FOR A PARTICULAR PURPOSE, GOOD TITLE or
+ * NON INFRINGEMENT.  See the GNU General Public License for more
+ * details.
+ *
+ * You should have received a copy of the GNU General Public License
+ * along with this program; if not, write to the Free Software
+ * Foundation, Inc., 675 Mass Ave, Cambridge, MA 02139, USA.
+ *
+ * Send feedback to zach@vmware.com
+ *
+ */
+
+
+#ifndef _MACH_PGTABLE_LEVEL_OPS_H
+#define _MACH_PGTABLE_LEVEL_OPS_H
+
+/*
+ * VU: Certain archs need to do even more special things... 
+ */
+#define pte_pfn(x)	((unsigned long)(vmi_GetPteVal((x).pte_low) >> PAGE_SHIFT))
+
+#define pgd_val(x) (vmi_GetPdeVal((x).pgd))
+
+/*
+ * Certain architectures need to do special things when PTEs
+ * within a page table are directly modified.  Thus, the following
+ * hook is made available.
+ */
+/* VU: extended by level */
+#define set_pte(pteptr, pteval) \
+	vmi_SetPte(pte_val(pteval), (VMI_UINT32 *)&(pteptr)->pte_low, 2)
+
+#define set_pte_atomic(pteptr, pteval) set_pte(pteptr,pteval)
+
+/*
+ * (pmds are folded into pgds so this doesn't get actually called,
+ * but the define is needed for a generic inline function.)
+ */
+#define set_pmd(pmdptr, pmdval) \
+	vmi_SetPte((pmdval).pud.pgd.pgd, (VMI_UINT32 *)&((pmdptr)->pud.pgd), 0)
+
+#define ptep_get_and_clear(mm,addr,xp) \
+	__pte(vmi_SwapPte(0, (VMI_UINT32 *)&(xp)->pte_low))
+
+static inline int ptep_test_and_clear_dirty(struct vm_area_struct *vma, unsigned long addr, pte_t *ptep)	
+{
+	if (!pte_dirty(*ptep))
+		return 0;
+        return vmi_TestAndClearPteBit(_PAGE_BIT_DIRTY, (VMI_UINT32 *)ptep);
+}
+
+static inline int ptep_test_and_clear_young(struct vm_area_struct *vma, unsigned long addr, pte_t *ptep)	
+{ 
+	if (!pte_young(*ptep))
+		return 0;
+        return vmi_TestAndClearPteBit(_PAGE_BIT_ACCESSED, (VMI_UINT32 *)ptep);
+}
+
+static inline void ptep_set_wrprotect(struct mm_struct *mm, unsigned long addr, pte_t *ptep)
+{ 
+        (void)vmi_TestAndClearPteBit(_PAGE_BIT_RW, (VMI_UINT32 *)ptep);
+}
+
+#endif /* _MACH_PGTABLE_LEVEL_OPS_H */
diff -Naur linux-2.6.12.3.pristine/include/asm-i386/mach-vmi/pgtable-3level-ops.h linux-2.6.12.3-vmi/include/asm-i386/mach-vmi/pgtable-3level-ops.h
--- linux-2.6.12.3.pristine/include/asm-i386/mach-vmi/pgtable-3level-ops.h	1970-01-01 00:00:00.000000000 +0000
+++ linux-2.6.12.3-vmi/include/asm-i386/mach-vmi/pgtable-3level-ops.h	2005-11-15 16:57:30.000000000 +0000
@@ -0,0 +1,59 @@
+#ifndef _MACH_PGTABLE_LEVEL_OPS_H
+#define _MACH_PGTABLE_LEVEL_OPS_H
+
+/* Rules for using set_pte: the pte being assigned *must* be
+ * either not present or in a state where the hardware will
+ * not attempt to update the pte.  In places where this is
+ * not possible, use pte_get_and_clear to obtain the old pte
+ * value and then use set_pte to update it.  -ben
+ */
+static inline void set_pte(pte_t *ptep, pte_t pte)
+{
+	vmi_SetPteLong(pte_val(pte), (VMI_UINT64 *)ptep);
+}
+
+#define __HAVE_ARCH_SET_PTE_ATOMIC
+#define set_pte_atomic(pteptr,pteval) \
+		(void)vmi_SwapPteLong(pte_val(pteval), (VMI_UINT64 *)&(pteptr)->pte_low)
+#define set_pmd(pmdptr,pmdval) \
+		(void)vmi_SwapPteLong(pmd_val(pmdval), (VMI_UINT64 *)&(pmdptr)->pmd)
+
+/*
+ * Using SetPteLong here is only safe on inactive roots.  Not currently an issue, since
+ * PAE creates all 4 PDPEs at root creation time and does not dynamically change them.
+ */ 
+#define set_pud(pudptr,pudval) \
+		vmi_SetPteLong(pgd_val((pudval).pgd), (VMI_UINT64 *)&(pudptr)->pgd)
+
+/*
+ * Avoid using cmpxchg8b; cycle timing showed this winning by 40 cycles
+ */
+#define ptep_get_and_clear(mm,addr,xp) ({ \
+	pte_t __pte; \
+	int pteval; \
+	pteval = vmi_TestAndClearPteBitLong(_PAGE_BIT_PRESENT, (VMI_UINT64 *)&(xp)->pte_low) & 1; \
+	__pte = __pte(*(VMI_UINT64 *)xp | (unsigned)pteval); \
+	*(VMI_UINT64 *)xp = 0; \
+	__pte; \
+})
+
+static inline int ptep_test_and_clear_dirty(struct vm_area_struct *vma, unsigned long addr, pte_t *ptep)	
+{
+	if (!pte_dirty(*ptep))
+		return 0;
+        return vmi_TestAndClearPteBitLong(_PAGE_BIT_DIRTY, (VMI_UINT64 *)ptep);
+}
+
+static inline int ptep_test_and_clear_young(struct vm_area_struct *vma, unsigned long addr, pte_t *ptep)	
+{ 
+	if (!pte_young(*ptep))
+		return 0;
+        return vmi_TestAndClearPteBitLong(_PAGE_BIT_ACCESSED, (VMI_UINT64 *)ptep);
+}
+
+static inline void ptep_set_wrprotect(struct mm_struct *mm, unsigned long addr, pte_t *ptep)
+{ 
+        (void)vmi_TestAndClearPteBitLong(_PAGE_BIT_RW, (VMI_UINT64 *)ptep);
+}
+
+#endif
diff -Naur linux-2.6.12.3.pristine/include/asm-i386/mach-vmi/pgtable-ops.h linux-2.6.12.3-vmi/include/asm-i386/mach-vmi/pgtable-ops.h
--- linux-2.6.12.3.pristine/include/asm-i386/mach-vmi/pgtable-ops.h	1970-01-01 00:00:00.000000000 +0000
+++ linux-2.6.12.3-vmi/include/asm-i386/mach-vmi/pgtable-ops.h	2005-11-15 16:57:30.000000000 +0000
@@ -0,0 +1,69 @@
+/*
+ * Copyright (C) 2005, VMware, Inc.
+ *
+ * All rights reserved.
+ *
+ * This program is free software; you can redistribute it and/or modify
+ * it under the terms of the GNU General Public License as published by
+ * the Free Software Foundation; either version 2 of the License, or
+ * (at your option) any later version.
+ *
+ * This program is distributed in the hope that it will be useful, but
+ * WITHOUT ANY WARRANTY; without even the implied warranty of
+ * MERCHANTABILITY OR FITNESS FOR A PARTICULAR PURPOSE, GOOD TITLE or
+ * NON INFRINGEMENT.  See the GNU General Public License for more
+ * details.
+ *
+ * You should have received a copy of the GNU General Public License
+ * along with this program; if not, write to the Free Software
+ * Foundation, Inc., 675 Mass Ave, Cambridge, MA 02139, USA.
+ *
+ * Send feedback to zach@vmware.com
+ *
+ */
+
+
+#ifndef _PGTABLE_OPS_H
+#define _PGTABLE_OPS_H
+
+#include <vmi.h>
+
+#ifdef CONFIG_X86_PAE
+# include <pgtable-3level-ops.h>
+#else
+# include <pgtable-2level-ops.h>
+#endif
+
+/*
+ * Catch NP->P transitions which need to flush the update queue
+ */
+#define update_mmu_cache(vma,address,pte) vmi_FlushDeferredCalls()
+
+#define  __HAVE_ARCH_PTEP_SET_ACCESS_FLAGS
+#define ptep_set_access_flags(__vma, __address, __ptep, __entry, __dirty) \
+	do {								  \
+		if (__dirty) {						  \
+			set_pte(__ptep,__entry);		  	  \
+			flush_tlb_page(__vma, __address);		  \
+		}							  \
+	} while (0)
+  
+/*
+ * This hook may define an operation to occur directly before
+ * a context switch.  We use it to indicate lazy batching of
+ * hypercalls, which are flushed in the context switch code.
+ * Restoring the deferred mode to MMU operations will flush
+ * the entire queue.  Unfortunately, this means we need to
+ * define task_running() as well and keep it in sync with the
+ * definition in kernel/sched.c
+ */
+#define prepare_arch_switch(rq, next) \
+	vmi_SetDeferredMode(VMI_DEFER_MMU | VMI_DEFER_CPU)
+#define finish_arch_switch(rq, next) \
+do { \
+	spin_unlock_irq(&(rq)->lock); \
+	vmi_SetDeferredMode(VMI_DEFER_MMU); \
+} while (0)
+#define task_running(rq, p)		((rq)->curr == (p))
+
+#endif /* _PGTABLE_OPS_H */
diff -Naur linux-2.6.12.3.pristine/include/asm-i386/mach-vmi/setup_arch_pre.h linux-2.6.12.3-vmi/include/asm-i386/mach-vmi/setup_arch_pre.h
--- linux-2.6.12.3.pristine/include/asm-i386/mach-vmi/setup_arch_pre.h	1970-01-01 00:00:00.000000000 +0000
+++ linux-2.6.12.3-vmi/include/asm-i386/mach-vmi/setup_arch_pre.h	2005-11-15 16:57:30.000000000 +0000
@@ -0,0 +1,6 @@
+/* Hook to call BIOS initialisation function */
+
+/* no action for generic */
+
+#define ARCH_SETUP
+extern void vmi_init(void);
diff -Naur linux-2.6.12.3.pristine/include/asm-i386/mach-vmi/vicCalls.h linux-2.6.12.3-vmi/include/asm-i386/mach-vmi/vicCalls.h
--- linux-2.6.12.3.pristine/include/asm-i386/mach-vmi/vicCalls.h	1970-01-01 00:00:00.000000000 +0000
+++ linux-2.6.12.3-vmi/include/asm-i386/mach-vmi/vicCalls.h	2005-11-15 16:57:30.000000000 +0000
@@ -0,0 +1,25 @@
+/*
+ * vicCalls.h --
+ *
+ *   List of 32-bit VIC interface calls and parameters
+ *
+ *   Copyright (C) 2005, VMware, Inc.
+ *
+ */
+
+/*
+ * Format is: call, # args, # returns
+ */
+
+#define VIC_CALLS \
+   VDEF(RESERVED0,              0, 0) \
+   VDEF(RESERVED1,              0, 0) \
+   VDEF(RESERVED2,              0, 0) \
+   VDEF(RESERVED3,              0, 0) \
+   VDEF(Init,                   2, 1) \
+   VDEF(Mask,                   1, 0) \
+   VDEF(Unmask,                 1, 0) \
+   VDEF(Ack,                    1, 0) \
+   VDEF(EOI,                    1, 0) \
+   VDEF(SendIPI,                2, 0) \
+   VDEF(SetDeliveryMode,        2, 0) 
diff -Naur linux-2.6.12.3.pristine/include/asm-i386/mach-vmi/vmi.h linux-2.6.12.3-vmi/include/asm-i386/mach-vmi/vmi.h
--- linux-2.6.12.3.pristine/include/asm-i386/mach-vmi/vmi.h	1970-01-01 00:00:00.000000000 +0000
+++ linux-2.6.12.3-vmi/include/asm-i386/mach-vmi/vmi.h	2005-11-15 16:57:30.000000000 +0000
@@ -0,0 +1,97 @@
+
+/*
+ * Copyright (C) 2005, VMware, Inc.
+ *
+ * All rights reserved.
+ *
+ * This program is free software; you can redistribute it and/or modify
+ * it under the terms of the GNU General Public License as published by
+ * the Free Software Foundation; either version 2 of the License, or
+ * (at your option) any later version.
+ *
+ * This program is distributed in the hope that it will be useful, but
+ * WITHOUT ANY WARRANTY; without even the implied warranty of
+ * MERCHANTABILITY OR FITNESS FOR A PARTICULAR PURPOSE, GOOD TITLE or
+ * NON INFRINGEMENT.  See the GNU General Public License for more
+ * details.
+ *
+ * You should have received a copy of the GNU General Public License
+ * along with this program; if not, write to the Free Software
+ * Foundation, Inc., 675 Mass Ave, Cambridge, MA 02139, USA.
+ *
+ * Send feedback to zach@vmware.com
+ *
+ */
+
+#ifndef __MACH_VMI_H
+#define __MACH_VMI_H
+
+#include <linux/config.h>
+#include <asm/page.h>
+#include <vmiCalls.h>
+
+/* Linux type system definitions */
+struct Xgt_desc_struct;
+typedef struct Xgt_desc_struct VMI_DTR;
+typedef uint64_t VMI_UINT64;
+typedef uint32_t VMI_UINT32;
+typedef uint16_t VMI_UINT16;
+typedef uint8_t VMI_UINT8;
+typedef int8_t VMI_INT8;
+typedef int VMI_INT;
+typedef uint16_t VMI_SELECTOR;
+typedef uint8_t VMI_BOOL;
+
+typedef uint32_t VMI_PTE;
+typedef uint64_t VMI_PAE_PTE;
+
+#define VMI_ARGS(args...) args
+#define VMI_INPUT(args...) args
+#define VMI_OUTPUT(args...) args
+#define VMI_ASM_CLOBBER "cc"
+#define VMI_MEM_CLOBBER "cc", "memory"
+
+#define VMI_SPACE(...)
+#define VMI_FUNC(_call, _return, _proto, _output, _input, _clobber, _attributes) \
+static inline _return vmi_##_call (_proto) { \
+	_return ret; \
+	__asm__ __volatile__("call VMI_" #_call \
+			: _output \
+			: _input  \
+			: _clobber ); \
+	return ret; \
+};
+
+#define VMI_PROC(_call, _proto, _output, _input, _clobber, _attributes) \
+static inline void vmi_##_call (_proto) { \
+	__asm__ __volatile__("call VMI_" #_call \
+			: _output \
+			: _input  \
+			: _clobber ); \
+};
+
+#define VMI_JUMP(_call, _proto, _output, _input, _clobber, _attributes) \
+static inline void __attribute__((noreturn)) vmi_##_call (_proto) { \
+	__asm__ __volatile__("jmp VMI_" #_call \
+			: _output \
+			: _input  \
+			: _clobber ); \
+	while (1); \
+};
+
+VMI_CALLS
+
+#undef VMI_FUNC
+#undef VMI_PROC
+#undef VMI_JUMP
+#undef VMI_SPACE
+
+#include <paravirtualInterface.h>
+
+#define VMI_MIN_API_REV_MINOR 1
+
+/* For stubs usage */
+#define VMICALL extern __attribute__((regparm(3))) 
+#define VMIJUMP extern __attribute__((noreturn)) 
+
+#endif /* __MACH_VMI_H */
diff -Naur linux-2.6.12.3.pristine/include/asm-i386/mach-vmi/vmiCalls.h linux-2.6.12.3-vmi/include/asm-i386/mach-vmi/vmiCalls.h
--- linux-2.6.12.3.pristine/include/asm-i386/mach-vmi/vmiCalls.h	1970-01-01 00:00:00.000000000 +0000
+++ linux-2.6.12.3-vmi/include/asm-i386/mach-vmi/vmiCalls.h	2006-01-03 13:49:50.000000000 +0000
@@ -0,0 +1,777 @@
+/* **********************************************************
+ * Copyright 2004, 2005 VMware, Inc.  All rights reserved.
+ * Copyright 2005, Volkmar Uhlig
+ * **********************************************************/
+
+/*
+ * vmiCalls.h
+ *
+ * The VMI ROM layout is defined by this header file.  Each entry represents
+ * a single slot in the VROM, which is 32 bytes in size.  This file mayy be
+ * pre-processed to generate inline function prototypes required to call these
+ * functions from GNU C.  There are three types of definitions:
+ *
+ *   VMI_SPACE - a reserved space in the VROM table;
+ *   VMI_FUNC  - a function which returns a single (possibly 64-bit) value;
+ *   VMI_PROC  - defines a function which returns no value;
+ *   VMI_JUMP  - defines a function which does not return;
+ *
+ *   All functions have the same general macro layout which easily converts to
+ *   inline assembler.
+ *
+ *      TYPEDEF (return type, if applicable),
+ *      ARGS (C function arguments),
+ *      OUTPUT (how values are returned),
+ *      INPUT (how values are passed in),
+ *      CLOBBER (what if anything is clobbered),
+ *      ATTRIBUTES (special attributes of the function)
+ *
+ *   Types are defined via abstract type definitions so that they may be
+ *   redefined local as convenient.
+ *
+ *   These function definitions are defined to be C-compatible with regparm(3)
+ *   argument passing wherever possible, but some of these functions must be
+ *   available to assembler code, and emulate hardware instructions with fixed
+ *   register input.  In these cases, an argument convention that mimics the
+ *   hardware instruction has been chosen.  In addition, the amount of state
+ *   which is clobbered by any VMI function is extremely minimal.  To allow
+ *   for conditional branch logic in the implementation of a VMI function,
+ *   clobbering of flags is almost universally allowed (VMI_ASM_CLOBBER), but
+ *   for most cases, clobbering of registers is not allowed.  This allows the
+ *   compiler to optimize code around VMI callouts almost identically to the
+ *   way it would optimize for native hardware.
+ *
+ *   While the implementation of these functions is relocatable code, most
+ *   functions require flat segments, which are zero based, maximal limit
+ *   segments for CS, DS, ES, and SS.  The flatness requirements are tagged
+ *   with attributes.  Flatness is never assumed for FS and GS segments.
+ *
+ *      VMI_FLAT     - CS, DS, ES, SS must be flat
+ *      VMI_FLAT_SS  - CS, SS must be flat
+ *      VMI_NOT_FLAT - no assumptions are made
+ *
+ * Zachary Amsden <zach@vmware.com>
+ *
+ * Volkmar Uhlig: Extended with additional VMI calls to support DMA
+ *                and ptab reads
+ *
+ */
+
+#define VMI_CALLS \
+/*                                                                                               \
+ * Space for the ROM and VROM headers and 16-bit init code.                                      \
+ * PnP and PCI header are stored after ROM code segment                                          \
+ */                                                                                              \
+VMI_SPACE( ROM_HEADER0 )                                                                         \
+VMI_SPACE( ROM_HEADER1 )                                                                         \
+                                                                                                 \
+/*                                                                                               \
+ * Space for the bare ELF header and interpreter.                                                \
+ * Program header and section header stored after ROM code segment                               \
+ */                                                                                              \
+VMI_SPACE( ELF_HEADER0 )                                                                         \
+VMI_SPACE( ELF_HEADER1 )                                                                         \
+                                                                                                 \
+/* Initialize the per-cpu VMI data area and enter the CPU into VMI mode */                       \
+VMI_FUNC( Init,                                                                                  \
+          VMI_UINT32, VMI_ARGS(void *dataArea),                                                  \
+          VMI_OUTPUT("=a" (ret)),                                                                \
+          VMI_INPUT("0" (dataArea)),                                                             \
+          VMI_ASM_CLOBBER,                                                                       \
+          VMI_ATTRIBUTES(VMI_FLAT, VMI_VOLATILE))                                                \
+                                                                                                 \
+/* Binary CPUID equivalent - ebx, ecx, edx returned via variables, eax live */                   \
+VMI_FUNC( CPUID,                                                                                 \
+          VMI_UINT32, VMI_ARGS(VMI_UINT32 func, VMI_UINT32 *b, VMI_UINT32 *c, VMI_UINT32 *d),    \
+          VMI_OUTPUT("=a"(ret),"=b"(*b),"=c"(*c),"=d"(*c)),                                      \
+          VMI_INPUT("0" (func)),                                                                 \
+          VMI_ASM_CLOBBER,                                                                       \
+          VMI_ATTRIBUTES(VMI_FLAT, VMI_VOLATILE))                                                \
+                                                                                                 \
+/* Binary WRMSR equivalent */                                                                    \
+VMI_PROC( WRMSR,                                                                                 \
+          VMI_ARGS(VMI_UINT32 msr, VMI_UINT64 value),                                            \
+          VMI_OUTPUT(),                                                                          \
+          VMI_INPUT("A" (value), "c" (msr)),                                                     \
+          VMI_MEM_CLOBBER,                                                                       \
+          VMI_ATTRIBUTES(VMI_FLAT, VMI_VOLATILE))                                                \
+                                                                                                 \
+/* Binary RDMSR equivalent */                                                                    \
+VMI_FUNC( RDMSR,                                                                                 \
+          VMI_UINT64, VMI_ARGS(VMI_UINT32 msr),                                                  \
+          VMI_OUTPUT("=A" (ret)),                                                                \
+          VMI_INPUT("c" (msr)),                                                                  \
+          VMI_MEM_CLOBBER,                                                                       \
+          VMI_ATTRIBUTES(VMI_FLAT, VMI_VOLATILE))                                                \
+                                                                                                 \
+/* Binary LGDT equivalent */                                                                     \
+VMI_PROC( SetGDT,                                                                                \
+          VMI_ARGS(VMI_DTR *dtr),                                                                \
+          VMI_OUTPUT(),                                                                          \
+          VMI_INPUT("a" (dtr)),                                                                  \
+          VMI_MEM_CLOBBER,                                                                       \
+          VMI_ATTRIBUTES(VMI_FLAT, VMI_VOLATILE))                                                \
+                                                                                                 \
+/* Binary LIDT equivalent */                                                                     \
+VMI_PROC( SetIDT,                                                                                \
+          VMI_ARGS(VMI_DTR *dtr),                                                                \
+          VMI_OUTPUT(),                                                                          \
+          VMI_INPUT("a" (dtr)),                                                                  \
+          VMI_MEM_CLOBBER,                                                                       \
+          VMI_ATTRIBUTES(VMI_FLAT, VMI_VOLATILE))                                                \
+                                                                                                 \
+/* Binary LLDT equivalent */                                                                     \
+VMI_PROC( SetLDT,                                                                                \
+          VMI_ARGS(VMI_SELECTOR sel),                                                            \
+          VMI_OUTPUT(),                                                                          \
+          VMI_INPUT("a" (sel)),                                                                  \
+          VMI_MEM_CLOBBER,                                                                       \
+          VMI_ATTRIBUTES(VMI_FLAT, VMI_VOLATILE))                                                \
+                                                                                                 \
+/* Binary LTR equivalent */                                                                      \
+VMI_PROC( SetTR,                                                                                 \
+          VMI_ARGS(VMI_SELECTOR sel),                                                            \
+          VMI_OUTPUT(),                                                                          \
+          VMI_INPUT("a" (sel)),                                                                  \
+          VMI_MEM_CLOBBER,                                                                       \
+          VMI_ATTRIBUTES(VMI_FLAT, VMI_VOLATILE))                                                \
+                                                                                                 \
+/* Binary SGDT equivalent */                                                                     \
+VMI_PROC( GetGDT,                                                                                \
+          VMI_ARGS(VMI_DTR *dtr),                                                                \
+          VMI_OUTPUT(),                                                                          \
+          VMI_INPUT("a" (dtr)),                                                                  \
+          VMI_ASM_CLOBBER,                                                                       \
+          VMI_ATTRIBUTES(VMI_FLAT, VMI_VOLATILE))                                                \
+                                                                                                 \
+/* Binary SIDT equivalent */                                                                     \
+VMI_PROC( GetIDT,                                                                                \
+          VMI_ARGS(VMI_DTR *dtr),                                                                \
+          VMI_OUTPUT(),                                                                          \
+          VMI_INPUT("a" (dtr)),                                                                  \
+          VMI_ASM_CLOBBER,                                                                       \
+          VMI_ATTRIBUTES(VMI_FLAT, VMI_VOLATILE))                                                \
+                                                                                                 \
+/* Binary SLDT equivalent */                                                                     \
+VMI_FUNC( GetLDT,                                                                                \
+          VMI_SELECTOR, VMI_ARGS(void),                                                          \
+          VMI_OUTPUT("=a" (ret)),                                                                \
+          VMI_INPUT(),                                                                           \
+          VMI_ASM_CLOBBER,                                                                       \
+          VMI_ATTRIBUTES(VMI_FLAT, VMI_VOLATILE))                                                \
+                                                                                                 \
+/* Binary STR equivalent */                                                                      \
+VMI_FUNC( GetTR,                                                                                 \
+          VMI_SELECTOR, VMI_ARGS(void),                                                          \
+          VMI_OUTPUT("=a" (ret)),                                                                \
+          VMI_INPUT(),                                                                           \
+          VMI_ASM_CLOBBER,                                                                       \
+          VMI_ATTRIBUTES(VMI_FLAT, VMI_VOLATILE))                                                \
+                                                                                                 \
+/* GDT update notification */                                                                    \
+VMI_PROC( UpdateGDT,                                                                             \
+          VMI_ARGS(VMI_UINT32 first, VMI_UINT32 last),                                           \
+          VMI_OUTPUT(),                                                                          \
+          VMI_INPUT("a" (first), "d" (last)),                                                    \
+          VMI_ASM_CLOBBER,                                                                       \
+          VMI_ATTRIBUTES(VMI_FLAT, VMI_VOLATILE))                                                \
+                                                                                                 \
+/* IDT update notification */                                                                    \
+VMI_PROC( UpdateIDT,                                                                             \
+          VMI_ARGS(VMI_UINT32 first, VMI_UINT32 last),                                           \
+          VMI_OUTPUT(),                                                                          \
+          VMI_INPUT("a" (first), "d" (last)),                                                    \
+          VMI_ASM_CLOBBER,                                                                       \
+          VMI_ATTRIBUTES(VMI_FLAT, VMI_VOLATILE))                                                \
+                                                                                                 \
+/* LDT update notification */                                                                    \
+VMI_PROC( UpdateLDT,                                                                             \
+          VMI_ARGS(VMI_UINT32 first, VMI_UINT32 last),                                           \
+          VMI_OUTPUT(),                                                                          \
+          VMI_INPUT("a" (first), "d" (last)),                                                    \
+          VMI_ASM_CLOBBER,                                                                       \
+          VMI_ATTRIBUTES(VMI_FLAT, VMI_VOLATILE))                                                \
+                                                                                                 \
+/* TSS ss0 / esp0 update notification */                                                         \
+VMI_PROC( UpdateKernelStack,                                                                     \
+          VMI_ARGS(VMI_SELECTOR ss0, char *esp0),                                                \
+          VMI_OUTPUT(),                                                                          \
+          VMI_INPUT("a" (ss0), "d" (esp0)),                                                      \
+          VMI_ASM_CLOBBER,                                                                       \
+          VMI_ATTRIBUTES(VMI_FLAT, VMI_VOLATILE))                                                \
+                                                                                                 \
+/* Binary mov %eax, %cr0 equivalent */                                                           \
+VMI_PROC( SetCR0,                                                                                \
+          VMI_ARGS(VMI_UINT32 val),                                                              \
+          VMI_OUTPUT(),                                                                          \
+          VMI_INPUT("a" (val)),                                                                  \
+          VMI_MEM_CLOBBER,                                                                       \
+          VMI_ATTRIBUTES(VMI_FLAT, VMI_VOLATILE))                                                \
+                                                                                                 \
+/* Binary mov %eax, %cr2 equivalent */                                                           \
+VMI_PROC( SetCR2,                                                                                \
+          VMI_ARGS(VMI_UINT32 val),                                                              \
+          VMI_OUTPUT(),                                                                          \
+          VMI_INPUT("a" (val)),                                                                  \
+          VMI_MEM_CLOBBER,                                                                       \
+          VMI_ATTRIBUTES(VMI_FLAT, VMI_VOLATILE))                                                \
+                                                                                                 \
+/* Binary mov %eax, %cr3 equivalent */                                                           \
+VMI_PROC( SetCR3,                                                                                \
+          VMI_ARGS(VMI_UINT32 val),                                                              \
+          VMI_OUTPUT(),                                                                          \
+          VMI_INPUT("a" (val)),                                                                  \
+          VMI_MEM_CLOBBER,                                                                       \
+          VMI_ATTRIBUTES(VMI_FLAT, VMI_VOLATILE))                                                \
+                                                                                                 \
+/* Binary mov %eax, %cr4 equivalent */                                                           \
+VMI_PROC( SetCR4,                                                                                \
+          VMI_ARGS(VMI_UINT32 val),                                                              \
+          VMI_OUTPUT(),                                                                          \
+          VMI_INPUT("a" (val)),                                                                  \
+          VMI_MEM_CLOBBER,                                                                       \
+          VMI_ATTRIBUTES(VMI_FLAT, VMI_VOLATILE))                                                \
+                                                                                                 \
+/* Binary mov %cr0, %eax equivalent */                                                           \
+VMI_FUNC( GetCR0,                                                                                \
+          VMI_UINT32, VMI_ARGS(void),                                                            \
+          VMI_OUTPUT("=a" (ret)),                                                                \
+          VMI_INPUT(),                                                                           \
+          VMI_ASM_CLOBBER,                                                                       \
+          VMI_ATTRIBUTES(VMI_FLAT, VMI_VOLATILE))                                                \
+                                                                                                 \
+/* Binary mov %cr2, %eax equivalent */                                                           \
+VMI_FUNC( GetCR2,                                                                                \
+          VMI_UINT32, VMI_ARGS(void),                                                            \
+          VMI_OUTPUT("=a" (ret)),                                                                \
+          VMI_INPUT(),                                                                           \
+          VMI_ASM_CLOBBER,                                                                       \
+          VMI_ATTRIBUTES(VMI_FLAT, VMI_VOLATILE))                                                \
+                                                                                                 \
+/* Binary mov %cr3, %eax equivalent */                                                           \
+VMI_FUNC( GetCR3,                                                                                \
+          VMI_UINT32, VMI_ARGS(void),                                                            \
+          VMI_OUTPUT("=a" (ret)),                                                                \
+          VMI_INPUT(),                                                                           \
+          VMI_ASM_CLOBBER,                                                                       \
+          VMI_ATTRIBUTES(VMI_FLAT, VMI_VOLATILE))                                                \
+                                                                                                 \
+/* Binary mov %cr4, %eax equivalent */                                                           \
+VMI_FUNC( GetCR4,                                                                                \
+          VMI_UINT32, VMI_ARGS(void),                                                            \
+          VMI_OUTPUT("=a" (ret)),                                                                \
+          VMI_INPUT(),                                                                           \
+          VMI_ASM_CLOBBER,                                                                       \
+          VMI_ATTRIBUTES(VMI_FLAT, VMI_VOLATILE))                                                \
+                                                                                                 \
+/* Binary LMSW equivalent */                                                                     \
+VMI_PROC( LMSW,                                                                                  \
+          VMI_ARGS(VMI_UINT16 word),                                                             \
+          VMI_OUTPUT(),                                                                          \
+          VMI_INPUT("a" (word)),                                                                 \
+          VMI_ASM_CLOBBER,                                                                       \
+          VMI_ATTRIBUTES(VMI_FLAT, VMI_VOLATILE))                                                \
+                                                                                                 \
+/* Binary SMSW equivalent */                                                                     \
+VMI_FUNC( SMSW,                                                                                  \
+          VMI_UINT16, VMI_ARGS(void),                                                            \
+          VMI_OUTPUT("=a" (ret)),                                                                \
+          VMI_INPUT(),                                                                           \
+          VMI_ASM_CLOBBER,                                                                       \
+          VMI_ATTRIBUTES(VMI_FLAT, VMI_VOLATILE))                                                \
+                                                                                                 \
+/* Binary CLTS equivalent */                                                                     \
+VMI_PROC( CLTS,                                                                                  \
+          VMI_ARGS(void),                                                                        \
+          VMI_OUTPUT(),                                                                          \
+          VMI_INPUT(),                                                                           \
+          VMI_ASM_CLOBBER,                                                                       \
+          VMI_ATTRIBUTES(VMI_FLAT, VMI_VOLATILE))                                                \
+                                                                                                 \
+/* Set TS bit in CR0 */                                                                          \
+VMI_PROC( STTS,                                                                                  \
+          VMI_ARGS(void),                                                                        \
+          VMI_OUTPUT(),                                                                          \
+          VMI_INPUT(),                                                                           \
+          VMI_ASM_CLOBBER,                                                                       \
+          VMI_ATTRIBUTES(VMI_FLAT, VMI_VOLATILE))                                                \
+                                                                                                 \
+/* Set debug register */                                                                         \
+VMI_PROC( SetDR,                                                                                 \
+          VMI_ARGS(VMI_UINT32 num, VMI_UINT32 val),                                              \
+          VMI_OUTPUT(),                                                                          \
+          VMI_INPUT("a" (num), "d" (val)),                                                       \
+          VMI_ASM_CLOBBER,                                                                       \
+          VMI_ATTRIBUTES(VMI_FLAT, VMI_VOLATILE))                                                \
+                                                                                                 \
+/* Get debug register */                                                                         \
+VMI_FUNC( GetDR,                                                                                 \
+          VMI_UINT32, VMI_ARGS(VMI_UINT32 num),                                                  \
+          VMI_OUTPUT("=a" (ret)),                                                                \
+          VMI_INPUT("0" (num)),                                                                  \
+          VMI_ASM_CLOBBER,                                                                       \
+          VMI_ATTRIBUTES(VMI_FLAT, VMI_VOLATILE))                                                \
+                                                                                                 \
+/* Binary RDPMC equivalent */                                                                    \
+VMI_FUNC( RDPMC,                                                                                 \
+          VMI_UINT64, VMI_ARGS(VMI_UINT32 num),                                                  \
+          VMI_OUTPUT("=A" (ret)),                                                                \
+          VMI_INPUT("c" (num)),                                                                  \
+          VMI_ASM_CLOBBER,                                                                       \
+          VMI_ATTRIBUTES(VMI_FLAT, VMI_VOLATILE))                                                \
+                                                                                                 \
+/* Binary RDTSC equivalent */                                                                    \
+VMI_FUNC( RDTSC,                                                                                 \
+          VMI_UINT64, VMI_ARGS(void),                                                            \
+          VMI_OUTPUT("=A" (ret)),                                                                \
+          VMI_INPUT(),                                                                           \
+          VMI_ASM_CLOBBER,                                                                       \
+          VMI_ATTRIBUTES(VMI_FLAT, VMI_VOLATILE))                                                \
+                                                                                                 \
+/* Binary INVD equivalent */                                                                     \
+VMI_PROC( INVD,                                                                                  \
+          VMI_ARGS(void),                                                                        \
+          VMI_OUTPUT(),                                                                          \
+          VMI_INPUT(),                                                                           \
+          VMI_MEM_CLOBBER,                                                                       \
+          VMI_ATTRIBUTES(VMI_FLAT, VMI_VOLATILE))                                                \
+                                                                                                 \
+/* Binary WBINVD equivalent */                                                                   \
+VMI_PROC( WBINVD,                                                                                \
+          VMI_ARGS(void),                                                                        \
+          VMI_OUTPUT(),                                                                          \
+          VMI_INPUT(),                                                                           \
+          VMI_MEM_CLOBBER,                                                                       \
+          VMI_ATTRIBUTES(VMI_FLAT, VMI_VOLATILE))                                                \
+                                                                                                 \
+/* Binary INB equivalent */                                                                      \
+VMI_FUNC( INB,                                                                                   \
+          VMI_UINT8,  VMI_ARGS(VMI_UINT32 port),                                                 \
+          VMI_OUTPUT("=a" (ret)),                                                                \
+          VMI_INPUT("d" (port)),                                                                 \
+          VMI_MEM_CLOBBER,                                                                       \
+          VMI_ATTRIBUTES(VMI_FLAT, VMI_VOLATILE))                                                \
+                                                                                                 \
+/* Binary INW equivalent */                                                                      \
+VMI_FUNC( INW,                                                                                   \
+          VMI_UINT16,  VMI_ARGS(VMI_UINT32 port),                                                \
+          VMI_OUTPUT("=a" (ret)),                                                                \
+          VMI_INPUT("d" (port)),                                                                 \
+          VMI_MEM_CLOBBER,                                                                       \
+          VMI_ATTRIBUTES(VMI_FLAT, VMI_VOLATILE))                                                \
+                                                                                                 \
+/* Binary INL equivalent */                                                                      \
+VMI_FUNC( INL,                                                                                   \
+          VMI_UINT32,  VMI_ARGS(VMI_UINT32 port),                                                \
+          VMI_OUTPUT("=a" (ret)),                                                                \
+          VMI_INPUT("d" (port)),                                                                 \
+          VMI_MEM_CLOBBER,                                                                       \
+          VMI_ATTRIBUTES(VMI_FLAT, VMI_VOLATILE))                                                \
+                                                                                                 \
+/* Binary OUTB equivalent */                                                                     \
+VMI_PROC( OUTB,                                                                                  \
+          VMI_ARGS(VMI_UINT8 val, VMI_UINT32 port),                                              \
+          VMI_OUTPUT(),                                                                          \
+          VMI_INPUT("a" (val), "d" (port)),                                                      \
+          VMI_MEM_CLOBBER,                                                                       \
+          VMI_ATTRIBUTES(VMI_FLAT, VMI_VOLATILE))                                                \
+                                                                                                 \
+/* Binary OUTW equivalent */                                                                     \
+VMI_PROC( OUTW,                                                                                  \
+          VMI_ARGS(VMI_UINT16 val, VMI_UINT32 port),                                             \
+          VMI_OUTPUT(),                                                                          \
+          VMI_INPUT("a" (val), "d" (port)),                                                      \
+          VMI_MEM_CLOBBER,                                                                       \
+          VMI_ATTRIBUTES(VMI_FLAT, VMI_VOLATILE))                                                \
+                                                                                                 \
+/* Binary OUTL equivalent */                                                                     \
+VMI_PROC( OUTL,                                                                                  \
+          VMI_ARGS(VMI_UINT32 val, VMI_UINT32 port),                                             \
+          VMI_OUTPUT(),                                                                          \
+          VMI_INPUT("a" (val), "d" (port)),                                                      \
+          VMI_MEM_CLOBBER,                                                                       \
+          VMI_ATTRIBUTES(VMI_FLAT, VMI_VOLATILE))                                                \
+                                                                                                 \
+/* Binary INSB equivalent */                                                                     \
+VMI_PROC( INSB,                                                                                  \
+          VMI_ARGS(VMI_UINT8 *addr, VMI_UINT32 port, VMI_UINT32 count),                          \
+          VMI_OUTPUT("+D" (addr), "+c" (count)),                                                 \
+          VMI_INPUT("d" (port)),                                                                 \
+          VMI_MEM_CLOBBER,                                                                       \
+          VMI_ATTRIBUTES(VMI_FLAT, VMI_VOLATILE))                                                \
+                                                                                                 \
+/* Binary INSW equivalent */                                                                     \
+VMI_PROC( INSW,                                                                                  \
+          VMI_ARGS(VMI_UINT16 *addr, VMI_UINT32 port, VMI_UINT32 count),                         \
+          VMI_OUTPUT("+D" (addr), "+c" (count)),                                                 \
+          VMI_INPUT("d" (port)),                                                                 \
+          VMI_MEM_CLOBBER,                                                                       \
+          VMI_ATTRIBUTES(VMI_FLAT, VMI_VOLATILE))                                                \
+                                                                                                 \
+/* Binary INSL equivalent */                                                                     \
+VMI_PROC( INSL,                                                                                  \
+          VMI_ARGS(VMI_UINT32 *addr, VMI_UINT32 port, VMI_UINT32 count),                         \
+          VMI_OUTPUT("+D" (addr), "+c" (count)),                                                 \
+          VMI_INPUT("d" (port)),                                                                 \
+          VMI_MEM_CLOBBER,                                                                       \
+          VMI_ATTRIBUTES(VMI_FLAT, VMI_VOLATILE))                                                \
+                                                                                                 \
+/* Binary OUTSB equivalent */                                                                    \
+VMI_PROC( OUTSB,                                                                                 \
+          VMI_ARGS(VMI_UINT8 *addr, VMI_UINT32 port, VMI_UINT32 count),                          \
+          VMI_OUTPUT("+S" (addr), "+c" (count)),                                                 \
+          VMI_INPUT("d" (port)),                                                                 \
+          VMI_MEM_CLOBBER,                                                                       \
+          VMI_ATTRIBUTES(VMI_FLAT, VMI_VOLATILE))                                                \
+                                                                                                 \
+/* Binary OUTSW equivalent */                                                                    \
+VMI_PROC( OUTSW,                                                                                 \
+          VMI_ARGS(VMI_UINT16 *addr, VMI_UINT32 port, VMI_UINT32 count),                         \
+          VMI_OUTPUT("+S" (addr), "+c" (count)),                                                 \
+          VMI_INPUT("d" (port)),                                                                 \
+          VMI_MEM_CLOBBER,                                                                       \
+          VMI_ATTRIBUTES(VMI_FLAT, VMI_VOLATILE))                                                \
+                                                                                                 \
+/* Binary OUTSL equivalent */                                                                    \
+VMI_PROC( OUTSL,                                                                                 \
+          VMI_ARGS(VMI_UINT32 *addr, VMI_UINT32 port, VMI_UINT32 count),                         \
+          VMI_OUTPUT("+S" (addr), "+c" (count)),                                                 \
+          VMI_INPUT("d" (port)),                                                                 \
+          VMI_MEM_CLOBBER,                                                                       \
+          VMI_ATTRIBUTES(VMI_FLAT, VMI_VOLATILE))                                                \
+                                                                                                 \
+/* Set current IOPL mask */                                                                      \
+VMI_PROC( SetIOPLMask,                                                                           \
+          VMI_ARGS(VMI_UINT32 mask),                                                             \
+          VMI_OUTPUT(),                                                                          \
+          VMI_INPUT("a" (mask)),                                                                 \
+          VMI_ASM_CLOBBER,                                                                       \
+          VMI_ATTRIBUTES(VMI_FLAT, VMI_VOLATILE))                                                \
+                                                                                                 \
+/* Get currnet IOPL mask */                                                                      \
+VMI_FUNC( GetIOPLMask,                                                                           \
+          VMI_UINT32, VMI_ARGS(void),                                                            \
+          VMI_OUTPUT("=a" (ret)),                                                                \
+          VMI_INPUT(),                                                                           \
+          VMI_ASM_CLOBBER,                                                                       \
+          VMI_ATTRIBUTES(VMI_FLAT, VMI_VOLATILE))                                                \
+                                                                                                 \
+/* Notify hypervisor of changes to IO bitmap */                                                  \
+VMI_PROC( UpdateIOBitmap,                                                                        \
+          VMI_ARGS(void),                                                                        \
+          VMI_OUTPUT(),                                                                          \
+          VMI_INPUT(),                                                                           \
+          VMI_MEM_CLOBBER,                                                                       \
+          VMI_ATTRIBUTES(VMI_FLAT, VMI_VOLATILE))                                                \
+                                                                                                 \
+/* Notify hypervisor of changes to VME interrupt redirection bitmap */                           \
+VMI_PROC( UpdateInterruptBitmap,                                                                 \
+          VMI_ARGS(void),                                                                        \
+          VMI_OUTPUT(),                                                                          \
+          VMI_INPUT(),                                                                           \
+          VMI_MEM_CLOBBER,                                                                       \
+          VMI_ATTRIBUTES(VMI_FLAT, VMI_VOLATILE))                                                \
+                                                                                                 \
+/* Set all EFLAGS except VIF, VIP, VM */                                                         \
+VMI_PROC( SetEFLAGS,                                                                             \
+          VMI_ARGS(VMI_UINT32 flags),                                                            \
+          VMI_OUTPUT(),                                                                          \
+          VMI_INPUT("a" (flags)),                                                                \
+          VMI_ASM_CLOBBER,                                                                       \
+          VMI_ATTRIBUTES(VMI_FLAT, VMI_VOLATILE))                                                \
+                                                                                                 \
+/* Get all EFLAGS */                                                                             \
+VMI_FUNC( GetEFLAGS,                                                                             \
+          VMI_UINT32, VMI_ARGS(void),                                                            \
+          VMI_OUTPUT("=a" (ret)),                                                                \
+          VMI_INPUT(),                                                                           \
+          VMI_ASM_CLOBBER,                                                                       \
+          VMI_ATTRIBUTES(VMI_FLAT, VMI_VOLATILE))                                                \
+                                                                                                 \
+/* Clear EFLAGS_IF, return old value */                                                          \
+VMI_FUNC( SaveAndDisableIRQs,                                                                    \
+          VMI_UINT32, VMI_ARGS(void),                                                            \
+          VMI_OUTPUT("=a" (ret)),                                                                \
+          VMI_INPUT(),                                                                           \
+          VMI_ASM_CLOBBER,                                                                       \
+          VMI_ATTRIBUTES(VMI_FLAT, VMI_VOLATILE))                                                \
+                                                                                                 \
+/* Restore EFLAGS_IF from saved value */                                                         \
+VMI_PROC( RestoreIRQs,                                                                           \
+          VMI_ARGS(VMI_UINT32 mask),                                                             \
+          VMI_OUTPUT(),                                                                          \
+          VMI_INPUT("a" (mask)),                                                                 \
+          VMI_ASM_CLOBBER,                                                                       \
+          VMI_ATTRIBUTES(VMI_FLAT, VMI_VOLATILE))                                                \
+                                                                                                 \
+/* Binary STI equivalent */                                                                      \
+VMI_PROC( STI,                                                                                   \
+          VMI_ARGS(void),                                                                        \
+          VMI_OUTPUT(),                                                                          \
+          VMI_INPUT(),                                                                           \
+          VMI_ASM_CLOBBER,                                                                       \
+          VMI_ATTRIBUTES(VMI_FLAT_SS, VMI_VOLATILE))                                             \
+                                                                                                 \
+/* Binary CLI equivalent */                                                                      \
+VMI_PROC( CLI,                                                                                   \
+          VMI_ARGS(void),                                                                        \
+          VMI_OUTPUT(),                                                                          \
+          VMI_INPUT(),                                                                           \
+          VMI_ASM_CLOBBER,                                                                       \
+          VMI_ATTRIBUTES(VMI_FLAT_SS, VMI_VOLATILE))                                             \
+                                                                                                 \
+/* Perform an IRET; may not change IOPL, but EFLAGS_IF restored */                               \
+VMI_JUMP( IRET,                                                                                  \
+          VMI_ARGS(void),                                                                        \
+          VMI_OUTPUT(),                                                                          \
+          VMI_INPUT(),                                                                           \
+          VMI_ASM_CLOBBER,                                                                       \
+          VMI_ATTRIBUTES(VMI_FLAT_SS, VMI_VOLATILE))                                             \
+                                                                                                 \
+/* Perform an IRET as above, but on a 16-bit stack */                                            \
+VMI_JUMP( IRET16,                                                                                \
+          VMI_ARGS(void),                                                                        \
+          VMI_OUTPUT(),                                                                          \
+          VMI_INPUT(),                                                                           \
+          VMI_ASM_CLOBBER,                                                                       \
+          VMI_ATTRIBUTES(VMI_NOT_FLAT, VMI_VOLATILE))                                            \
+                                                                                                 \
+/* Binary SYSEXIT equivalent */                                                                  \
+VMI_JUMP( SysExit,                                                                               \
+          VMI_ARGS(VMI_UINT32 eip, VMI_UINT32 esp),                                              \
+          VMI_OUTPUT(),                                                                          \
+          VMI_INPUT("d" (eip), "c" (esp)),                                                       \
+          VMI_ASM_CLOBBER,                                                                       \
+          VMI_ATTRIBUTES(VMI_FLAT_SS, VMI_VOLATILE))                                             \
+                                                                                                 \
+/* Enable interrupts and holdoff until SYSEXIT completes */                                      \
+VMI_JUMP( StiSysexit,                                                                            \
+          VMI_ARGS(VMI_UINT32 eip, VMI_UINT32 esp),                                              \
+          VMI_OUTPUT(),                                                                          \
+          VMI_INPUT("d" (eip), "c" (esp)),                                                       \
+          VMI_ASM_CLOBBER,                                                                       \
+          VMI_ATTRIBUTES(VMI_FLAT_SS, VMI_VOLATILE))                                             \
+                                                                                                 \
+/* Binary SYSRET equivalent */                                                                   \
+VMI_JUMP( SysRet,                                                                                \
+          VMI_ARGS(VMI_UINT32 eip),                                                              \
+          VMI_OUTPUT(),                                                                          \
+          VMI_INPUT("c" (eip)),                                                                  \
+          VMI_ASM_CLOBBER,                                                                       \
+          VMI_ATTRIBUTES(VMI_FLAT_SS, VMI_VOLATILE))                                             \
+                                                                                                 \
+/* Enable interrupts and halt until interrupted */                                               \
+VMI_PROC( SafeHalt,                                                                              \
+          VMI_ARGS(void),                                                                        \
+          VMI_OUTPUT(),                                                                          \
+          VMI_INPUT(),                                                                           \
+          VMI_ASM_CLOBBER,                                                                       \
+          VMI_ATTRIBUTES(VMI_FLAT, VMI_VOLATILE))                                                \
+                                                                                                 \
+/* Halt until interrupted */                                                                     \
+VMI_PROC( Halt,                                                                                  \
+          VMI_ARGS(void),                                                                        \
+          VMI_OUTPUT(),                                                                          \
+          VMI_INPUT(),                                                                           \
+          VMI_ASM_CLOBBER,                                                                       \
+          VMI_ATTRIBUTES(VMI_FLAT, VMI_VOLATILE))                                                \
+                                                                                                 \
+/* Binary PAUSE equivalent */                                                                    \
+VMI_PROC( Pause,                                                                                 \
+          VMI_ARGS(void),                                                                        \
+          VMI_OUTPUT(),                                                                          \
+          VMI_INPUT(),                                                                           \
+          VMI_ASM_CLOBBER,                                                                       \
+          VMI_ATTRIBUTES(VMI_FLAT, VMI_VOLATILE))                                                \
+                                                                                                 \
+/* Shutdown this processor */                                                                    \
+VMI_PROC( Shutdown,                                                                              \
+          VMI_ARGS(void),                                                                        \
+          VMI_OUTPUT(),                                                                          \
+          VMI_INPUT(),                                                                           \
+          VMI_ASM_CLOBBER,                                                                       \
+          VMI_ATTRIBUTES(VMI_FLAT, VMI_VOLATILE))                                                \
+                                                                                                 \
+/* Reboot the machine */                                                                         \
+VMI_PROC( Reboot,                                                                                \
+          VMI_ARGS(VMI_UINT32 how),                                                              \
+          VMI_OUTPUT(),                                                                          \
+          VMI_INPUT(),                                                                           \
+          VMI_ASM_CLOBBER,                                                                       \
+          VMI_ATTRIBUTES(VMI_FLAT, VMI_VOLATILE))                                                \
+                                                                                                 \
+/* Translates the value of a pte */                                                              \
+VMI_FUNC( GetPteVal,                                                                             \
+          VMI_UINT32, VMI_ARGS(VMI_PTE pte),							 \
+          VMI_OUTPUT("=a" (ret)),                                                                \
+          VMI_INPUT("0" (pte)),			                                                 \
+          VMI_MEM_CLOBBER,                                                                       \
+          VMI_ATTRIBUTES(VMI_FLAT, VMI_VOLATILE))                                                \
+                                                                                                 \
+VMI_FUNC( GetPdeVal,                                                                             \
+          VMI_UINT32, VMI_ARGS(VMI_PTE pde),							 \
+          VMI_OUTPUT("=a" (ret)),                                                                \
+          VMI_INPUT("0" (pde)),			                                                 \
+          VMI_MEM_CLOBBER,                                                                       \
+          VMI_ATTRIBUTES(VMI_FLAT, VMI_VOLATILE))                                                \
+												 \
+/* Set a non-PAE P{T|D}E */                                                                      \
+VMI_PROC( SetPte,                                                                                \
+          VMI_ARGS(VMI_PTE pte, VMI_PTE *ptep, VMI_UINT32 level),                                \
+          VMI_OUTPUT(),                                                                          \
+          VMI_INPUT("a" (pte), "d" (ptep), "c" (level)),                                         \
+          VMI_MEM_CLOBBER,                                                                       \
+          VMI_ATTRIBUTES(VMI_FLAT, VMI_VOLATILE))                                                \
+                                                                                                 \
+/* Atomically swap a non-PAE PTE */                                                              \
+VMI_FUNC( SwapPte,                                                                               \
+          VMI_PTE, VMI_ARGS(VMI_PTE pte, VMI_PTE *ptep),                                         \
+          VMI_OUTPUT("=a" (ret)),                                                                \
+          VMI_INPUT("0" (pte), "d" (ptep)),                                                      \
+          VMI_MEM_CLOBBER,                                                                       \
+          VMI_ATTRIBUTES(VMI_FLAT, VMI_VOLATILE))                                                \
+                                                                                                 \
+/* Atomically test and set a bit in a PTE */                                                     \
+VMI_FUNC( TestAndSetPteBit,                                                                      \
+          VMI_BOOL, VMI_ARGS(VMI_INT bit, VMI_PTE *ptep),                                        \
+          VMI_OUTPUT("=a" (ret)),                                                                \
+          VMI_INPUT("0" (bit), "d" (ptep)),                                                      \
+          VMI_MEM_CLOBBER,                                                                       \
+          VMI_ATTRIBUTES(VMI_FLAT, VMI_VOLATILE))                                                \
+                                                                                                 \
+/* Atomically test and clear a bit in a PTE */                                                   \
+VMI_FUNC( TestAndClearPteBit,                                                                    \
+          VMI_BOOL, VMI_ARGS(VMI_INT bit, VMI_PTE *ptep),                                        \
+          VMI_OUTPUT("=a" (ret)),                                                                \
+          VMI_INPUT("0" (bit), "d" (ptep)),                                                      \
+          VMI_MEM_CLOBBER,                                                                       \
+          VMI_ATTRIBUTES(VMI_FLAT, VMI_VOLATILE))                                                \
+                                                                                                 \
+/* Set a PAE P{T|D|PD}E */                                                                       \
+VMI_PROC( SetPteLong,                                                                            \
+          VMI_ARGS(VMI_PAE_PTE pte, VMI_PAE_PTE *ptep),                                          \
+          VMI_OUTPUT(),                                                                          \
+          VMI_INPUT("A" (pte), "c" (ptep)),                                                      \
+          VMI_MEM_CLOBBER,                                                                       \
+          VMI_ATTRIBUTES(VMI_FLAT, VMI_VOLATILE))                                                \
+                                                                                                 \
+/* Atomically swap a PAE PTE */                                                                  \
+VMI_FUNC( SwapPteLong,                                                                           \
+          VMI_PAE_PTE, VMI_ARGS(VMI_UINT64 pte, VMI_PAE_PTE *ptep),                              \
+          VMI_OUTPUT("=A" (ret)),                                                                \
+          VMI_INPUT("b" ((VMI_UINT32)(pte)), "c" ((VMI_UINT32)((pte)>>32)), "D" (ptep)),         \
+          VMI_MEM_CLOBBER,                                                                       \
+          VMI_ATTRIBUTES(VMI_FLAT, VMI_VOLATILE))                                                \
+                                                                                                 \
+/* Atomically test and set a bit in a PAE PTE */                                                 \
+VMI_FUNC( TestAndSetPteBitLong,                                                                  \
+          VMI_BOOL, VMI_ARGS(VMI_INT bit, VMI_PAE_PTE *ptep),                                    \
+          VMI_OUTPUT("=a" (ret)),                                                                \
+          VMI_INPUT("0" (bit), "d" (ptep)),                                                      \
+          VMI_MEM_CLOBBER,                                                                       \
+          VMI_ATTRIBUTES(VMI_FLAT, VMI_VOLATILE))                                                \
+                                                                                                 \
+/* Atomically test and clear a bit in a PAE PTE */                                               \
+VMI_FUNC( TestAndClearPteBitLong,                                                                \
+          VMI_BOOL, VMI_ARGS(VMI_INT bit, VMI_PAE_PTE *ptep),                                    \
+          VMI_OUTPUT("=a" (ret)),                                                                \
+          VMI_INPUT("0" (bit), "d" (ptep)),                                                      \
+          VMI_MEM_CLOBBER,                                                                       \
+          VMI_ATTRIBUTES(VMI_FLAT, VMI_VOLATILE))                                                \
+                                                                                                 \
+/* Clone a new PT from an existing page */                                                       \
+VMI_PROC( ClonePageTable,                                                                        \
+          VMI_ARGS(VMI_UINT32 dstPPN, VMI_UINT32 srcPPN, VMI_UINT32 flags),                      \
+          VMI_OUTPUT(),                                                                          \
+          VMI_INPUT("a" (dstPPN), "d" (srcPPN), "c" (flags)),                                    \
+          VMI_ASM_CLOBBER,                                                                       \
+          VMI_ATTRIBUTES(VMI_FLAT, VMI_VOLATILE))                                                \
+                                                                                                 \
+/* Clone a new PD from an existing page */                                                       \
+VMI_PROC( ClonePageDirectory,                                                                    \
+          VMI_ARGS(VMI_UINT32 dstPPN, VMI_UINT32 srcPPN, VMI_UINT32 flags),                      \
+          VMI_OUTPUT(),                                                                          \
+          VMI_INPUT("a" (dstPPN), "d" (srcPPN), "c" (flags)),                                    \
+          VMI_ASM_CLOBBER,                                                                       \
+          VMI_ATTRIBUTES(VMI_FLAT, VMI_VOLATILE))                                                \
+                                                                                                 \
+/* Notify hypervisor about maps of page primaries */                                             \
+VMI_PROC( RegisterPageMapping,                                                                   \
+          VMI_ARGS(VMI_UINT32 va, VMI_UINT32 ppn, VMI_UINT32 pages),                             \
+          VMI_OUTPUT(),                                                                          \
+          VMI_INPUT("a" (va), "d" (ppn), "c" (pages)),                                           \
+          VMI_ASM_CLOBBER,                                                                       \
+          VMI_ATTRIBUTES(VMI_FLAT, VMI_VOLATILE))                                                \
+                                                                                                 \
+/* Notify hypervisor how a page is being used (PT, PD, GDT, etc.) */                             \
+VMI_PROC( RegisterPageUsage,                                                                     \
+          VMI_ARGS(VMI_UINT32 ppn, int flags),                                                   \
+          VMI_OUTPUT(),                                                                          \
+          VMI_INPUT("a" (ppn), "d" (flags)),                                                     \
+          VMI_ASM_CLOBBER,                                                                       \
+          VMI_ATTRIBUTES(VMI_FLAT, VMI_VOLATILE))                                                \
+                                                                                                 \
+/* Notify hypervisor a page is no longer being used */                                           \
+VMI_PROC( ReleasePage,                                                                           \
+          VMI_ARGS(VMI_UINT32 ppn, int flags),                                                   \
+          VMI_OUTPUT(),                                                                          \
+          VMI_INPUT("a" (ppn), "d" (flags)),                                                     \
+          VMI_ASM_CLOBBER,                                                                       \
+          VMI_ATTRIBUTES(VMI_FLAT, VMI_VOLATILE))                                                \
+                                                                                                 \
+/* Binary INVLPG equivalent */                                                                   \
+VMI_PROC( InvalPage,                                                                             \
+          VMI_ARGS(VMI_UINT32 va),                                                               \
+          VMI_OUTPUT(),                                                                          \
+          VMI_INPUT("a" (va)),                                                                   \
+          VMI_MEM_CLOBBER,                                                                       \
+          VMI_ATTRIBUTES(VMI_FLAT, VMI_VOLATILE))                                                \
+                                                                                                 \
+/* Flush local TLB */                                                                            \
+VMI_PROC( FlushTLB,                                                                              \
+          VMI_ARGS(void),                                                                        \
+          VMI_OUTPUT(),                                                                          \
+          VMI_INPUT(),                                                                           \
+          VMI_MEM_CLOBBER,                                                                       \
+          VMI_ATTRIBUTES(VMI_FLAT, VMI_VOLATILE))                                                \
+                                                                                                 \
+/* Flush local TLB, including global entries */                                                  \
+VMI_PROC( FlushTLBAll,                                                                           \
+          VMI_ARGS(void),                                                                        \
+          VMI_OUTPUT(),                                                                          \
+          VMI_INPUT(),                                                                           \
+          VMI_MEM_CLOBBER,                                                                       \
+          VMI_ATTRIBUTES(VMI_FLAT, VMI_VOLATILE))                                                \
+                                                                                                 \
+/* Set new lazy update mode */                                                                   \
+VMI_PROC( SetDeferredMode,                                                                       \
+          VMI_ARGS(VMI_UINT32 deferBits),                                                        \
+          VMI_OUTPUT(),                                                                          \
+          VMI_INPUT(),                                                                           \
+          VMI_ASM_CLOBBER,                                                                       \
+          VMI_ATTRIBUTES(VMI_FLAT, VMI_VOLATILE))                                                \
+                                                                                                 \
+/* Flush all pending CPU & MMU state updates */                                                  \
+VMI_PROC( FlushDeferredCalls,                                                                    \
+          VMI_ARGS(void),                                                                        \
+          VMI_OUTPUT(),                                                                          \
+          VMI_INPUT(),                                                                           \
+          VMI_ASM_CLOBBER,                                                                       \
+          VMI_ATTRIBUTES(VMI_FLAT, VMI_VOLATILE))                                                \
+												 \
+/* Translate guest physical to machine physical */                                               \
+VMI_FUNC( PhysToMachine,                                                                         \
+          VMI_UINT32, VMI_ARGS(VMI_UINT32 addr),						 \
+          VMI_OUTPUT("=a" (ret)),                                                                \
+          VMI_INPUT("0" (addr)),		                                                 \
+          VMI_MEM_CLOBBER,                                                                       \
+          VMI_ATTRIBUTES(VMI_FLAT, VMI_VOLATILE))                                                \
+												 \
+/* Translate machine physical to guest physical */                                               \
+VMI_FUNC( MachineToPhys,                                                                         \
+          VMI_UINT32, VMI_ARGS(VMI_UINT32 addr),						 \
+          VMI_OUTPUT("=a" (ret)),                                                                \
+          VMI_INPUT("0" (addr)),		                                                 \
+          VMI_MEM_CLOBBER,                                                                       \
+          VMI_ATTRIBUTES(VMI_FLAT, VMI_VOLATILE))                                                \
+
diff -Naur linux-2.6.12.3.pristine/include/asm-i386/msr.h linux-2.6.12.3-vmi/include/asm-i386/msr.h
--- linux-2.6.12.3.pristine/include/asm-i386/msr.h	2005-07-15 21:18:57.000000000 +0000
+++ linux-2.6.12.3-vmi/include/asm-i386/msr.h	2005-11-15 16:57:30.000000000 +0000
@@ -1,22 +1,14 @@
 #ifndef __ASM_MSR_H
 #define __ASM_MSR_H
 
+#include <mach_msr.h>
+
 /*
  * Access to machine-specific registers (available on 586 and better only)
  * Note: the rd* operations modify the parameters directly (without using
  * pointer indirection), this allows gcc to optimize better
  */
 
-#define rdmsr(msr,val1,val2) \
-	__asm__ __volatile__("rdmsr" \
-			  : "=a" (val1), "=d" (val2) \
-			  : "c" (msr))
-
-#define wrmsr(msr,val1,val2) \
-	__asm__ __volatile__("wrmsr" \
-			  : /* no outputs */ \
-			  : "c" (msr), "a" (val1), "d" (val2))
-
 #define rdmsrl(msr,val) do { \
 	unsigned long l__,h__; \
 	rdmsr (msr, l__, h__);  \
@@ -32,37 +24,6 @@
 	wrmsr (msr, lo, hi);
 }
 
-/* wrmsr with exception handling */
-#define wrmsr_safe(msr,a,b) ({ int ret__;						\
-	asm volatile("2: wrmsr ; xorl %0,%0\n"						\
-		     "1:\n\t"								\
-		     ".section .fixup,\"ax\"\n\t"					\
-		     "3:  movl %4,%0 ; jmp 1b\n\t"					\
-		     ".previous\n\t"							\
- 		     ".section __ex_table,\"a\"\n"					\
-		     "   .align 4\n\t"							\
-		     "   .long 	2b,3b\n\t"						\
-		     ".previous"							\
-		     : "=a" (ret__)							\
-		     : "c" (msr), "0" (a), "d" (b), "i" (-EFAULT));\
-	ret__; })
-
-#define rdtsc(low,high) \
-     __asm__ __volatile__("rdtsc" : "=a" (low), "=d" (high))
-
-#define rdtscl(low) \
-     __asm__ __volatile__("rdtsc" : "=a" (low) : : "edx")
-
-#define rdtscll(val) \
-     __asm__ __volatile__("rdtsc" : "=A" (val))
-
-#define write_tsc(val1,val2) wrmsr(0x10, val1, val2)
-
-#define rdpmc(counter,low,high) \
-     __asm__ __volatile__("rdpmc" \
-			  : "=a" (low), "=d" (high) \
-			  : "c" (counter))
-
 /* symbolic names for some interesting MSRs */
 /* Intel defined MSRs. */
 #define MSR_IA32_P5_MC_ADDR		0
diff -Naur linux-2.6.12.3.pristine/include/asm-i386/page.h linux-2.6.12.3-vmi/include/asm-i386/page.h
--- linux-2.6.12.3.pristine/include/asm-i386/page.h	2005-07-15 21:18:57.000000000 +0000
+++ linux-2.6.12.3-vmi/include/asm-i386/page.h	2005-12-14 20:44:54.000000000 +0000
@@ -49,7 +49,7 @@
 typedef struct { unsigned long long pmd; } pmd_t;
 typedef struct { unsigned long long pgd; } pgd_t;
 typedef struct { unsigned long long pgprot; } pgprot_t;
-#define pmd_val(x)	((x).pmd)
+// VU: #define pmd_val(x)	((x).pmd)
 #define pte_val(x)	((x).pte_low | ((unsigned long long)(x).pte_high << 32))
 #define __pmd(x) ((pmd_t) { (x) } )
 #define HPAGE_SHIFT	21
@@ -70,7 +70,7 @@
 #define HAVE_ARCH_HUGETLB_UNMAPPED_AREA
 #endif
 
-#define pgd_val(x)	((x).pgd)
+//VU: #define pgd_val(x)	((x).pgd)
 #define pgprot_val(x)	((x).pgprot)
 
 #define __pte(x) ((pte_t) { (x) } )
diff -Naur linux-2.6.12.3.pristine/include/asm-i386/param.h linux-2.6.12.3-vmi/include/asm-i386/param.h
--- linux-2.6.12.3.pristine/include/asm-i386/param.h	2005-07-15 21:18:57.000000000 +0000
+++ linux-2.6.12.3-vmi/include/asm-i386/param.h	2005-11-15 16:57:30.000000000 +0000
@@ -1,10 +1,18 @@
 #ifndef _ASMi386_PARAM_H
 #define _ASMi386_PARAM_H
 
+#include <linux/config.h>
+
 #ifdef __KERNEL__
+#ifdef CONFIG_FAST_TIMER
 # define HZ		1000		/* Internal kernel timer frequency */
+# define CLOCK_ADJ	0
+#else
+# define HZ             100
+# define CLOCK_ADJ	30000		/* hack around borken times() conversion */
+#endif
 # define USER_HZ	100		/* .. some user interfaces are in "ticks" */
-# define CLOCKS_PER_SEC		(USER_HZ)	/* like times() */
+# define CLOCKS_PER_SEC	(USER_HZ)	/* like times() */
 #endif
 
 #ifndef HZ
diff -Naur linux-2.6.12.3.pristine/include/asm-i386/pgalloc.h linux-2.6.12.3-vmi/include/asm-i386/pgalloc.h
--- linux-2.6.12.3.pristine/include/asm-i386/pgalloc.h	2005-07-15 21:18:57.000000000 +0000
+++ linux-2.6.12.3-vmi/include/asm-i386/pgalloc.h	2005-11-15 16:57:30.000000000 +0000
@@ -5,14 +5,22 @@
 #include <asm/fixmap.h>
 #include <linux/threads.h>
 #include <linux/mm.h>		/* for struct page */
+#include <mach_pgalloc.h>
 
-#define pmd_populate_kernel(mm, pmd, pte) \
-		set_pmd(pmd, __pmd(_PAGE_TABLE + __pa(pte)))
+#define pmd_populate_kernel(mm, pmd, pte) 			\
+do {								\
+	mach_use_pte(__pa(pte) >> PAGE_SHIFT);			\
+	set_pmd(pmd, __pmd(_PAGE_TABLE + __pa(pte)));		\
+} while (0)
 
 #define pmd_populate(mm, pmd, pte) 				\
+do {								\
+	mach_use_pte(page_to_pfn(pte));				\
 	set_pmd(pmd, __pmd(_PAGE_TABLE +			\
 		((unsigned long long)page_to_pfn(pte) <<	\
-			(unsigned long long) PAGE_SHIFT)))
+			(unsigned long long) PAGE_SHIFT)));	\
+} while (0)
+
 /*
  * Allocate and free page tables.
  */
@@ -33,7 +41,11 @@
 }
 
 
-#define __pte_free_tlb(tlb,pte) tlb_remove_page((tlb),(pte))
+#define __pte_free_tlb(tlb,pte) 		\
+do {						\
+	tlb_remove_page((tlb),(pte));		\
+	mach_unuse_pte(page_to_pfn(pte));	\
+} while (0)
 
 #ifdef CONFIG_X86_PAE
 /*
diff -Naur linux-2.6.12.3.pristine/include/asm-i386/pgtable-2level.h linux-2.6.12.3-vmi/include/asm-i386/pgtable-2level.h
--- linux-2.6.12.3.pristine/include/asm-i386/pgtable-2level.h	2005-07-15 21:18:57.000000000 +0000
+++ linux-2.6.12.3-vmi/include/asm-i386/pgtable-2level.h	2005-12-14 20:46:31.000000000 +0000
@@ -8,21 +8,10 @@
 #define pgd_ERROR(e) \
 	printk("%s:%d: bad pgd %08lx.\n", __FILE__, __LINE__, pgd_val(e))
 
-/*
- * Certain architectures need to do special things when PTEs
- * within a page table are directly modified.  Thus, the following
- * hook is made available.
- */
-#define set_pte(pteptr, pteval) (*(pteptr) = pteval)
-#define set_pte_at(mm,addr,ptep,pteval) set_pte(ptep,pteval)
-#define set_pte_atomic(pteptr, pteval) set_pte(pteptr,pteval)
-#define set_pmd(pmdptr, pmdval) (*(pmdptr) = (pmdval))
-
-#define ptep_get_and_clear(mm,addr,xp)	__pte(xchg(&(xp)->pte_low, 0))
 #define pte_same(a, b)		((a).pte_low == (b).pte_low)
 #define pte_page(x)		pfn_to_page(pte_pfn(x))
 #define pte_none(x)		(!(x).pte_low)
-#define pte_pfn(x)		((unsigned long)(((x).pte_low >> PAGE_SHIFT)))
+// VU: #define pte_pfn(x)		((unsigned long)(((x).pte_low >> PAGE_SHIFT)))
 #define pfn_pte(pfn, prot)	__pte(((pfn) << PAGE_SHIFT) | pgprot_val(prot))
 #define pfn_pmd(pfn, prot)	__pmd(((pfn) << PAGE_SHIFT) | pgprot_val(prot))
 
diff -Naur linux-2.6.12.3.pristine/include/asm-i386/pgtable-3level.h linux-2.6.12.3-vmi/include/asm-i386/pgtable-3level.h
--- linux-2.6.12.3.pristine/include/asm-i386/pgtable-3level.h	2005-07-15 21:18:57.000000000 +0000
+++ linux-2.6.12.3-vmi/include/asm-i386/pgtable-3level.h	2005-11-15 16:57:30.000000000 +0000
@@ -44,28 +44,6 @@
 	return pte_x(pte);
 }
 
-/* Rules for using set_pte: the pte being assigned *must* be
- * either not present or in a state where the hardware will
- * not attempt to update the pte.  In places where this is
- * not possible, use pte_get_and_clear to obtain the old pte
- * value and then use set_pte to update it.  -ben
- */
-static inline void set_pte(pte_t *ptep, pte_t pte)
-{
-	ptep->pte_high = pte.pte_high;
-	smp_wmb();
-	ptep->pte_low = pte.pte_low;
-}
-#define set_pte_at(mm,addr,ptep,pteval) set_pte(ptep,pteval)
-
-#define __HAVE_ARCH_SET_PTE_ATOMIC
-#define set_pte_atomic(pteptr,pteval) \
-		set_64bit((unsigned long long *)(pteptr),pte_val(pteval))
-#define set_pmd(pmdptr,pmdval) \
-		set_64bit((unsigned long long *)(pmdptr),pmd_val(pmdval))
-#define set_pud(pudptr,pudval) \
-		set_64bit((unsigned long long *)(pudptr),pud_val(pudval))
-
 /*
  * Pentium-II erratum A13: in PAE mode we explicitly have to flush
  * the TLB via cr3 if the top-level pgd is changed...
@@ -90,18 +68,6 @@
 #define pmd_offset(pud, address) ((pmd_t *) pud_page(*(pud)) + \
 			pmd_index(address))
 
-static inline pte_t ptep_get_and_clear(struct mm_struct *mm, unsigned long addr, pte_t *ptep)
-{
-	pte_t res;
-
-	/* xchg acts as a barrier before the setting of the high bits */
-	res.pte_low = xchg(&ptep->pte_low, 0);
-	res.pte_high = ptep->pte_high;
-	ptep->pte_high = 0;
-
-	return res;
-}
-
 static inline int pte_same(pte_t a, pte_t b)
 {
 	return a.pte_low == b.pte_low && a.pte_high == b.pte_high;
@@ -155,6 +121,4 @@
 #define __pte_to_swp_entry(pte)		((swp_entry_t){ (pte).pte_high })
 #define __swp_entry_to_pte(x)		((pte_t){ 0, (x).val })
 
-#define __pmd_free_tlb(tlb, x)		do { } while (0)
-
 #endif /* _I386_PGTABLE_3LEVEL_H */
diff -Naur linux-2.6.12.3.pristine/include/asm-i386/pgtable.h linux-2.6.12.3-vmi/include/asm-i386/pgtable.h
--- linux-2.6.12.3.pristine/include/asm-i386/pgtable.h	2005-07-15 21:18:57.000000000 +0000
+++ linux-2.6.12.3-vmi/include/asm-i386/pgtable.h	2005-11-15 16:57:30.000000000 +0000
@@ -201,11 +201,9 @@
 extern unsigned long pg0[];
 
 #define pte_present(x)	((x).pte_low & (_PAGE_PRESENT | _PAGE_PROTNONE))
-#define pte_clear(mm,addr,xp)	do { set_pte_at(mm, addr, xp, __pte(0)); } while (0)
 
 #define pmd_none(x)	(!pmd_val(x))
 #define pmd_present(x)	(pmd_val(x) & _PAGE_PRESENT)
-#define pmd_clear(xp)	do { set_pmd(xp, __pmd(0)); } while (0)
 #define	pmd_bad(x)	((pmd_val(x) & (~PAGE_MASK & ~_PAGE_USER)) != _KERNPG_TABLE)
 
 
@@ -242,24 +240,24 @@
 #else
 # include <asm/pgtable-2level.h>
 #endif
+#include <pgtable-ops.h>
+  
+#define set_pte_at(mm,addr,pteptr,pteval) set_pte(pteptr,pteval)
 
-static inline int ptep_test_and_clear_dirty(struct vm_area_struct *vma, unsigned long addr, pte_t *ptep)
-{
-	if (!pte_dirty(*ptep))
-		return 0;
-	return test_and_clear_bit(_PAGE_BIT_DIRTY, &ptep->pte_low);
-}
-
-static inline int ptep_test_and_clear_young(struct vm_area_struct *vma, unsigned long addr, pte_t *ptep)
-{
-	if (!pte_young(*ptep))
-		return 0;
-	return test_and_clear_bit(_PAGE_BIT_ACCESSED, &ptep->pte_low);
-}
+#define pte_clear(mm,addr,xp)	do { set_pte_at(mm, addr, xp, __pte(0)); } while (0)
+#define pmd_clear(xp)	do { set_pmd(xp, __pmd(0)); } while (0)
 
-static inline void ptep_set_wrprotect(struct mm_struct *mm, unsigned long addr, pte_t *ptep)
+static inline pte_t ptep_get_and_clear_full(struct mm_struct *mm, unsigned long addr, pte_t *ptep, int full) 
 {
-	clear_bit(_PAGE_BIT_RW, &ptep->pte_low);
+	pte_t pte;
+	if (full) {
+		pte = *ptep;
+		set_pte(ptep, __pte(0));
+		// VU: *ptep = __pte(0);
+	} else {
+		pte = ptep_get_and_clear(mm, addr, ptep);
+	}
+	return pte;
 }
 
 /*
@@ -361,11 +359,20 @@
 
 extern void noexec_setup(const char *str);
 
+#include <mach_pgalloc.h>
 #if defined(CONFIG_HIGHPTE)
-#define pte_offset_map(dir, address) \
-	((pte_t *)kmap_atomic(pmd_page(*(dir)),KM_PTE0) + pte_index(address))
-#define pte_offset_map_nested(dir, address) \
-	((pte_t *)kmap_atomic(pmd_page(*(dir)),KM_PTE1) + pte_index(address))
+#define pte_offset_map(dir, address) ({ \
+	pte_t *ptep = ((pte_t *)kmap_atomic(pmd_page(*(dir)),KM_PTE0) + \
+		 pte_index(address)); \
+	mach_map_pagetables((unsigned long)ptep,page_to_pfn(pmd_page(*(dir))), 1); \
+	ptep; \
+})
+#define pte_offset_map_nested(dir, address) ({ \
+	pte_t *ptep = ((pte_t *)kmap_atomic(pmd_page(*(dir)),KM_PTE1) + \
+		 pte_index(address)); \
+	mach_map_pagetables((unsigned long)ptep, page_to_pfn(pmd_page(*(dir))), 1); \
+	ptep; \
+})
 #define pte_unmap(pte) kunmap_atomic(pte, KM_PTE0)
 #define pte_unmap_nested(pte) kunmap_atomic(pte, KM_PTE1)
 #else
@@ -376,26 +383,6 @@
 #define pte_unmap_nested(pte) do { } while (0)
 #endif
 
-/*
- * The i386 doesn't have any external MMU info: the kernel page
- * tables contain all the necessary information.
- *
- * Also, we only update the dirty/accessed state if we set
- * the dirty bit by hand in the kernel, since the hardware
- * will do the accessed bit for us, and we don't want to
- * race with other CPU's that might be updating the dirty
- * bit at the same time.
- */
-#define update_mmu_cache(vma,address,pte) do { } while (0)
-#define  __HAVE_ARCH_PTEP_SET_ACCESS_FLAGS
-#define ptep_set_access_flags(__vma, __address, __ptep, __entry, __dirty) \
-	do {								  \
-		if (__dirty) {						  \
-			(__ptep)->pte_low = (__entry).pte_low;	  	  \
-			flush_tlb_page(__vma, __address);		  \
-		}							  \
-	} while (0)
-
 #endif /* !__ASSEMBLY__ */
 
 #ifndef CONFIG_DISCONTIGMEM
@@ -415,6 +402,7 @@
 #define __HAVE_ARCH_PTEP_TEST_AND_CLEAR_YOUNG
 #define __HAVE_ARCH_PTEP_TEST_AND_CLEAR_DIRTY
 #define __HAVE_ARCH_PTEP_GET_AND_CLEAR
+#define __HAVE_ARCH_PTEP_GET_AND_CLEAR_FULL
 #define __HAVE_ARCH_PTEP_SET_WRPROTECT
 #define __HAVE_ARCH_PTE_SAME
 #include <asm-generic/pgtable.h>
diff -Naur linux-2.6.12.3.pristine/include/asm-i386/processor.h linux-2.6.12.3-vmi/include/asm-i386/processor.h
--- linux-2.6.12.3.pristine/include/asm-i386/processor.h	2005-07-15 21:18:57.000000000 +0000
+++ linux-2.6.12.3-vmi/include/asm-i386/processor.h	2005-11-15 16:57:30.000000000 +0000
@@ -23,6 +23,7 @@
 
 /* flag for disabling the tsc */
 extern int tsc_disable;
+extern int mwait_disable;
 
 struct desc_struct {
 	unsigned long a,b;
@@ -133,81 +134,6 @@
 #define X86_EFLAGS_ID	0x00200000 /* CPUID detection flag */
 
 /*
- * Generic CPUID function
- * clear %ecx since some cpus (Cyrix MII) do not set or clear %ecx
- * resulting in stale register contents being returned.
- */
-static inline void cpuid(unsigned int op, unsigned int *eax, unsigned int *ebx, unsigned int *ecx, unsigned int *edx)
-{
-	__asm__("cpuid"
-		: "=a" (*eax),
-		  "=b" (*ebx),
-		  "=c" (*ecx),
-		  "=d" (*edx)
-		: "0" (op), "c"(0));
-}
-
-/* Some CPUID calls want 'count' to be placed in ecx */
-static inline void cpuid_count(int op, int count, int *eax, int *ebx, int *ecx,
-	       	int *edx)
-{
-	__asm__("cpuid"
-		: "=a" (*eax),
-		  "=b" (*ebx),
-		  "=c" (*ecx),
-		  "=d" (*edx)
-		: "0" (op), "c" (count));
-}
-
-/*
- * CPUID functions returning a single datum
- */
-static inline unsigned int cpuid_eax(unsigned int op)
-{
-	unsigned int eax;
-
-	__asm__("cpuid"
-		: "=a" (eax)
-		: "0" (op)
-		: "bx", "cx", "dx");
-	return eax;
-}
-static inline unsigned int cpuid_ebx(unsigned int op)
-{
-	unsigned int eax, ebx;
-
-	__asm__("cpuid"
-		: "=a" (eax), "=b" (ebx)
-		: "0" (op)
-		: "cx", "dx" );
-	return ebx;
-}
-static inline unsigned int cpuid_ecx(unsigned int op)
-{
-	unsigned int eax, ecx;
-
-	__asm__("cpuid"
-		: "=a" (eax), "=c" (ecx)
-		: "0" (op)
-		: "bx", "dx" );
-	return ecx;
-}
-static inline unsigned int cpuid_edx(unsigned int op)
-{
-	unsigned int eax, edx;
-
-	__asm__("cpuid"
-		: "=a" (eax), "=d" (edx)
-		: "0" (op)
-		: "bx", "cx");
-	return edx;
-}
-
-#define load_cr3(pgdir) \
-	asm volatile("movl %0,%%cr3": :"r" (__pa(pgdir)))
-
-
-/*
  * Intel CPU features in CR4
  */
 #define X86_CR4_VME		0x0001	/* enable vm86 extensions */
@@ -222,6 +148,9 @@
 #define X86_CR4_OSFXSR		0x0200	/* enable fast FPU save and restore */
 #define X86_CR4_OSXMMEXCPT	0x0400	/* enable unmasked SSE exceptions */
 
+#include <mach_processor.h>
+#include <mach_segment.h>
+
 /*
  * Save the cr4 feature set we're using (ie
  * Pentium 4MB enable and PPro Global page
@@ -232,22 +161,20 @@
 
 static inline void set_in_cr4 (unsigned long mask)
 {
+	unsigned cr4;
 	mmu_cr4_features |= mask;
-	__asm__("movl %%cr4,%%eax\n\t"
-		"orl %0,%%eax\n\t"
-		"movl %%eax,%%cr4\n"
-		: : "irg" (mask)
-		:"ax");
+	cr4 = read_cr4();
+	cr4 |= mask;
+	write_cr4(cr4);
 }
 
 static inline void clear_in_cr4 (unsigned long mask)
 {
+	unsigned cr4;
 	mmu_cr4_features &= ~mask;
-	__asm__("movl %%cr4,%%eax\n\t"
-		"andl %0,%%eax\n\t"
-		"movl %%eax,%%cr4\n"
-		: : "irg" (~mask)
-		:"ax");
+	cr4 = read_cr4();
+	cr4 &= ~mask;
+	write_cr4(cr4);
 }
 
 /*
@@ -281,6 +208,11 @@
 	outb((data), 0x23); \
 } while (0)
 
+static inline void serialize(void)
+{
+	 __asm__ __volatile__ ("cpuid" : : : "ax", "bx", "cx", "dx");
+}
+
 static inline void __monitor(const void *eax, unsigned long ecx,
 		unsigned long edx)
 {
@@ -456,6 +388,7 @@
 	unsigned long	*io_bitmap_ptr;
 /* max allowed port in the bitmap, in bytes: */
 	unsigned long	io_bitmap_max;
+	unsigned long	iopl;
 };
 
 #define INIT_THREAD  {							\
@@ -481,7 +414,7 @@
 
 static inline void load_esp0(struct tss_struct *tss, struct thread_struct *thread)
 {
-	tss->esp0 = thread->esp0;
+	load_kernel_stack(tss, __KERNEL_DS, thread->esp0);
 	/* This can only happen when SEP is enabled, no need to test "SEP"arately */
 	if (unlikely(tss->ss1 != thread->sysenter_cs)) {
 		tss->ss1 = thread->sysenter_cs;
@@ -500,14 +433,6 @@
 	regs->esp = new_esp;					\
 } while (0)
 
-/*
- * This special macro can be used to load a debugging register
- */
-#define loaddebug(thread,register) \
-               __asm__("movl %0,%%db" #register  \
-                       : /* no output */ \
-                       :"r" ((thread)->debugreg[register]))
-
 /* Forward declaration, a strange C thing */
 struct task_struct;
 struct mm_struct;
diff -Naur linux-2.6.12.3.pristine/include/asm-i386/ptrace.h linux-2.6.12.3-vmi/include/asm-i386/ptrace.h
--- linux-2.6.12.3.pristine/include/asm-i386/ptrace.h	2005-07-15 21:18:57.000000000 +0000
+++ linux-2.6.12.3-vmi/include/asm-i386/ptrace.h	2005-11-15 16:57:30.000000000 +0000
@@ -57,7 +57,15 @@
 #ifdef __KERNEL__
 struct task_struct;
 extern void send_sigtrap(struct task_struct *tsk, struct pt_regs *regs, int error_code);
-#define user_mode(regs) ((VM_MASK & (regs)->eflags) || (3 & (regs)->xcs))
+
+/*
+ * user_mode(regs) determines whether a register set came from user mode.
+ * This is true if V8086 mode was enabled OR if the register set was from
+ * protected mode with RPL-3 CS value.  This tricky test checks that with
+ * one comparison.  Many places in the kernel can bypass this full check
+ * if they have already ruled out V8086 mode.
+ */
+#define user_mode(regs) (((VM_MASK & (regs)->eflags) | ((regs)->xcs & 3)) >= 3)
 #define instruction_pointer(regs) ((regs)->eip)
 #if defined(CONFIG_SMP) && defined(CONFIG_FRAME_POINTER)
 extern unsigned long profile_pc(struct pt_regs *regs);
diff -Naur linux-2.6.12.3.pristine/include/asm-i386/system.h linux-2.6.12.3-vmi/include/asm-i386/system.h
--- linux-2.6.12.3.pristine/include/asm-i386/system.h	2005-07-15 21:18:57.000000000 +0000
+++ linux-2.6.12.3-vmi/include/asm-i386/system.h	2005-11-15 16:57:30.000000000 +0000
@@ -14,8 +14,7 @@
 
 #define switch_to(prev,next,last) do {					\
 	unsigned long esi,edi;						\
-	asm volatile("pushfl\n\t"					\
-		     "pushl %%ebp\n\t"					\
+	asm volatile("pushl %%ebp\n\t"					\
 		     "movl %%esp,%0\n\t"	/* save ESP */		\
 		     "movl %5,%%esp\n\t"	/* restore ESP */	\
 		     "movl $1f,%1\n\t"		/* save EIP */		\
@@ -23,7 +22,6 @@
 		     "jmp __switch_to\n"				\
 		     "1:\t"						\
 		     "popl %%ebp\n\t"					\
-		     "popfl"						\
 		     :"=m" (prev->thread.esp),"=m" (prev->thread.eip),	\
 		      "=a" (last),"=S" (esi),"=D" (edi)			\
 		     :"m" (next->thread.esp),"m" (next->thread.eip),	\
@@ -93,44 +91,23 @@
 		".align 4\n\t"			\
 		".long 1b,3b\n"			\
 		".previous"			\
-		: :"m" (value))
+		: :"rm" (value))
 
 /*
  * Save a segment register away
  */
 #define savesegment(seg, value) \
-	asm volatile("mov %%" #seg ",%0":"=m" (value))
+	asm volatile("mov %%" #seg ",%0":"=rm" (value))
 
-/*
- * Clear and set 'TS' bit respectively
- */
-#define clts() __asm__ __volatile__ ("clts")
-#define read_cr0() ({ \
-	unsigned int __dummy; \
-	__asm__( \
-		"movl %%cr0,%0\n\t" \
-		:"=r" (__dummy)); \
-	__dummy; \
-})
-#define write_cr0(x) \
-	__asm__("movl %0,%%cr0": :"r" (x));
-
-#define read_cr4() ({ \
-	unsigned int __dummy; \
-	__asm__( \
-		"movl %%cr4,%0\n\t" \
-		:"=r" (__dummy)); \
-	__dummy; \
-})
-#define write_cr4(x) \
-	__asm__("movl %0,%%cr4": :"r" (x));
-#define stts() write_cr0(8 | read_cr0())
+static inline unsigned short get_current_ss(void)
+{
+	unsigned short seg;
+	__asm__("mov %%ss, %0" : "=rm" (seg));
+	return seg;
+}
 
 #endif	/* __KERNEL__ */
 
-#define wbinvd() \
-	__asm__ __volatile__ ("wbinvd": : :"memory");
-
 static inline unsigned long get_limit(unsigned long segment)
 {
 	unsigned long __limit;
@@ -441,12 +418,7 @@
 #define set_wmb(var, value) do { var = value; wmb(); } while (0)
 
 /* interrupt control.. */
-#define local_save_flags(x)	do { typecheck(unsigned long,x); __asm__ __volatile__("pushfl ; popl %0":"=g" (x): /* no input */); } while (0)
-#define local_irq_restore(x) 	do { typecheck(unsigned long,x); __asm__ __volatile__("pushl %0 ; popfl": /* no output */ :"g" (x):"memory", "cc"); } while (0)
-#define local_irq_disable() 	__asm__ __volatile__("cli": : :"memory")
-#define local_irq_enable()	__asm__ __volatile__("sti": : :"memory")
-/* used in the idle loop; sti takes one instruction cycle to complete */
-#define safe_halt()		__asm__ __volatile__("sti; hlt": : :"memory")
+#include <mach_irqcontrol.h>
 
 #define irqs_disabled()			\
 ({					\
@@ -455,9 +427,6 @@
 	!(flags & (1<<9));		\
 })
 
-/* For spinlocks etc */
-#define local_irq_save(x)	__asm__ __volatile__("pushfl ; popl %0 ; cli":"=g" (x): /* no input */ :"memory")
-
 /*
  * disable hlt during certain critical i/o operations
  */
diff -Naur linux-2.6.12.3.pristine/include/asm-i386/tlbflush.h linux-2.6.12.3-vmi/include/asm-i386/tlbflush.h
--- linux-2.6.12.3.pristine/include/asm-i386/tlbflush.h	2005-07-15 21:18:57.000000000 +0000
+++ linux-2.6.12.3-vmi/include/asm-i386/tlbflush.h	2005-11-15 16:57:30.000000000 +0000
@@ -4,36 +4,7 @@
 #include <linux/config.h>
 #include <linux/mm.h>
 #include <asm/processor.h>
-
-#define __flush_tlb()							\
-	do {								\
-		unsigned int tmpreg;					\
-									\
-		__asm__ __volatile__(					\
-			"movl %%cr3, %0;              \n"		\
-			"movl %0, %%cr3;  # flush TLB \n"		\
-			: "=r" (tmpreg)					\
-			:: "memory");					\
-	} while (0)
-
-/*
- * Global pages have to be flushed a bit differently. Not a real
- * performance problem because this does not happen often.
- */
-#define __flush_tlb_global()						\
-	do {								\
-		unsigned int tmpreg;					\
-									\
-		__asm__ __volatile__(					\
-			"movl %1, %%cr4;  # turn off PGE     \n"	\
-			"movl %%cr3, %0;                     \n"	\
-			"movl %0, %%cr3;  # flush TLB        \n"	\
-			"movl %2, %%cr4;  # turn PGE back on \n"	\
-			: "=&r" (tmpreg)				\
-			: "r" (mmu_cr4_features & ~X86_CR4_PGE),	\
-			  "r" (mmu_cr4_features)			\
-			: "memory");					\
-	} while (0)
+#include <mach_tlbflush.h>
 
 extern unsigned long pgkern_mask;
 
@@ -47,9 +18,6 @@
 
 #define cpu_has_invlpg	(boot_cpu_data.x86 > 3)
 
-#define __flush_tlb_single(addr) \
-	__asm__ __volatile__("invlpg %0": :"m" (*(char *) addr))
-
 #ifdef CONFIG_X86_INVLPG
 # define __flush_tlb_one(addr) __flush_tlb_single(addr)
 #else
diff -Naur linux-2.6.12.3.pristine/include/asm-i386/vmlinux.lds.h linux-2.6.12.3-vmi/include/asm-i386/vmlinux.lds.h
--- linux-2.6.12.3.pristine/include/asm-i386/vmlinux.lds.h	1970-01-01 00:00:00.000000000 +0000
+++ linux-2.6.12.3-vmi/include/asm-i386/vmlinux.lds.h	2005-11-15 16:57:30.000000000 +0000
@@ -0,0 +1,2 @@
+#include <asm-generic/vmlinux.lds.h>
+#include <mach-vmlinux.lds.h>
diff -Naur linux-2.6.12.3.pristine/include/asm-i386/xor.h linux-2.6.12.3-vmi/include/asm-i386/xor.h
--- linux-2.6.12.3.pristine/include/asm-i386/xor.h	2005-07-15 21:18:57.000000000 +0000
+++ linux-2.6.12.3-vmi/include/asm-i386/xor.h	2005-11-15 16:57:30.000000000 +0000
@@ -535,14 +535,14 @@
 
 #define XMMS_SAVE do {				\
 	preempt_disable();			\
+	cr0 = read_cr0();			\
+	clts();					\
 	__asm__ __volatile__ ( 			\
-		"movl %%cr0,%0		;\n\t"	\
-		"clts			;\n\t"	\
-		"movups %%xmm0,(%1)	;\n\t"	\
-		"movups %%xmm1,0x10(%1)	;\n\t"	\
-		"movups %%xmm2,0x20(%1)	;\n\t"	\
-		"movups %%xmm3,0x30(%1)	;\n\t"	\
-		: "=&r" (cr0)			\
+		"movups %%xmm0,(%0)	;\n\t"	\
+		"movups %%xmm1,0x10(%0)	;\n\t"	\
+		"movups %%xmm2,0x20(%0)	;\n\t"	\
+		"movups %%xmm3,0x30(%0)	;\n\t"	\
+		:				\
 		: "r" (xmm_save) 		\
 		: "memory");			\
 } while(0)
@@ -550,14 +550,14 @@
 #define XMMS_RESTORE do {			\
 	__asm__ __volatile__ ( 			\
 		"sfence			;\n\t"	\
-		"movups (%1),%%xmm0	;\n\t"	\
-		"movups 0x10(%1),%%xmm1	;\n\t"	\
-		"movups 0x20(%1),%%xmm2	;\n\t"	\
-		"movups 0x30(%1),%%xmm3	;\n\t"	\
-		"movl 	%0,%%cr0	;\n\t"	\
+		"movups (%0),%%xmm0	;\n\t"	\
+		"movups 0x10(%0),%%xmm1	;\n\t"	\
+		"movups 0x20(%0),%%xmm2	;\n\t"	\
+		"movups 0x30(%0),%%xmm3	;\n\t"	\
 		:				\
-		: "r" (cr0), "r" (xmm_save)	\
+		: "r" (xmm_save)		\
 		: "memory");			\
+	write_cr0(cr0);				\
 	preempt_enable();			\
 } while(0)
 
